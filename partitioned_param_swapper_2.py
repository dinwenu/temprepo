# Copyright (c) Microsoft Corporation.
# SPDX-License-Identifier: Apache-2.0

# DeepSpeed Team
"""
Functionality of swapping tensors to/from (NVMe) storage devices.
"""

import os
import shutil
from enum import Enum
import torch
from deepspeed import comm as dist
from deepspeed.accelerator import get_accelerator
from deepspeed.ops.op_builder import AsyncIOBuilder
from .constants import *
from .utils import swap_in_tensors, swap_out_tensors, MIN_AIO_BYTES, AIO_ALIGNED_BYTES, print_object, SwapBufferPool

from .utils import swap_in_tensors_sync, swap_out_tensors_sync, swap_in_tensors_sync_2, swap_out_tensors_sync_2

import time

def print_rank_0(message, debug=False, force=False):
    if dist.get_rank() == 0 and (debug or force):
        print(message)


class PartitionedParamStatus(Enum):
    # Partitioned parameters are present and ready for use
    AVAILABLE = 1

    # partitioned params are in some non-memory device
    NOT_AVAILABLE = 2

    # partitioned params are being read from some non-memory device.
    INFLIGHT = 3


class AsyncPartitionedParameterSwapper(object):

    def __init__(self, ds_config, pinned_buffer_information, nvme_layers, model_dtype, layer_id_to_rank, rank):
        # åˆ›å»ºäº†ä¸€ä¸ª AsyncIOBuilder ç±»çš„å®ä¾‹ã€‚è¿™æ˜¯ä¸€ä¸ª OpBuilder ç±»ï¼Œç”¨äºæ„å»ºå¼‚æ­¥ I/O ç›¸å…³çš„æ“ä½œã€‚
        # å¯¹åˆšåˆ›å»ºçš„ AsyncIOBuilder å®ä¾‹è°ƒç”¨äº† load æ–¹æ³•ã€‚è¿™ä¸ªæ–¹æ³•ç”¨äºåŠ è½½å¼‚æ­¥ I/O æ“ä½œçš„æ¨¡å—
        # å®è´¨ä¸Šå°±æ˜¯ Loads a PyTorch C++ extension just-in-time (JIT).
        aio_op = AsyncIOBuilder().load(verbose=False)
        self.aio_handle = aio_op.aio_handle
        self.dtype = model_dtype
        self.rank = rank
        self.layer_id_to_rank = layer_id_to_rank

        #set swap buffers, create aio handles
        # 1.æ„å»ºnvmeè·¯å¾„å¹¶åˆ›å»ºæ–°çš„æ–‡ä»¶å¤¹
        # 2.æ ¹æ®é…ç½®ä¿¡æ¯è®¡ç®—æ¯ä¸ªbufferå¯¹é½åçš„å…ƒç´ æ•°é‡
        # 3.buffers: åˆ›å»ºä¸€ä¸ªä¸€ç»´çš„ç©ºtensorï¼Œé”å®šåœ¨å†…å­˜ä¸­ã€‚å¤§å°ä¸ºbufferå¯¹é½åçš„å…ƒç´ æ•°é‡ Ã— bufferæ•°é‡
        # 4.aio handlesï¼šåˆ›å»ºä¸¤ä¸ªaio_handle(C++)ç±»ï¼Œç”¨äºè¯»å’Œå†™
        self._configure_aio_2(ds_config, pinned_buffer_information, nvme_layers)

        #mapping from param id to path
        self.id_to_path = {}

        #mapping from pram_id to buffer id
        self.param_id_to_buffer_id = {}

        # mapping from param_id to swap buffer
        # å°†å½“å‰param_idç›´æ¥æ˜ å°„åˆ°çœŸæ­£çš„bufferä¸Šï¼ˆæœ¬è´¨ä¸Šæ˜¯bufferçš„narrowï¼‰
        self.param_id_to_swap_buffer = {}

        #number of elements in the param
        # ğŸ“Œå‚æ•°é‡çš„æ˜ å°„æ˜¯ åˆ’åˆ†åçš„å‚æ•°é‡
        self.param_id_to_numel = {}

        self.pending_writes = 0
        self.pending_reads = 0

        #keep track of async swap in params and buffers
        self.inflight_params = []
        self.inflight_swap_in_buffers = []
        self.inflight_numel = 0

        #keep track of available params
        self.available_params = set()
        self.available_numel = 0

        # for swapping out from partitioned fp32 params
        self.partitioned_swap_buffer = None
        self.partitioned_swap_pool = None

        # åˆ›å»ºäº†ä¸€ä¸ªåŒ…å«å•ä¸ªå…ƒç´ å€¼ 1 çš„ PyTorch å¼ é‡ï¼Œç±»å‹ torch.float16
        self.invalid_buffer = torch.tensor(1).half()

        if self.rank == 0:
            exclude_list = ['aio_read_handle', 'aio_write_handle', 'buffers']
            print_object(obj=self, name='AsyncPartitionedParameterSwapper', exclude_list=exclude_list)

    def available_swap_in_buffers(self):
        return len(self.available_buffer_ids)

    # è¿™ä¸ªåº”è¯¥ä¸ç”¨åŠ¨ï¼Œåªè¦æå‰æŠŠå‚æ•°è®¾ç½®å¥½å°±è¡Œï¼Œæœ€é‡è¦çš„åº”è¯¥æ˜¯æˆ‘ä»¬åªç”¨1ä¸ªbufferï¼Œä¸ç”¨åˆ›å»ºå¤šä¸ª

    # 1.æ„å»ºnvmeè·¯å¾„å¹¶åˆ›å»ºæ–°çš„æ–‡ä»¶å¤¹
    # 2.æ ¹æ®é…ç½®ä¿¡æ¯è®¡ç®—æ¯ä¸ªbufferå¯¹é½åçš„å…ƒç´ æ•°é‡
    # 3.ä¸ºæ‰€æœ‰Bufferåˆ›å»ºä¸€ä¸ªè¿ç»­çš„å­˜å‚¨ç©ºé—´ï¼Œå³ä¸€ä¸ªä¸€ç»´ç©ºtensorï¼Œä½äºpinned memoryã€‚å¤§å°ä¸ºbufferå¯¹é½åçš„å…ƒç´ æ•°é‡ Ã— bufferæ•°é‡
    # 4.åˆ›å»ºä¸¤ä¸ªaio_handle(C++)ç±»ï¼Œç”¨äºè¯»å’Œå†™
    # ğŸ“Œå¤‡æ³¨ï¼šä»€ä¹ˆæ˜¯bufferï¼šbuffer poolä¸­æœ‰å¤šä¸ªbufferï¼Œé‡Œé¢è£…çš„paramå‡†å¤‡å¸è½½åˆ°NVMe.
    # self.bufferå°±æ˜¯ä¸€ä¸ªå›ºå®šåœ¨å†…å­˜çš„å¤§tensorï¼Œå¤§å°ä¸ºbuffer poolä¸­æ‰€æœ‰bufferçš„å¤§å°ä¹‹å’Œ
    def _configure_aio(self, ds_config):
        self.swap_config = ds_config.zero_config.offload_param
        torch_dtype_string = str(self.dtype).split(".")[1] # torch.float32
        # æ„å»ºnvmeè·¯å¾„
        self.swap_folder = os.path.join(self.swap_config.nvme_path, 'zero_stage_3', f'{torch_dtype_string}params',
                                        f'rank{dist.get_rank()}')
        
        # æ¸…ç†å·²å­˜åœ¨çš„ä¸´æ—¶æ–‡ä»¶å¤¹ï¼Œå¹¶åˆ›å»ºæ–°çš„æ–‡ä»¶å¤¹
        shutil.rmtree(self.swap_folder, ignore_errors=True)
        os.makedirs(self.swap_folder, exist_ok=True)

        # .element_size(): è·å–å¼ é‡ä¸­(ä¸€ä¸ª)å…ƒç´ çš„å­—èŠ‚å¤§å°
        self.swap_element_size = torch.tensor([], dtype=self.dtype).element_size()

        # è‹¥æ²¡åœ¨ "ds_config" ä¸­è®¾ç½®çš„è¯ï¼Œaio_configä¸­å­˜çš„éƒ½æ˜¯é»˜è®¤å€¼
        self.aio_config = ds_config.aio_config

        # Read/Write alignment for each thread during Intra-request parallelism
        # 
        self.min_aio_bytes = max(MIN_AIO_BYTES, self.aio_config[AIO_BLOCK_SIZE]) # 1024**2, 1048576 (éƒ½æ˜¯1MBï¼Œç›¸ç­‰)
        # å¼‚æ­¥I/Oçš„å¯¹é½å­—èŠ‚æ•°
        # å¯¹é½å­—èŠ‚æ•° Ã— I/Oçº¿ç¨‹æ•°é‡
        self.aligned_bytes = AIO_ALIGNED_BYTES * self.aio_config[AIO_THREAD_COUNT] # 1024 Ã— 1
        # å¯¹é½çš„å…ƒç´ æ•°é‡ = å¯¹é½çš„å­—èŠ‚æ•°/tensorä¸­ä¸€ä¸ªå…ƒç´ çš„å­—èŠ‚æ•°
        # å³ä¸€ä¸ªå¯¹é½çš„å—èƒ½è£…å¤šå°‘å…ƒç´ 
        self.numel_alignment = self.aligned_bytes // self.swap_element_size

        # Size of buffers in buffer pool for parameter offloading to NVMe. Default 1e8
        self.elements_per_buffer = self.swap_config.buffer_size
        # è‹¥bufferä¸­å…ƒç´ æ•°é‡èƒ½è¢« å¯¹é½å…ƒç´ æ•°é‡ æ•´æ¨¡ï¼Œè¿”å›å…ƒç´ æ•°é‡ï¼›ä¸ç„¶è¿”å›å¯¹é½åçš„å…ƒç´ æ•°é‡ï¼ˆå‘ä¸Šå¯¹é½ï¼‰
        self.aligned_elements_per_buffer = self._io_aligned_numel(self.elements_per_buffer)
        # Number of buffers in buffer pool for parameter offloading to NVMe. Default 5
        self.param_buffer_count = self.swap_config.buffer_count

        self.available_buffer_ids = [i for i in range(self.param_buffer_count)]
        self.reserved_buffer_ids = []
        # åˆ›å»ºä¸€ä¸ªä¸€ç»´çš„ç©ºtensorï¼Œé”å®šåœ¨å†…å­˜ä¸­
        # ä¸ºæ‰€æœ‰Bufferåˆ›å»ºä¸€ä¸ªè¿ç»­çš„å­˜å‚¨ç©ºé—´ï¼Œä½äºpinned memoryï¼šbufferå¯¹é½åçš„å…ƒç´ æ•°é‡ Ã— bufferä¸ªæ•°
        self.buffers = get_accelerator().pin_memory(torch.empty(int(self.aligned_elements_per_buffer *
                                                                    self.param_buffer_count),
                                                                dtype=self.dtype,
                                                                requires_grad=False),
                                                    align_bytes=0)

        # åˆ›å»ºä¸¤ä¸ªaio_handle(C++)ç±»ï¼Œç”¨äºè¯»å’Œå†™
        self.aio_read_handle = self.aio_handle(self.aio_config[AIO_BLOCK_SIZE], self.aio_config[AIO_QUEUE_DEPTH],
                                               self.aio_config[AIO_SINGLE_SUBMIT], self.aio_config[AIO_OVERLAP_EVENTS],
                                               self.aio_config[AIO_THREAD_COUNT])

        self.aio_write_handle = self.aio_handle(self.aio_config[AIO_BLOCK_SIZE], self.aio_config[AIO_QUEUE_DEPTH],
                                                self.aio_config[AIO_SINGLE_SUBMIT],
                                                self.aio_config[AIO_OVERLAP_EVENTS], self.aio_config[AIO_THREAD_COUNT])

        self.swap_out_params = []

    # ğŸ“
    def _configure_aio_2(self, ds_config, pinned_buffer_information, nvme_layers):
        self.swap_config = ds_config.zero_config.offload_param
        torch_dtype_string = str(self.dtype).split(".")[1] # torch.float32
        # æ„å»ºnvmeè·¯å¾„
        self.swap_folder = os.path.join(self.swap_config.nvme_path, 'zero_stage_3', f'{torch_dtype_string}params',
                                        f'rank{self.rank}')
        print(f"rank:{self.rank}, å½“å‰rankçš„å¸è½½è·¯å¾„ä¸º:{self.swap_folder}")
        # æ¸…ç†å·²å­˜åœ¨çš„ä¸´æ—¶æ–‡ä»¶å¤¹ï¼Œå¹¶åˆ›å»ºæ–°çš„æ–‡ä»¶å¤¹
        shutil.rmtree(self.swap_folder, ignore_errors=True)
        os.makedirs(self.swap_folder, exist_ok=True)

        # .element_size(): è·å–å¼ é‡ä¸­(ä¸€ä¸ª)å…ƒç´ çš„å­—èŠ‚å¤§å°
        self.swap_element_size = torch.tensor([], dtype=self.dtype).element_size()

        # è‹¥æ²¡åœ¨ "ds_config" ä¸­è®¾ç½®çš„è¯ï¼Œaio_configä¸­å­˜çš„éƒ½æ˜¯é»˜è®¤å€¼
        self.aio_config = ds_config.aio_config
        print(f"rank:{self.rank}, aioconfig:{self.aio_config}")

        # Read/Write alignment for each thread during Intra-request parallelism
        # 
        self.min_aio_bytes = max(MIN_AIO_BYTES, self.aio_config[AIO_BLOCK_SIZE]) # 1024**2, 1048576 (éƒ½æ˜¯1MBï¼Œç›¸ç­‰)
        # å¼‚æ­¥I/Oçš„å¯¹é½å­—èŠ‚æ•°
        # å¯¹é½å­—èŠ‚æ•° Ã— I/Oçº¿ç¨‹æ•°é‡
        self.aligned_bytes = AIO_ALIGNED_BYTES * self.aio_config[AIO_THREAD_COUNT] # 1024 Ã— 1
        # å¯¹é½çš„å…ƒç´ æ•°é‡ = å¯¹é½çš„å­—èŠ‚æ•°/tensorä¸­ä¸€ä¸ªå…ƒç´ çš„å­—èŠ‚æ•°
        # å³ä¸€ä¸ªå¯¹é½çš„å—èƒ½è£…å¤šå°‘å…ƒç´ 
        self.numel_alignment = self.aligned_bytes // self.swap_element_size

        # ğŸ“ç›´æ¥æ‹¿åˆ°è®¡ç®—å‡ºæ¥çš„buffersçš„å¤§å°ï¼Œæ›¿ä»£æ‰‹åŠ¨æŒ‡å®šbufferå¤§å°
        self.elements_per_buffer = pinned_buffer_information.get_buffers_size()

        # ğŸ“è®¡ç®—å‡ºæ¥çš„bufferå¤§å°å·²ç»åŒ…å«äº†è¡¥é½çš„éƒ¨åˆ†ï¼Œè¿™é‡Œä¸éœ€è¦å†æ¬¡è¡¥é½äº†
        self.aligned_elements_per_buffer = self.elements_per_buffer

        # Number of buffers in buffer pool for parameter offloading to NVMe. Default 5
        self.param_buffer_count = self.swap_config.buffer_count

        # åˆ›å»ºä¸€ä¸ªä¸€ç»´çš„ç©ºtensorï¼Œé”å®šåœ¨å†…å­˜ä¸­
        # ğŸ“ä¸Šé¢å·²ç»è¿”å›ç®—å¥½çš„å€¼äº†ï¼Œè¿™é‡Œä¸ç”¨å† Ã— bufferçš„æ•°é‡äº†
        self.buffers = get_accelerator().pin_memory(torch.empty(int(self.aligned_elements_per_buffer),
                                                                dtype=self.dtype,
                                                                requires_grad=False),
                                                    align_bytes=0)

        self.pinned_buffer_information = pinned_buffer_information

        self.layer_count = self.pinned_buffer_information.layer_count

        self.nvme_layers = nvme_layers
        self.layer_id_param_idx_to_path = {}
        for layer_id in self.nvme_layers:
            self.layer_id_param_idx_to_path[layer_id] = {}

        # ğŸ“2
        self.layer_id_to_path = {}

        # åˆ›å»ºä¸¤ä¸ªaio_handle(C++)ç±»ï¼Œç”¨äºè¯»å’Œå†™
        self.aio_read_handle = self.aio_handle(self.aio_config[AIO_BLOCK_SIZE], self.aio_config[AIO_QUEUE_DEPTH],
                                               self.aio_config[AIO_SINGLE_SUBMIT], self.aio_config[AIO_OVERLAP_EVENTS],
                                               self.aio_config[AIO_THREAD_COUNT], self.rank)

        self.aio_write_handle = self.aio_handle(self.aio_config[AIO_BLOCK_SIZE], self.aio_config[AIO_QUEUE_DEPTH],
                                                self.aio_config[AIO_SINGLE_SUBMIT],
                                                self.aio_config[AIO_OVERLAP_EVENTS], self.aio_config[AIO_THREAD_COUNT], self.rank)

        print(f"å½“å‰nvmeé…ç½®ä¸º: block_size:{self.aio_config[AIO_BLOCK_SIZE]}, queue_depthï¼š{self.aio_config[AIO_QUEUE_DEPTH]}, single_submit:{self.aio_config[AIO_SINGLE_SUBMIT]}, overlap:{self.aio_config[AIO_OVERLAP_EVENTS]}, thread:{self.aio_config[AIO_THREAD_COUNT]}")
        # exit(0)
        self.swap_out_params = []

    #Check if partitioned param or numel in a tensor is swappable or not
    # è‹¥ä¼ å…¥çš„å‚æ•°æ˜¯numelï¼Œè®¡ç®—æ€»çš„å­—èŠ‚æ•°ï¼Œè‹¥æ€»å­—èŠ‚æ•°å¤§äºç­‰äºåˆå§‹åŒ–æ—¶å†™æ­»çš„æœ€å°‘I/Oå­—èŠ‚æ•°(é»˜è®¤1MB)ï¼Œè¿”å›true
    def swappable_tensor(self, param=None, numel=None):
        if param is not None:
            assert numel is None, "Both parma and numel cannot be provided"
            numel = param.ds_tensor.ds_numel
        # æ£€æŸ¥è§„å®šçš„æœ€å°å­—èŠ‚æ•°é‡æ˜¯å¦å°äºæˆ–ç­‰äºæ€»çš„å­—èŠ‚æ•°
        # æ„æ€å°±æ˜¯tensorå¿…é¡»å¤§åˆ°ä¸€å®šç¨‹åº¦ï¼ˆé»˜è®¤1MBï¼‰æ‰æ˜¯å¯æ¢å‡ºçš„
        if numel is not None:
            # åˆå§‹åŒ–æ—¶å†™æ­»çš„æœ€å°‘I/Oå­—èŠ‚æ•° <= å…ƒç´ æ•°é‡Ã—ä¸€ä¸ªå…ƒç´ å å‡ ä¸ªå­—èŠ‚
            return self.min_aio_bytes <= numel * self.swap_element_size
        assert False, "Either param or numel must be provided"

    def get_path(self, param, must_exist=False):
        paths = self._get_swap_paths([param], must_exist=must_exist)
        return paths[0]

    # å¾—åˆ°paramså¯¹åº”çš„pathå¹¶è¿”å›ã€‚è‹¥å½“å‰paramçš„è·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ª
    def _get_swap_paths(self, params, must_exist=False):
        paths = []
        for param in params:
            param_id = param.ds_id
            if param_id in self.id_to_path.keys():
                param_path = self.id_to_path[param_id]
            else:
                assert not must_exist, f"Path for param id {param_id} does not exist"
                # è‹¥å½“å‰paramçš„è·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ª
                # os.path.join: æ¥å—ä»»æ„æ•°é‡çš„å­—ç¬¦ä¸²å‚æ•°ï¼Œå°†å®ƒä»¬è¿æ¥æˆä¸€ä¸ªæœ‰æ•ˆçš„æ–‡ä»¶è·¯å¾„
                param_path = os.path.join(self.swap_folder, f'{param_id}_param.tensor.swp')

                self.id_to_path[param_id] = param_path
            paths.append(param_path)

        return paths

    # ğŸ“é€šè¿‡layer_id, layer idxï¼Œparam_idxæ¥è·å–path
    def _get_swap_paths_2(self, layer_id, param_idx, layer_idx=None, must_exist=False):
        owner_rank = self.layer_id_to_rank[layer_id]

        if param_idx in self.layer_id_param_idx_to_path[layer_id].keys():
            param_path = self.layer_id_param_idx_to_path[layer_id][param_idx]
        else:
            assert not must_exist, f"Path for layer id {layer_id} param idx {param_idx} does not exist"
            # param_path = os.path.join(self.swap_folder, f'{layer_id}_{param_idx}_param.tensor.swp')
            param_path = os.path.join(
                self.swap_config.nvme_path,
                'zero_stage_3',
                f'{str(self.dtype).split(".")[1]}params',
                f'rank{owner_rank}',  # ä½¿ç”¨æ‹¥æœ‰è¿™ä¸ªlayerçš„rankçš„ç›®å½•
                f'{layer_id}_{param_idx}_param.tensor.swp'
            )

            self.layer_id_param_idx_to_path[layer_id][param_idx] = param_path
        return param_path

    # ğŸ“2
    def _get_transformer_layer_swap_paths(self, layer_id, layer_idx=None, must_exist=False):
        owner_rank = self.layer_id_to_rank[layer_id]

        if layer_id in self.layer_id_to_path.keys():
            param_path = self.layer_id_to_path[layer_id]
        else:
            assert not must_exist, f"Path for layer id {layer_id} does not exist"
            # param_path = os.path.join(self.swap_folder, f'{layer_id}_{param_idx}_param.tensor.swp')
            param_path = os.path.join(
                self.swap_config.nvme_path,
                'zero_stage_3',
                f'{str(self.dtype).split(".")[1]}params',
                f'rank{owner_rank}',  # ä½¿ç”¨æ‹¥æœ‰è¿™ä¸ªlayerçš„rankçš„ç›®å½•
                f'layer_{layer_id}.tensor.swp'
            )

            self.layer_id_to_path[layer_id] = param_path
        return param_path

    # å¾—åˆ°paramså¯¹åº”çš„buffer(ä¸€ä¸ªå¤§tensor(å°±æ˜¯æ‰€è°“çš„buffer)çš„narrowåçš„ç»“æœ)å¹¶è¿”å›
    def _get_swap_buffers(self, params):
        buffers = []
        for param in params:
            param_id = param.ds_id
            assert param_id in self.param_id_to_swap_buffer.keys(), \
            f'param {param_id} has not been assigned a swap buffer'
            buffers.append(self.param_id_to_swap_buffer[param_id])

        return buffers

    # å¯¹param listä¸­çš„æ¯ä¸ªparamï¼Œå»ºç«‹param_idåˆ°å…¶partitionåå‚æ•°é‡çš„æ˜ å°„
    def _track_numel(self, params):
        for param in params:
            assert param.ds_tensor is not None, "Partitioned tensor is None"
            self.param_id_to_numel[param.ds_id] = param.ds_tensor.ds_numel

    # 1.ä»å¯ç”¨çš„buffer_idä¸­å¼¹å‡ºä¸€ä¸ªidï¼Œå»ºç«‹å½“å‰param idåˆ°è¯¥buffer_idçš„æ˜ å°„å…³ç³»
    # 2.ä½¿ç”¨narrowæ–¹æ³•è¿”å›bufferä¸­å¯¹åº”è¯¥paramçš„éƒ¨åˆ†(é•¿åº¦ä¸ºå¯¹é½åçš„å…ƒç´ æ•°é‡)ï¼Œå³swap_bufferï¼Œå¹¶å»ºç«‹å½“å‰param idåˆ°è¯¥bufferçš„æ˜ å°„å…³ç³»
    #   å°†è¯¥bufferåŠ å…¥åˆ°swap_buffersåˆ—è¡¨ä¸­
    # 3.è¿›ä¸€æ­¥ä»swap_bufferä¸­narrowå‡ºå½“å‰paramå‚æ•°é‡çš„éƒ¨åˆ†ï¼Œå¾—åˆ°compute_bufferï¼ˆswap_bufferå¯èƒ½å«æœ‰è¡¥é½çš„éƒ¨åˆ†ï¼‰
    #   å¹¶å°†è¯¥bufferåŠ å…¥åˆ°compute_buffersåˆ—è¡¨ä¸­
    # è¿”å›ä¸¤ä¸ªåˆ—è¡¨ï¼š
    # ç¬¬ä¸€ä¸ªåˆ—è¡¨è£…ç€æ¯ä¸ªparamå¯¹åº”çš„compute_buffer(é•¿åº¦ä»…ä¸ºå½“å‰paramçš„å‚æ•°é‡)ï¼Œ
    # ç¬¬äºŒä¸ªåˆ—è¡¨è£…ç€æ¯ä¸€ä¸ªå¯¹åº”çš„swap_bufferï¼ˆå¯èƒ½åŒ…å«è¡¥é½çš„éƒ¨åˆ†ï¼‰
    def _allocate_and_return_buffers_for_swap_in(self, params):
        compute_buffers = []
        swap_buffers = []

        for param in params:
            param_id = param.ds_id
            assert param_id in self.param_id_to_numel.keys(), f" Number of elements in param {param_id} is unknown"
            assert param_id not in self.param_id_to_buffer_id.keys(
            ), f"param {param_id} already assigned swap buffer id {self.param_id_to_buffer_id[param_id]}"
            assert param_id not in self.param_id_to_swap_buffer.keys(
            ), f"param {param_id} has already been assigned a swap buffer"

            # 1.ä»å¯ç”¨çš„buffer_idä¸­å¼¹å‡ºä¸€ä¸ªidï¼Œå»ºç«‹å½“å‰param idåˆ°è¯¥buffer_idçš„æ˜ å°„å…³ç³»
            buffer_id = self.available_buffer_ids.pop()
            print_rank_0(f"param {param.ds_id} is assigned swap in buffer id {buffer_id}  ")
            self.param_id_to_buffer_id[param_id] = buffer_id
            # å¾—åˆ°å‚æ•°å¯¹é½åçš„å…ƒç´ æ•°é‡
            aligned_swap_numel = self._io_aligned_numel(self.param_id_to_numel[param_id])
            # 2.è¿”å›bufferä¸­å¯¹åº”è¯¥paramçš„éƒ¨åˆ†ï¼Œå³swap_bufferï¼Œå¹¶å»ºç«‹å½“å‰paramåˆ°è¯¥bufferçš„æ˜ å°„å…³ç³»
            #   å°†è¯¥bufferåŠ å…¥åˆ°swap_buffersåˆ—è¡¨ä¸­
            swap_buffer = self.buffers.narrow(0, int(buffer_id * self.aligned_elements_per_buffer), aligned_swap_numel)

            self.param_id_to_swap_buffer[param_id] = swap_buffer
            # 3.è¿›ä¸€æ­¥ä»swap_bufferä¸­narrowå‡ºå½“å‰paramå‚æ•°é‡çš„éƒ¨åˆ†ï¼Œå¾—åˆ°compute_bufferï¼ˆswap_bufferå¯èƒ½å«æœ‰è¡¥é½çš„éƒ¨åˆ†ï¼‰
            #   å¹¶å°†è¯¥bufferåŠ å…¥åˆ°compute_buffersåˆ—è¡¨ä¸­
            compute_buffer = swap_buffer.narrow(0, 0, self.param_id_to_numel[param_id])
            compute_buffers.append(compute_buffer)
            swap_buffers.append(swap_buffer)

        return compute_buffers, swap_buffers

    # ğŸ“ç›´æ¥æ ¹æ®transformer layerå’Œå†…éƒ¨paramçš„ä¸‹æ ‡è·å–åœ¨buffersä¸­çš„èŒƒå›´ï¼Œä½œä¸ºæ¥æ”¶tensorçš„ç©ºé—´
    def _allocate_and_return_buffers_for_swap_in_2(self, layer_idx, param_idx):

        # ä¸éœ€è¦å¼¹å‡ºä»€ä¹ˆbuffer idï¼Œç›´æ¥æ‹¿åˆ°paramåœ¨bufferä¸­çš„åç§»é‡
        layer_start = self.pinned_buffer_information.get_layer_start_pos_in_buffers(layer_idx)
        layer_size = self.pinned_buffer_information.get_buffer_size()
        param_start = self.pinned_buffer_information.get_param_start_pos(param_idx)
        param_size = self.pinned_buffer_information.get_param_size(param_idx)
        buffer = self.buffers.narrow(0, layer_start, layer_size)
        compute_buffer = buffer.narrow(0, param_start, param_size)

        aligned_size = self.pinned_buffer_information.get_param_aligned_size(param_idx)
        swap_buffer = buffer.narrow(0, param_start, aligned_size)

        return compute_buffer, swap_buffer
    
    # ğŸ“å› ä¸ºç›´æ¥å¸è½½è¯»å–æ•´ä¸ªtransformer layerï¼Œæ‰€ä»¥ä¸éœ€è¦è¡¥é½paramï¼Œç›´æ¥æŒ‰paramåŸå§‹
    #   çš„å¤§å°è·å–å°±å¥½äº†
    def _allocate_and_return_buffers_for_param(self, layer_idx, param_idx):
        layer_start = self.pinned_buffer_information.get_layer_start_pos_in_buffers(layer_idx)
        layer_size = self.pinned_buffer_information.get_buffer_size()
        param_start = self.pinned_buffer_information.get_param_start_pos(param_idx)
        param_size = self.pinned_buffer_information.get_param_size(param_idx)
        buffer = self.buffers.narrow(0, layer_start, layer_size)
        compute_buffer = buffer.narrow(0, param_start, param_size)

        return compute_buffer


    # ğŸ“3.è·Ÿä¸Šé¢ä¸€ä¸ªç‰ˆæœ¬çš„
    def _return_buffer_for_transformer_layer(self, layer_idx):
        layer_start = self.pinned_buffer_information.get_layer_start_pos_in_buffers(layer_idx)
        aligned_layer_size = self.pinned_buffer_information.get_buffer_size()
        layer_size = self.pinned_buffer_information.get_layer_size()

        swap_buffer = self.buffers.narrow(0, layer_start, aligned_layer_size)

        compute_buffer = swap_buffer.narrow(0, 0, layer_size)

        return compute_buffer, swap_buffer

    # ğŸ“å› ä¸ºç›´æ¥å¸è½½è¯»å–æ•´ä¸ªtransformer layerï¼Œæ‰€ä»¥ä¸éœ€è¦è¡¥é½paramï¼Œç›´æ¥æŒ‰paramåŸå§‹
    #   çš„å¤§å°è·å–å°±å¥½äº†
    def _allocate_and_return_buffers_for_param_double_buffer(self, buffer_id, layer_idx, param_idx):
        layer_start = self.pinned_buffer_information.get_layer_start_pos_in_buffers(buffer_id, layer_idx)
        layer_size = self.pinned_buffer_information.get_layer_size()
        param_start = self.pinned_buffer_information.get_param_start_pos(param_idx)
        param_size = self.pinned_buffer_information.get_param_size(param_idx)
        buffer = self.buffers.narrow(0, layer_start, layer_size)
        compute_buffer = buffer.narrow(0, param_start, param_size)

        return compute_buffer
    
    # ğŸ“4.åŒbufferç‰ˆæœ¬
    def _return_buffer_for_transformer_layer_double_buffer(self, buffer_id, layer_idx):
        layer_start = self.pinned_buffer_information.get_layer_start_pos_in_buffers(buffer_id, layer_idx)
        aligned_layer_size = self.pinned_buffer_information.get_aligned_layer_size()
        layer_size = self.pinned_buffer_information.get_layer_size()
        swap_buffer = self.buffers.narrow(0, layer_start, aligned_layer_size)
        compute_buffer = swap_buffer.narrow(0, 0, layer_size)

        return compute_buffer, swap_buffer

    #waits for inflight nvme write to complete
    # 1.ç­‰åœ¨æ­£åœ¨è¿›è¡Œçš„å†™æ“ä½œå…¨éƒ¨å®Œæˆ
    # 2.
    # 2.1.å°†å½“å‰å‚æ•°æ‰€åœ¨çš„bufferçš„ id æ”¾å›å¯ç”¨bufferåˆ—è¡¨
    # 2.2.åˆ é™¤è¯¥param_idçš„æ˜ å°„å…³ç³»(å³å­—å…¸)
    # 2.3.è‹¥å½“å‰å‚æ•°åœ¨å¯ç”¨å‚æ•°é›†åˆä¸­ï¼Œå°†å…¶ç§»é™¤ï¼›åŒæ—¶æ›´æ–°å‚æ•°é‡(å‡å»ç§»é™¤çš„tensorçš„å‚æ•°é‡)
    # 2.4.å°†param.ds_tensor.dataæŒ‡å‘ä¸€ä¸ªæ— æ•ˆçš„tensorçš„æ•°æ®(è¯¥tensoråªæœ‰ä¸€ä¸ª1)ï¼ŒåŒæ—¶æ›´æ–°param.ds_tensorçš„çŠ¶æ€ä¸º NOT_AVAILABLE
    def synchronize_writes(self):
        if self.pending_writes == 0:
            return
        # ç­‰åœ¨æ­£åœ¨è¿›è¡Œçš„å†™æ“ä½œå…¨éƒ¨å®Œæˆ
        assert self.pending_writes == self.aio_write_handle.wait()
        self.pending_writes = 0
        # 1.å°†å½“å‰å‚æ•°æ‰€åœ¨çš„bufferçš„ id æ”¾å›å¯ç”¨bufferåˆ—è¡¨
        # 2.åˆ é™¤è¯¥param_idçš„æ˜ å°„å…³ç³»(å³å­—å…¸)
        # 3.è‹¥å½“å‰å‚æ•°åœ¨å¯ç”¨å‚æ•°é›†åˆä¸­ï¼Œå°†å…¶ç§»é™¤ï¼›åŒæ—¶æ›´æ–°å‚æ•°é‡(å‡å»ç§»é™¤çš„tensorçš„å‚æ•°é‡)
        # 4.å°†param.ds_tensor.dataæŒ‡å‘ä¸€ä¸ªæ— æ•ˆçš„tensorçš„æ•°æ®(è¯¥tensoråªæœ‰ä¸€ä¸ª1)ï¼ŒåŒæ—¶æ›´æ–°param.ds_tensorçš„çŠ¶æ€ä¸º NOT_AVAILABLE
        self.remove_partition_and_release_buffers(self.swap_out_params)
        self.swap_out_params = []

    # ğŸ“å› ä¸ºæ˜¯ä»shared memoryç›´æ¥å¸è½½çš„ï¼Œå› æ­¤æ ¹æœ¬æ— éœ€å›æ”¶pinned buffer
    #    é‡Šæ”¾å‚æ•°åˆ™äº¤ç»™ä¸Šçº§ç±»å¤„ç†ï¼Œä¸åœ¨æœ¬ç±»ä¸­å¤„ç†
    def synchronize_writes_without_release(self):
        if self.pending_writes == 0:
            return
        # ç­‰åœ¨æ­£åœ¨è¿›è¡Œçš„å†™æ“ä½œå…¨éƒ¨å®Œæˆ
        assert self.pending_writes == self.aio_write_handle.wait()
        self.pending_writes = 0
        # self.swap_out_params = []

    #waits for inflight nvme reads to complete
    # 1.ç­‰å¾…æ­£åœ¨ä»nvmeè¯»æ•°æ®çš„çº¿ç¨‹å…¨éƒ¨å®Œæˆ
    # 2.å°†ä¸Šé¢åˆšåˆšå®Œæˆè¯»å–çš„é‚£äº›paramçš„ param.ds_tensor.data æŒ‡å‘å¯¹åº”çš„ buffer(åˆšåˆšè¯»åˆ°bufferé‡Œäº†)ã€‚
    #   å¹¶å°† param.ds_tensor.status è®¾ç½®ä¸º AVAILABLE
    # 3.å°†ä¸Šé¢åˆšæ‰§è¡Œå®Œçš„å‚æ•°çš„ds_idæ·»åŠ åˆ°å¯ç”¨å‚æ•°é›†åˆä¸­(ğŸ“Œå¯ç”¨è¯´çš„æ˜¯ds_tensorå¯ç”¨äº†)ã€‚æ¸…ç©ºè¿½è¸ªçš„å˜é‡ï¼ˆè¿½è¸ªæ­£åœ¨è¯»å–çš„å‚æ•°çš„ç›¸å…³ä¿¡æ¯ï¼‰
    def synchronize_reads(self):
        # è‹¥æ²¡æœ‰æ­£åœ¨è¯»å–çš„å‚æ•°ï¼Œç›´æ¥è¿”å›
        if self.pending_reads == 0:
            return

        assert self.pending_reads == self.aio_read_handle.wait()

        # æ¸…ç©ºæ­£åœ¨æ‰§è¡Œçš„è¯»å–çš„å‚æ•°æ•°é‡
        self.pending_reads = 0

        # å°†ä¸Šé¢åˆšåˆšå®Œæˆè¯»å–çš„é‚£äº›paramçš„ param.ds_tensor.data æŒ‡å‘å¯¹åº”çš„ buffer ï¼ˆåˆšåˆšè¯»åˆ°bufferé‡Œäº†ï¼‰
        # çŠ¶æ€è®¾ç½®ä¸º AVAILABLE
        for param, swap_in_buffer in zip(self.inflight_params, self.inflight_swap_in_buffers):
            param_id = param.ds_id
            compute_buffer = swap_in_buffer.narrow(0, 0, self.param_id_to_numel[param_id])
            param.ds_tensor.data = compute_buffer.data
            param.ds_tensor.status = PartitionedParamStatus.AVAILABLE

        # å°†ä¸Šé¢åˆšæ‰§è¡Œå®Œçš„å‚æ•°çš„ds_idæ·»åŠ åˆ°å¯ç”¨å‚æ•°é›†åˆä¸­
        self.available_params.update([param.ds_id for param in self.inflight_params])
        self.available_numel += self.inflight_numel

        # æ¸…ç©ºæ­£åœ¨è¿½è¸ªçš„è¦è¯»å–çš„paramçš„ä¿¡æ¯
        self.inflight_params = []
        self.inflight_swap_in_buffers = []
        self.inflight_numel = 0

    def synchronize_reads_2(self):
        if self.pending_reads == 0:
            return
        assert self.pending_reads == self.aio_read_handle.wait()
        self.pending_reads = 0

    #Removes the memory assignment and releases the buffers
    #Should only be executed after swapping out the tensors
    # 1.è‹¥å½“å‰å‚æ•°åœ¨param_id_to_buffer_idçš„æ˜ å°„ä¸­ï¼Œåˆ™ï¼š
    #   1.1.å°†å½“å‰å‚æ•°æ‰€åœ¨çš„bufferçš„ id æ”¾å›å¯ç”¨bufferåˆ—è¡¨
    #   1.2.åˆ é™¤è¯¥param_idåˆ°buffer_idçš„æ˜ å°„å…³ç³»ï¼Œåˆ é™¤param_idåˆ°swap_bufferçš„æ˜ å°„å…³ç³»
    #   1.3.è‹¥å½“å‰å‚æ•°åœ¨å¯ç”¨å‚æ•°é›†åˆä¸­(è¯´æ˜åœ¨cpu bufferä¸Šå­˜ç€)ï¼Œå°†å…¶ç§»é™¤ï¼›åŒæ—¶æ›´æ–°å¯ç”¨å‚æ•°çš„å‚æ•°é‡(å‡å»ç§»é™¤çš„tensorçš„å‚æ•°é‡)
    # 2.å°†param.ds_tensor.dataæŒ‡å‘ä¸€ä¸ªæ— æ•ˆçš„tensorçš„æ•°æ®(è¯¥tensoråªæœ‰ä¸€ä¸ª1)ï¼ŒåŒæ—¶æ›´æ–°param.ds_tensorçš„çŠ¶æ€ä¸º NOT_AVAILABLE
    def remove_partition_and_release_buffers(self, params):
        for param in params:
            param_id = param.ds_id

            if param_id in self.param_id_to_buffer_id.keys():

                buffer_id = self.param_id_to_buffer_id[param_id]

                assert buffer_id is not None, "Missing buffer id for releasing"

                # å°†é‡Šæ”¾çš„ç¼“å†²åŒº id æ”¾å›å¯ç”¨åˆ—è¡¨
                # â“è¿™æ˜¯å•¥é€»è¾‘
                self.available_buffer_ids.append(buffer_id)
                # åˆ é™¤è¯¥param_idçš„æ˜ å°„å…³ç³»(å³å­—å…¸)
                del self.param_id_to_buffer_id[param_id]
                del self.param_id_to_swap_buffer[param_id]
                print_rank_0(f"param {param.ds_id} releases buffer id {buffer_id}  ")

                # è‹¥å½“å‰å‚æ•°åœ¨å¯ç”¨å‚æ•°é›†åˆä¸­ï¼Œå°†å…¶ç§»é™¤
                # åŒæ—¶æ›´æ–°å‚æ•°é‡(å‡å»ç§»é™¤çš„tensorçš„å‚æ•°é‡)
                if param_id in self.available_params:
                    self.available_params.remove(param_id)
                    self.available_numel -= self.param_id_to_numel[param_id]

            # å°†å‚æ•°çš„æ•°æ®æŒ‡å‘ä¸€ä¸ªæ— æ•ˆçš„tensorçš„æ•°æ®(è¯¥tensoråªæœ‰ä¸€ä¸ª1)ï¼ŒåŒæ—¶æ›´æ–°çŠ¶æ€
            param.ds_tensor.data = self.invalid_buffer.data
            param.ds_tensor.status = PartitionedParamStatus.NOT_AVAILABLE

    #writes from in memory to nvme. Does not release the buffers
    # 
    def _swap_out(self, params, async_op=True):

        swap_out_paths = self._get_swap_paths(params) # å¾—åˆ°å‚æ•°å¯¹åº”çš„pathå¹¶è¿”å›ã€‚è‹¥å½“å‰paramçš„è·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ª
        # â“paramçš„åº•å±‚æ•°æ®ä½•æ—¶è£…åˆ°è¿™ä¸ªbufferé‡Œçš„ï¼Ÿ
        # ç­”:è§partitioned_parameter.pyä¸­çš„_partition_paramçš„ç¬¬ä¸€ä¸ªğŸ“Œï¼Œparam.ds_tensorå·²ç»å’Œbufferå…±äº«åº•å±‚å­˜å‚¨äº†
        swap_out_params = self._get_swap_buffers(params) # å¾—åˆ°paramså¯¹åº”çš„buffer(ä¸€ä¸ªtensor narrowåçš„ç»“æœ)å¹¶è¿”å›
        self._track_numel(params) # å¯¹param listä¸­çš„æ¯ä¸ªparamï¼Œå»ºç«‹param_idåˆ°å…¶partitionåå‚æ•°é‡çš„æ˜ å°„

        # å¼‚æ­¥å†™å…¥ï¼Œç»™çº¿ç¨‹åˆ†é…å®Œä»»åŠ¡å°±ç›´æ¥è¿”å›ç»§ç»­å¾€ä¸‹è¿è¡Œäº†
        swap_out_tensors(self.aio_write_handle, swap_out_params, swap_out_paths)

        self.pending_writes += len(swap_out_params)
        self.swap_out_params += params

        # partition_paramä¸­æœªä¼ å…¥async_opå‚æ•°ï¼Œé»˜è®¤ä½¿ç”¨swap_out_and_releaseä¼ å…¥çš„falseï¼Œè¿™é‡Œæ‰§è¡ŒåŒæ­¥å†™å…¥
        if not async_op:
            # 1.ç­‰å¾…æ­£åœ¨è¿›è¡Œçš„å†™æ“ä½œå…¨éƒ¨å®Œæˆ
            # 2.
            # 2.1.å°†å½“å‰å‚æ•°æ‰€åœ¨çš„bufferçš„ id æ”¾å›å¯ç”¨bufferåˆ—è¡¨
            # 2.2.åˆ é™¤è¯¥param_idçš„æ˜ å°„å…³ç³»(å³å­—å…¸)
            # 2.3.è‹¥å½“å‰å‚æ•°åœ¨å¯ç”¨å‚æ•°é›†åˆä¸­ï¼Œå°†å…¶ç§»é™¤ï¼›åŒæ—¶æ›´æ–°å‚æ•°é‡(å‡å»ç§»é™¤çš„tensorçš„å‚æ•°é‡)
            # 2.4.å°†param.ds_tensor.dataæŒ‡å‘ä¸€ä¸ªæ— æ•ˆçš„tensorçš„æ•°æ®(è¯¥tensoråªæœ‰ä¸€ä¸ª1)ï¼ŒåŒæ—¶æ›´æ–°param.ds_tensorçš„çŠ¶æ€ä¸º
            #     NOT_AVAILABLE
            self.synchronize_writes()

    # ğŸ“æ–°çš„swap_outæ–¹æ³•ï¼Œç›´æ¥å¸è½½ç»™å®šçš„tensorï¼Œä¸éœ€è¦ä»pinned bufferå¸è½½
    def swap_out_2(self, param, layer_id, param_idx, async_op=False):
        swap_out_path = self._get_swap_paths_2(layer_id, param_idx)
        print(f"rank:{self.rank}, å‡†å¤‡å¼€å§‹å¸è½½layer{layer_id}", flush=True)
        swap_out_tensors(self.aio_write_handle, [param], [swap_out_path])
        self.pending_writes += 1
        # self.swap_out_params += param
        if not async_op:
            print(f"rank:{self.rank}, layer{layer_id} å¼€å§‹syncå†™å…¥nvme", flush=True)
            self.synchronize_writes_without_release()
            print(f"rank:{self.rank}, layer{layer_id}-{param_idx}å¸è½½å®Œæˆ", flush=True)

    def swap_out_2_sync(self, param, layer_id, param_idx):
        swap_out_path = self._get_swap_paths_2(layer_id, param_idx)
        swap_out_tensors_sync(self.aio_write_handle, [param], [swap_out_path])
        print(f"rank:{self.rank}, layer{layer_id}-{param_idx}å¸è½½å®Œæˆ", flush=True)
        
    def swap_out_2_sync_2(self, param, layer_id, param_idx):
        swap_out_path = self._get_swap_paths_2(layer_id, param_idx)
        swap_out_tensors_sync_2(self.aio_write_handle, [param], [swap_out_path])
        print(f"rank:{self.rank}, layer{layer_id}-{param_idx}å¸è½½å®Œæˆ", flush=True)

    # ğŸ“
    def swap_out_transformer_layer(self, layer_id, layer_idx, async_op=False):
        # start_time = time.perf_counter()
        swap_out_path = self._get_transformer_layer_swap_paths(layer_id)
        # end_time = time.perf_counter()
        # print(f"rank:{self.rank}, è¿”å›åœ°å€æ—¶é—´: {(end_time - start_time):.4f} ç§’", flush=True)
        # start_time = time.perf_counter()
        _, swap_buffer = self._return_buffer_for_transformer_layer(layer_idx)
        # end_time = time.perf_counter()
        # print(f"rank:{self.rank}, åˆ†é…bufferæ—¶é—´: {(end_time - start_time):.4f} ç§’", flush=True)
        # print(f"rank:{self.rank}, å‡†å¤‡å¼€å§‹å¸è½½layer{layer_id}", flush=True)
        # start_time = time.perf_counter()
        swap_out_tensors(self.aio_write_handle, [swap_buffer], [swap_out_path])
        # end_time = time.perf_counter()
        # print(f"rank:{self.rank}, è°ƒç”¨swap_out_tensorså‡½æ•°æ—¶é—´: {(end_time - start_time):.4f} ç§’", flush=True)
        self.pending_writes += 1
        # ğŸ“Œç“¶é¢ˆåœ¨è¿™ï¼Œå°¼ç›çš„å ç”¨æ—¶é—´å·¨é•¿ï¼Œåº”è¯¥æ˜¯+=è§¦å‘äº†tensorçš„æ·±åº¦æ‹·è´
        # start_time = time.perf_counter()
        # self.swap_out_params += swap_buffer
        # end_time = time.perf_counter()
        # print(f"rank:{self.rank}, \"self.swap_out_params += swap_buffer\"æ—¶é—´: {(end_time - start_time):.4f} ç§’", flush=True)
        if not async_op:
            # start_time = time.perf_counter()
            print(f"rank:{self.rank}, layer{layer_id} å¼€å§‹syncå†™å…¥nvme", flush=True)
            self.synchronize_writes_without_release()
            # end_time = time.perf_counter()
            # print(f"rank:{self.rank}ï¼Œç­‰å¾…å¸è½½çš„æ—¶é—´: {(end_time - start_time):.4f} ç§’", flush=True)
            print(f"rank:{self.rank}, layer{layer_id}å¸è½½å®Œæˆ", flush=True)

    # ğŸ“
    def swap_out_transformer_layer_sync(self, layer_id, layer_idx, async_op=False):
        # start_time = time.perf_counter()
        swap_out_path = self._get_transformer_layer_swap_paths(layer_id)
        # end_time = time.perf_counter()
        # print(f"rank:{self.rank}, è¿”å›åœ°å€æ—¶é—´: {(end_time - start_time):.4f} ç§’", flush=True)
        # start_time = time.perf_counter()
        _, swap_buffer = self._return_buffer_for_transformer_layer(layer_idx)
        swap_in_tensors_sync_2(self.aio_write_handle, [swap_buffer], [swap_out_path])
        print(f"rank:{self.rank}, layer{layer_id}å¸è½½å®Œæˆ", flush=True)
        

    # ğŸ“åŒbufferç‰ˆæœ¬
    def swap_out_transformer_layer_double_buffer(self, buffer_id, layer_id, layer_idx, async_op=False):
        swap_out_path = self._get_transformer_layer_swap_paths(layer_id)
        _, swap_buffer = self._return_buffer_for_transformer_layer_double_buffer(buffer_id, layer_idx)
        swap_out_tensors(self.aio_write_handle, [swap_buffer], [swap_out_path])
        self.pending_writes += 1
        if not async_op:
            self.synchronize_writes_without_release()
            print(f"rank:{self.rank}, layer{layer_id}å¸è½½å®Œæˆ", flush=True)

    # ğŸ“åŒbufferç‰ˆæœ¬
    def swap_out_transformer_layer_double_buffer_sync(self, buffer_id, layer_id, layer_idx):
        swap_out_path = self._get_transformer_layer_swap_paths(layer_id)
        _, swap_buffer = self._return_buffer_for_transformer_layer_double_buffer(buffer_id, layer_idx)
        swap_out_tensors_sync_2(self.aio_write_handle, [swap_buffer], [swap_out_path])

    #blocking swap out followed by releasing the memory buffers
    def swap_out_and_release(self, params, async_op=False, force_buffer_release=False):
        if async_op:
            assert force_buffer_release, "Should not release preallocated buffers without completing the swap out. Set force_buffer_release to True to do it anyways"
        self._swap_out(params, async_op=async_op)


    # book keeping function for inflight swap in
    # å°†å‚æ•°åˆ—è¡¨åŠ åˆ°inflight_paramsä¸­ï¼Œè¡¨ç¤ºè¿™äº›å‚æ•°æ­£åœ¨è¯»å–
    # å°†buffersåŠ å…¥åˆ°inflight_swap_in_buffersåˆ—è¡¨ï¼ŒåŒç†
    # å°†æ­£åœ¨è¯»å–çš„å‚æ•°é‡èµ‹ç»™self.inflight_numel
    # 
    # å°†æ‰€æœ‰æ­£åœ¨è¯»å–çš„åˆ’åˆ†åçš„paramçš„çŠ¶æ€æ ‡è®°ä¸º INFLIGHT
    # è®°å½•æ­£åœ¨è¯»å–çš„å‚æ•°æ•°é‡
    def _update_inflight_swap_in(self, params, swap_in_buffers, inflight_numel):
        self.inflight_params.extend(params)
        self.inflight_swap_in_buffers.extend(swap_in_buffers)
        self.inflight_numel += inflight_numel

        for param in params:
            param.ds_tensor.status = PartitionedParamStatus.INFLIGHT

        self.pending_reads += len(params)

    #assigns an in memory buffer and swaps in from nvme
    # 1.é¦–å…ˆè¦ç¡®ä¿æ‰€æœ‰çš„åˆ’åˆ†åçš„paraméƒ½å¤„äºä¸å¯ç”¨çŠ¶æ€
    # 2.è‹¥æ²¡æœ‰ç»™å®šçš„bufferï¼Œåˆ™å»ºç«‹ç¼“å†²åŒºç”¨äºæ¥æ”¶nvmeçš„å‚æ•°
    #   -ä¸ºæ¯ä¸€ä¸ªparamåˆ†é…ä¸€ä¸ªbufferï¼Œç”¨äºæ¥å—nvmeè¯»ä¸Šæ¥çš„å‚æ•°
    # 3.è°ƒç”¨C++å‡½æ•°æŠŠæ ¹æ®æŠŠè·¯å¾„æŠŠparaméƒ½æ‹¿åˆ°bufferä¸­
    # 4.å¯¹æ­£åœ¨è¯»å–çš„paramå’Œbufferè¿›è¡Œè¿½è¸ªï¼ˆå°±æ˜¯èµ‹ç»™ä¸€äº›selfæˆå‘˜å˜é‡ï¼‰,å¹¶å°†æ‰€æœ‰æ­£åœ¨è¯»å–çš„paramçš„çŠ¶æ€æ ‡è®°ä¸º INFLIGHT
    #
    # è‹¥å¹¶éå¼‚æ­¥æ‰§è¡Œï¼Œå³å¿…é¡»ç­‰nvmeè¯»æ“ä½œå®Œæˆï¼š
    # 5.
    #   5.1.ç­‰å¾…æ­£åœ¨ä»nvmeè¯»æ•°æ®çš„çº¿ç¨‹å…¨éƒ¨å®Œæˆ
    #   5.2.å°†ä¸Šé¢åˆšåˆšå®Œæˆè¯»å–çš„é‚£äº›paramçš„ param.ds_tensor.data æŒ‡å‘å¯¹åº”çš„ buffer(åˆšåˆšè¯»åˆ°bufferé‡Œäº†)ã€‚
    #       å¹¶å°† param.ds_tensor.status è®¾ç½®ä¸º AVAILABLE
    #   5.3.å°†ä¸Šé¢åˆšæ‰§è¡Œå®Œçš„å‚æ•°çš„ds_idæ·»åŠ åˆ°å¯ç”¨å‚æ•°é›†åˆä¸­(ğŸ“Œå¯ç”¨è¯´çš„æ˜¯ds_tensorå¯ç”¨äº†)ã€‚
    #       æ¸…ç©ºè¿½è¸ªçš„å˜é‡ï¼ˆè¿½è¸ªæ­£åœ¨è¯»å–çš„å‚æ•°çš„ç›¸å…³ä¿¡æ¯ï¼‰
    def swap_in(self, params, async_op=True, swap_in_buffers=None):

        # 1.é¦–å…ˆè¦ç¡®ä¿æ‰€æœ‰çš„paraméƒ½å¤„äºä¸å¯ç”¨çŠ¶æ€
        assert all([param.ds_tensor.status == PartitionedParamStatus.NOT_AVAILABLE
                    for param in params]), "Some params are already available or in flight"
        swap_in_paths = self._get_swap_paths(params)

        # 2.è‹¥æ²¡æœ‰ç»™å®šçš„bufferï¼Œåˆ™å»ºç«‹ç¼“å†²åŒºç”¨äºæ¥æ”¶nvmeçš„å‚æ•°
        # å¿…é¡»ä¿è¯å¯ç”¨bufferæ•°é‡ï¼Œæ¯”è¦è¯»çš„å‚æ•°å¤šï¼Œä¸ç„¶ç›´æ¥ä¸­æ–­
        if swap_in_buffers is None:
            if len(self.available_buffer_ids) < len(swap_in_paths):
                ids = [p.ds_id for p in params]
                print_rank_0(
                    f'Not enough swap in buffers {len(self.available_buffer_ids)} for {len(swap_in_paths)} params, ids = {ids}',
                    force=True)
                print_rank_0(
                    f'Num inflight: params {len(self.inflight_params)}, buffers {len(self.inflight_swap_in_buffers)}, numel = {self.inflight_numel}',
                    force=True)
                print_rank_0(
                    f'Num available params: count = {len(self.available_params)}, ids = {self.available_params}, numel = {self.available_numel}',
                    force=True)

            assert len(swap_in_paths) <= len(
                self.available_buffer_ids
            ), f"Not enough buffers {len(self.available_buffer_ids)} for swapping {len(swap_in_paths)}"
            # 3.ä¸ºæ¯ä¸€ä¸ªparamåˆ†é…ä¸€ä¸ªbufferï¼Œç”¨äºæ¥å—nvmeè¯»ä¸Šæ¥çš„å‚æ•°
            # 3.1.ä»å¯ç”¨çš„buffer_idä¸­å¼¹å‡ºä¸€ä¸ªidï¼Œå»ºç«‹å½“å‰param idåˆ°è¯¥buffer_idçš„æ˜ å°„å…³ç³»
            # 3.2.ä½¿ç”¨narrowæ–¹æ³•è¿”å›bufferä¸­å¯¹åº”è¯¥paramçš„éƒ¨åˆ†(é•¿åº¦ä¸ºå¯¹é½åçš„å…ƒç´ æ•°é‡)ï¼Œå³swap_bufferï¼Œå¹¶å»ºç«‹å½“å‰param idåˆ°è¯¥bufferçš„æ˜ å°„å…³ç³»
            #     å°†è¯¥bufferåŠ å…¥åˆ°swap_buffersåˆ—è¡¨ä¸­
            # 3.3.è¿›ä¸€æ­¥ä»swap_bufferä¸­narrowå‡ºå½“å‰paramå‚æ•°é‡çš„éƒ¨åˆ†ï¼Œå¾—åˆ°compute_bufferï¼ˆswap_bufferå¯èƒ½å«æœ‰è¡¥é½çš„éƒ¨åˆ†ï¼‰
            #     å¹¶å°†è¯¥bufferåŠ å…¥åˆ°compute_buffersåˆ—è¡¨ä¸­
            # è¿”å›ä¸¤ä¸ªåˆ—è¡¨ï¼š
            # ç¬¬ä¸€ä¸ªåˆ—è¡¨è£…ç€æ¯ä¸ªparamå¯¹åº”çš„compute_buffer(é•¿åº¦ä»…ä¸ºå½“å‰paramçš„å‚æ•°é‡)ï¼Œ
            # ç¬¬äºŒä¸ªåˆ—è¡¨è£…ç€æ¯ä¸€ä¸ªå¯¹åº”çš„swap_bufferï¼ˆå¯èƒ½åŒ…å«è¡¥é½çš„éƒ¨åˆ†ï¼‰
            compute_buffers, swap_in_buffers = self._allocate_and_return_buffers_for_swap_in(params)
            # è®¡ç®—è¿”å›çš„bufferèƒ½è£…çš„å‚æ•°é‡
            inflight_numel = sum([t.numel() for t in compute_buffers])
        else:
            inflight_numel = sum([t.numel() for t in swap_in_buffers])

        # 3.è°ƒç”¨C++å‡½æ•°æŠŠæ ¹æ®æŠŠè·¯å¾„æŠŠparaméƒ½æ‹¿åˆ°bufferä¸­
        swap_in_tensors(self.aio_read_handle, swap_in_buffers, swap_in_paths)

        # 4.å¯¹æ­£åœ¨è¯»å–çš„paramå’Œbufferè¿›è¡Œè¿½è¸ªï¼ˆå°±æ˜¯èµ‹ç»™ä¸€äº›selfæˆå‘˜å˜é‡ï¼‰,å¹¶å°†æ‰€æœ‰æ­£åœ¨è¯»å–çš„paramçš„çŠ¶æ€æ ‡è®°ä¸º INFLIGHT
        # å°†å‚æ•°åˆ—è¡¨åŠ åˆ°inflight_paramsä¸­ï¼Œè¡¨ç¤ºè¿™äº›å‚æ•°æ­£åœ¨è¯»å–
        # å°†buffersåŠ å…¥åˆ°inflight_swap_in_buffersåˆ—è¡¨ï¼ŒåŒç†
        # å°†æ­£åœ¨è¯»å–çš„å‚æ•°é‡èµ‹ç»™self.inflight_numel
        # 
        # å°†æ‰€æœ‰æ­£åœ¨è¯»å–çš„åˆ’åˆ†åçš„paramçš„çŠ¶æ€æ ‡è®°ä¸º INFLIGHT
        # è®°å½•æ­£åœ¨è¯»å–çš„å‚æ•°æ•°é‡
        self._update_inflight_swap_in(params, swap_in_buffers, inflight_numel)

        if not async_op:
            # 1.ç­‰å¾…æ­£åœ¨ä»nvmeè¯»æ•°æ®çš„çº¿ç¨‹å…¨éƒ¨å®Œæˆ
            # 2.å°†ä¸Šé¢åˆšåˆšå®Œæˆè¯»å–çš„é‚£äº›paramçš„ param.ds_tensor.data æŒ‡å‘å¯¹åº”çš„ buffer(åˆšåˆšè¯»åˆ°bufferé‡Œäº†)ã€‚
            #   å¹¶å°† param.ds_tensor.status è®¾ç½®ä¸º AVAILABLE
            # 3.å°†ä¸Šé¢åˆšæ‰§è¡Œå®Œçš„å‚æ•°çš„ds_idæ·»åŠ åˆ°å¯ç”¨å‚æ•°é›†åˆä¸­(å¯ç”¨è¯´çš„æ˜¯ds_tensorå¯ç”¨äº†)ã€‚
            #   æ¸…ç©ºè¿½è¸ªçš„å˜é‡ï¼ˆè¿½è¸ªæ­£åœ¨è¯»å–çš„å‚æ•°çš„ç›¸å…³ä¿¡æ¯ï¼‰
            self.synchronize_reads()

    # ğŸ“å°†nvmeçš„æ•°æ®è¯»å–åˆ°pinned bufferä¸Šï¼Œå‡†å¤‡é€ç»™GPU
    def swap_in_2(self, layer_id, layer_idx, param_idx, async_op=True):
        print(f"rank:{self.rank} å‡†å¤‡è·å–layer{layer_id}çš„æ–‡ä»¶è·¯å¾„", flush=True)
        swap_in_path = self._get_swap_paths_2(layer_id, param_idx)
        print(f"rank:{self.rank} æƒ³è¦è¯»å–çš„layer{layer_id}çš„æ–‡ä»¶è·¯å¾„ä¸º:{swap_in_path}", flush=True)

        compute_buffer, swap_in_buffer = self._allocate_and_return_buffers_for_swap_in_2(layer_idx, param_idx)
        print(f"rank:{self.rank}, pinned bufferåˆ†é…å®Œæˆ", flush=True)
        # è®¡ç®—è¿”å›çš„bufferèƒ½è£…çš„å‚æ•°é‡
        inflight_numel = compute_buffer.numel()

        swap_in_tensors(self.aio_read_handle, [swap_in_buffer], [swap_in_path])
        self.pending_reads += 1

        #
        if not async_op:
            print(f"rank:{self.rank}, å¼€å§‹syncè¯»å–", flush=True)
            self.synchronize_reads_2()
            print(f"rank:{self.rank}, syncç»“æŸ", flush=True)

    # åŒæ­¥è¯»å–ï¼Œä½¿ç”¨sync_preadæ–¹æ³•ï¼Œæœ‰çº¿ç¨‹
    def swap_in_2_sync(self, layer_id, layer_idx, param_idx):
        swap_in_path = self._get_swap_paths_2(layer_id, param_idx)
        compute_buffer, swap_in_buffer = self._allocate_and_return_buffers_for_swap_in_2(layer_idx, param_idx)
        swap_in_tensors_sync(self.aio_read_handle, [swap_in_buffer], [swap_in_path])
        print(f"rank:{self.rank}, åŒæ­¥è¯»å–{layer_id}-{param_idx}å®Œæˆ", flush=True)

    # çœŸæ­£çš„åŒæ­¥è¯»å–ï¼Œä½¿ç”¨readæ–¹æ³•ï¼Œæ²¡æœ‰çº¿ç¨‹
    def swap_in_2_sync_2(self, layer_id, layer_idx, param_idx):
        swap_in_path = self._get_swap_paths_2(layer_id, param_idx)
        compute_buffer, swap_in_buffer = self._allocate_and_return_buffers_for_swap_in_2(layer_idx, param_idx)
        swap_in_tensors_sync_2(self.aio_read_handle, [swap_in_buffer], [swap_in_path])
        print(f"rank:{self.rank}, åŒæ­¥è¯»å–{layer_id}-{param_idx}å®Œæˆ", flush=True)

    # ğŸ“2
    def swap_in_transformer_layer(self, layer_id, layer_idx, async_op=True):
        print(f"rank:{self.rank} å‡†å¤‡è·å–layer{layer_id}çš„æ–‡ä»¶è·¯å¾„", flush=True)
        swap_in_path = self._get_transformer_layer_swap_paths(layer_id)
        print(f"rank:{self.rank} æƒ³è¦è¯»å–çš„layer{layer_id}çš„æ–‡ä»¶è·¯å¾„ä¸º:{swap_in_path}", flush=True)

        compute_buffer, swap_in_buffer = self._return_buffer_for_transformer_layer(layer_idx)
        print(f"rank:{self.rank}, pinned bufferåˆ†é…å®Œæˆ", flush=True)
        # è®¡ç®—è¿”å›çš„bufferèƒ½è£…çš„å‚æ•°é‡
        inflight_numel = compute_buffer.numel()

        swap_in_tensors(self.aio_read_handle, [swap_in_buffer], [swap_in_path])
        self.pending_reads += 1

        #
        if not async_op:
            print(f"rank:{self.rank}, å¼€å§‹syncè¯»å–", flush=True)
            self.synchronize_reads_2()
            print(f"rank:{self.rank}, syncç»“æŸ", flush=True)
    
    # ğŸ“2.åŒæ­¥è¯»å–transformer layerï¼Œåº•å±‚C++åº“ä¸ä¼šæ”¾åˆ°çº¿ç¨‹ä¸­ï¼Œè€Œæ˜¯ç›´æ¥æ‰§è¡Œ
    def swap_in_transformer_layer_sync(self, layer_id, layer_idx):
        swap_in_path = self._get_transformer_layer_swap_paths(layer_id)
        compute_buffer, swap_in_buffer = self._return_buffer_for_transformer_layer(layer_idx)
        swap_in_tensors_sync_2(self.aio_read_handle, [swap_in_buffer], [swap_in_path])
        print(f"rank:{self.rank}, åŒæ­¥è¯»å–{layer_id}å®Œæˆ", flush=True)

    # ğŸ“3.åŒbufferç‰ˆæœ¬
    def swap_in_transformer_layer_double_buffer(self, buffer_id, layer_id, layer_idx, async_op=True):
        swap_in_path = self._get_transformer_layer_swap_paths(layer_id)
        compute_buffer, swap_in_buffer = self._return_buffer_for_transformer_layer_double_buffer(buffer_id, layer_idx)
        swap_in_tensors(self.aio_read_handle, [swap_in_buffer], [swap_in_path])
        self.pending_reads += 1

        if not async_op:
            self.synchronize_reads_2()

    # ğŸ“3.åŒbufferç‰ˆæœ¬
    def swap_in_transformer_layer_double_buffer_sync(self, buffer_id, layer_id, layer_idx):
        swap_in_path = self._get_transformer_layer_swap_paths(layer_id)
        compute_buffer, swap_in_buffer = self._return_buffer_for_transformer_layer_double_buffer(buffer_id, layer_idx)
        swap_in_tensors_sync_2(self.aio_read_handle, [swap_in_buffer], [swap_in_path])

    # Enables swapping into buffer that is out the control of swapper. This is always synchronous
    def swap_into_buffer(self, param, dest_buffer):
        assert param.ds_tensor.status == PartitionedParamStatus.NOT_AVAILABLE, f"param {param.ds_id} is already available or inflight"

        require_swap_buffer = not (get_accelerator().is_pinned(dest_buffer)
                                   and self._is_io_aligned(dest_buffer.numel()))

        if require_swap_buffer:
            assert len(self.available_buffer_ids) > 0, f"No buffer available to swap param {param.ds_id}."
            compute_buffers, swap_in_buffers = self._allocate_and_return_buffers_for_swap_in([param])
            inflight_numel = compute_buffers[0].numel()
        else:
            swap_in_buffers = [dest_buffer]
            inflight_numel = dest_buffer.numel()

        swap_in_paths = self._get_swap_paths([param])

        swap_in_tensors(self.aio_read_handle, swap_in_buffers, swap_in_paths)
        self._update_inflight_swap_in([param], swap_in_buffers, inflight_numel)
        self.synchronize_reads()

        if require_swap_buffer:
            dest_buffer.data.copy_(param.ds_tensor.data)
            # Release swap buffer memory assignment. Note, this will mark the parameter not available.
            self.remove_partition_and_release_buffers([param])

    #assign a buffer to a param and return the buffer
    # ä¸ºå½“å‰paramç¡®å®šbuffer
    # 1.å»ºç«‹param_idåˆ°numelçš„æ˜ å°„
    # 2.buffer_id = self.available_buffer_ids.pop()ï¼Œè€Œåå»ºç«‹param_idåˆ°buffer_idçš„æ˜ å°„
    # 3.å°†æˆªå–å‡ºçš„å¯¹åº”å½“å‰Paramçš„bufferï¼ˆå°±æ˜¯ä¸€ä¸ªå¤§tensorçš„ä¸€éƒ¨åˆ†ï¼Œå³ä¸€ä¸ªnarrowçš„ç»“æœï¼‰åŠ å…¥åˆ°param_id_to_swap_bufferçš„æ˜ å°„
    # 4.è¿›ä¸€æ­¥æˆªå–å‡ºå½“å‰paraméœ€è¦çš„éƒ¨åˆ†ï¼Œè€Œä¸æ˜¯ä¸Šä¸€æ­¥æˆªå–å‡ºçš„ä¸€æ•´ä¸ªbufferã€‚ï¼ˆä¸Šä¸€æ­¥æˆªå–çš„bufferå¯èƒ½åŒ…å«äº†è¡¥é½çš„éƒ¨åˆ†ï¼‰
    # ğŸ“Œæ³¨æ„è¿™ä¸ªbufferçš„é•¿åº¦ä»…ä»…æ˜¯å‚æ•°åˆ’åˆ†åçš„é•¿åº¦
    def get_buffer(self, param, numel):
        param_id = param.ds_id

        assert self.available_swap_in_buffers(
        ) > 0, f"No swap buffers to allocate for fp16 param {param_id} of numel = {numel}"
        assert numel < self.elements_per_buffer, f"More elements {numel} than buffer size {self.elements_per_buffer}"

        self.param_id_to_numel[param_id] = numel
        # åˆ—è¡¨æœ€åä¸€ä¸ªå…ƒç´ å‡ºé˜Ÿ
        buffer_id = self.available_buffer_ids.pop()
        # å»ºç«‹å½“å‰paramåˆ°buffer_idï¼ˆå³åˆšå‡ºé˜Ÿçš„buffer_idï¼‰çš„æ˜ å°„å…³ç³»
        self.param_id_to_buffer_id[param_id] = buffer_id
        # è‹¥å½“å‰paramçš„å…ƒç´ æ•°é‡èƒ½è¢« å¯¹é½å…ƒç´ æ•°é‡ æ•´æ¨¡ï¼Œè¿”å›å…ƒç´ æ•°é‡ï¼›ä¸ç„¶è¿”å›è¡¥é½åçš„å…ƒç´ æ•°é‡
        aligned_swap_numel = self._io_aligned_numel(self.param_id_to_numel[param_id])
        # ä»å¤§bufferä¸­æˆªå–å‡ºå¯¹ç”¨å½“å‰buffer_idçš„ã€å¯¹åº”å½“å‰paramå…ƒç´ æ•°é‡çš„éƒ¨åˆ†ï¼ˆå¯èƒ½è¢«è¡¥é½äº†ï¼‰
        # narrow(dim, start, length)
        # - dim: è¦åˆ‡ç‰‡çš„ç»´åº¦
        # - start: åˆ‡ç‰‡çš„èµ·å§‹ç´¢å¼•
        # - length: åˆ‡ç‰‡çš„é•¿åº¦
        swap_buffer = self.buffers.narrow(0, int(buffer_id * self.aligned_elements_per_buffer), aligned_swap_numel)

        # å°†æˆªå–å‡ºçš„å¯¹åº”å½“å‰Paramçš„bufferï¼ˆå¯è§å°±æ˜¯ä¸€ä¸ªå¤§tensorçš„ä¸€éƒ¨åˆ†ï¼Œå³ä¸€ä¸ªnarrowçš„ç»“æœï¼‰åŠ å…¥åˆ°param_id_to_swap_bufferçš„æ˜ å°„
        self.param_id_to_swap_buffer[param_id] = swap_buffer
        # è¿›ä¸€æ­¥æˆªå–å‡ºå½“å‰paraméœ€è¦çš„éƒ¨åˆ†ï¼Œè€Œä¸æ˜¯è¿™ä¸€æ•´ä¸ªbuffer
        compute_buffer = swap_buffer.narrow(0, 0, self.param_id_to_numel[param_id])
        print_rank_0(f"param {param.ds_id} is assigned swap in buffer id {buffer_id}")
        return compute_buffer

    # ğŸ“
    def get_buffer(self, layer_idx, param_idx):
        start_pos = self.pinned_buffer_information.get_layer_start_pos_in_buffers(layer_idx)
        buffer_size = self.pinned_buffer_information.get_buffer_size()
        param_start_pos = self.pinned_buffer_information.get_param_start_pos(param_idx)
        param_size = self.pinned_buffer_information.get_param_size(param_idx)
        buffer = self.buffers.narrow(0, start_pos, buffer_size)
        compute_buffer = buffer.narrow(0, param_start_pos, param_size)
        return compute_buffer
    


    def reserve_available_buffers(self):
        buffers = []
        for id in self.available_buffer_ids:
            buffers.append(
                self.buffers.narrow(0, int(id * self.aligned_elements_per_buffer),
                                    int(self.aligned_elements_per_buffer)))
            self.reserved_buffer_ids.append(id)

        self.available_buffer_ids = []
        return buffers

    def release_reserved_buffers(self):
        for id in self.reserved_buffer_ids:
            self.available_buffer_ids.append(id)
        self.reserved_buffer_ids = []

    # numelï¼šä¸€ä¸ªbufferçš„å¤§å°
    # è‹¥å…ƒç´ æ•°é‡èƒ½è¢« å¯¹é½å…ƒç´ æ•°é‡ æ•´æ¨¡ï¼Œè¿”å›å…ƒç´ æ•°é‡ï¼›ä¸ç„¶è¿”å›è¡¥é½åçš„å…ƒç´ æ•°é‡
    def _io_aligned_numel(self, numel):
        # å…ƒç´ æ•°é‡ % å¯¹é½å…ƒç´ æ•°é‡
        remainder = numel % self.numel_alignment
        return numel if remainder == 0 else (numel + self.numel_alignment - remainder)

    def _is_io_aligned(self, numel):
        return (numel % self.numel_alignment) == 0

    # 1.è®¡ç®—æ‰€æœ‰paramè¡¥é½åçš„ æ€»å‚é‡
    # 2.åœ¨cpuä¸Šåˆ›å»ºä¸€ä¸ªå›ºå®šçš„è¿ç»­çš„ç¼“å†²åŒºï¼Œç”¨äºswap
    # 3.ä½¿ç”¨åˆšåˆšåˆ›å»ºçš„ç¼“å†²åŒºï¼Œå®ä¾‹åŒ–ä¸€ä¸ª SwapBufferPool ç±»ï¼Œä¹‹åé€šè¿‡è¯¥ç±»ç®¡ç†ç¼“å†²åŒº
    def reserve_partitioned_swap_space(self, partition_num_elems):
        # è®¡ç®—æ‰€æœ‰paramè¡¥é½åçš„ æ€»å‚é‡
        aligned_numel = sum([self._io_aligned_numel(numel) for numel in partition_num_elems])
        # åœ¨cpuä¸Šåˆ›å»ºä¸€ä¸ªå›ºå®šçš„è¿ç»­çš„ç¼“å†²åŒºï¼Œç”¨äºswap
        self.partitioned_swap_buffer = get_accelerator().pin_memory(torch.zeros(aligned_numel,
                                                                                device='cpu',
                                                                                dtype=self.dtype),
                                                                    align_bytes=0)
        # ä½¿ç”¨åˆšåˆšåˆ›å»ºçš„ç¼“å†²åŒºï¼Œå®ä¾‹åŒ–ä¸€ä¸ª SwapBufferPool ç±»ï¼Œä¹‹åé€šè¿‡è¯¥ç±»ç®¡ç†ç¼“å†²åŒº
        self.partitioned_swap_pool = SwapBufferPool([self.partitioned_swap_buffer])

    # src_fp32_paramsï¼šè¦å†™å…¥nvmeçš„param list
    # æŠŠfp32 paramså†™å…¥åˆ°fp16 paramså¯¹åº”çš„åœ°å€ä¸Šï¼ˆnvmeï¼‰
    def swap_out_partitioned_params(self, dst_fp16_params, src_fp32_params):
        assert self.partitioned_swap_buffer is not None, f'partitioned swap buffers for fp16 params not initialized'
        assert self.partitioned_swap_pool is not None, f'partitioned swap pool for fp16 params not initialized'
        assert len(dst_fp16_params) == len(src_fp32_params), \
        f'mismatch in number of fp16 params {len(dst_fp16_params)} and fp32 params {len(src_fp32_params)}'

        # å¾—åˆ°fp16 paramså¯¹åº”çš„pathå¹¶è¿”å›ã€‚è‹¥å½“å‰paramçš„è·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ª
        fp16_swap_paths = self._get_swap_paths(dst_fp16_params, must_exist=True)
        self.synchronize_writes()
        # å¯¹buffer poolä¸­çš„æ¯ä¸€ä¸ªbufferï¼Œæ‰§è¡Œreset()ï¼Œå°±æ˜¯æŠŠæ‰€æœ‰çš„æˆå‘˜å˜é‡å…¨éƒ¨æ¸…ç©ºï¼Œå½“ç„¶bufferæ²¡åˆ 
        self.partitioned_swap_pool.reset()
        # å°† src_fp32_params ä¸­çš„ tensor éƒ½æ”¾è¿›buffer poolä¸­
        # å¹¶å°†å¯¹åº”çš„fp16 paramçš„ds_tensorçš„çŠ¶æ€ç½®ä¸º AVAILABLE
        for i, fp32_tensor in enumerate(src_fp32_params):
            # è‹¥buffer poolè¿˜èƒ½è£…ä¸‹paddingåçš„tensorï¼ˆå­˜åœ¨ä¸€ä¸ªèƒ½è£…ä¸‹çš„bufferï¼‰ï¼š
            # 1.æ ¹æ®ç»™å®šçš„ å‚æ•°é‡ å’Œ paddingåçš„å‚æ•°é‡ åˆ†é…buffer
            #   è¿”å› buffer å’Œ ä¸åŒ…å«paddingéƒ¨åˆ†çš„ buffer (æœ¬è´¨ä¸Šæ˜¯åŒä¸€ä¸ªbufferï¼Œåªæ˜¯é•¿åº¦ä¸åŒ)
            # 2.å°†ç»™å®šçš„ tensorï¼ˆfp32_tensorï¼‰å¤åˆ¶åˆ°bufferä¸­
            # 3.è¿”å›ä¸Šé¢ä¸¤ä¸ªbuffer
            # ä¼ å…¥çš„åœ°å€ä¼šè¢«æ”¾å…¥bufferçš„å­—å…¸ä¸­å­˜èµ·æ¥
            swap_tensor, _ = self.partitioned_swap_pool.insert_tensor(fp32_tensor, fp16_swap_paths[i],
                                                                      self._io_aligned_numel(fp32_tensor.numel()))
            assert swap_tensor is not None
            dst_fp16_params[i].ds_tensor.status = PartitionedParamStatus.AVAILABLE

        # å°†buffer poolä¸­è£…çš„tensoréƒ½å¸è½½åˆ°nvmeä¸­
        # 1.è¿”å›æ‰€æœ‰ä½¿ç”¨ä¸­çš„bufferä¸­ä¿å­˜çš„tensorï¼ˆæœ¬è´¨æ˜¯buffer narrowå‡ºæ¥çš„ï¼Œå³bufferçš„ä¸€éƒ¨åˆ†ï¼‰ï¼›
        #   è¿”å›æ‰€æœ‰ä½¿ç”¨ä¸­çš„bufferä¸­ä¿å­˜çš„path
        # 2.ä½¿ç”¨swap_handleç±»ï¼Œå¼‚æ­¥çš„å°†bufferå†™å…¥åˆ°æŒ‡å®šçš„åœ°å€
        # 3.è‹¥æ²¡è®¾ç½®å¼‚æ­¥æ“ä½œï¼Œç­‰å¾…å¼‚æ­¥æ“ä½œå®Œæˆ
        # å†™å…¥çš„åœ°å€åœ¨è°ƒç”¨insert_tensoræ—¶å·²ç»å­˜å¥½äº†
        self.partitioned_swap_pool.swap_out(self.aio_write_handle)

        # å°†fp16 paramçš„ds_tensorçš„çŠ¶æ€ç½®ä¸º NOT_AVAILABLE
        for param in dst_fp16_params:
            param.ds_tensor.status = PartitionedParamStatus.NOT_AVAILABLE
