# Copyright (c) Microsoft Corporation.
# Licensed under the MIT license.

from collections import OrderedDict as ODict
import numpy as np
import random
from collections import deque

import sys; sys.path.append("../2_profiler")
from prof_data_struct import *
from analyze_profiles import time_of_pack, memory_of_pack, model_size_of_pack

from task_data_struct import Medium, vTask

# â“åˆ°åº•æ˜¯å•¥æ„æ€ï¼Œä¸æ‡‚
# å·²æ‡‚
# è¿”å›taskçš„æœ€åä¸€ä¸ªsubpack idï¼Œå³ä¸€ä¸ªtaskåŒ…å«å¤šå±‚ï¼Œè‹¥è¦ä¿å­˜å…¶ä¸­å¤šä¸ªå±‚çš„è¾“å…¥Xï¼Œåˆ™ä»æ¯ä¸ªå¯¹åº”çš„å±‚å¼€å§‹çš„ä¸€äº›å±‚è¢«ç§°ä¸ºsubpack
# å¯¹å‰å‘ä»»åŠ¡ï¼Œè¯¥å€¼å¯èƒ½éœ€è¦è¿›è¡Œè®¡ç®—ã€‚å¯¹äºBWDå’ŒUPDä»»åŠ¡ï¼Œè¿”å›çš„æ°¸è¿œæ˜¯0
def find_last_subpack_idx(vt):
    # è‹¥æ˜¯å‰å‘ä»»åŠ¡ï¼Œä¸”ä»»åŠ¡çš„Outä¸­çš„Xæ²¡æœ‰å€¼ï¼Œspi=0ã€‚
    if vt.type == "FWD":
        if not vt.Out['X']:
            spi = 0
        else:
            # spi=Out['X']é”®å€¼å¯¹çš„æ•°é‡
            spi = len(vt.Out['X'].keys()) + 1 - 1
            # è‹¥Out['X']çš„keyå°±æ˜¯è¯¥vtçš„ç¬¬ä¸€å±‚ï¼Œspi-=1
            # ğŸ“Œä¸ºä»€ä¹ˆ-1ï¼šå› ä¸ºä¸‹æ ‡ä»0å¼€å§‹ï¼Œ-1å¾—åˆ°çš„spiå°±æ˜¯æœ€åä¸€ä¸ªsubpackçš„ä¸‹æ ‡ï¼Œ
            #    è‹¥vtçš„ç¬¬0å±‚ä¸å‘é€StashXï¼Œé‚£ä¹ˆspiè¿™ä¸ªä¸‹æ ‡å€¼ä¹Ÿä¸ç”¨å˜ï¼Œå› ä¸ºåœ¨ find_subpack_layers ä¸­ï¼Œ
            #    vtçš„ç¬¬0å±‚ä¼šè¢«æ·»åŠ åˆ°subpackçš„åˆ—è¡¨çš„é¦–ä½ï¼Œspiçš„ä¸‹æ ‡ä¾ç„¶æ˜¯æ­£ç¡®çš„
            #    ğŸ“Œæ¢å¥è¯è¯´ï¼Œæ— è®ºå‘ä¸å‘vté¦–å±‚çš„æ¥æ”¶åˆ°çš„è¾“å…¥Xï¼Œéƒ½é»˜è®¤è¯¥vtçš„é¦–ä¸ªsubpackå°±æ˜¯ä»é¦–å±‚å¼€å§‹çš„å‡ å±‚
            if vt.layers[0] in vt.Out['X']:
                spi -= 1

    # å¯¹äºBWDå’ŒUPDä»»åŠ¡ï¼Œspiæ°¸è¿œ=0
    else: # "BWD", "UPD"
        spi = 0
    assert spi >= 0
    return spi

# è¿”å›ï¼švtçš„æºtaskï¼Œä»¥åŠvtçš„é¦–å±‚åœ¨æºä»»åŠ¡ä¸­å¯¹åº”çš„subpack idx
def find_stash_subpack_idx(vt, TASKS):
    l, m = vt.layers[0], vt.In['X'][vt.layers[0]]; assert m.medium == "MSG"
    src_vt = TASKS[m.idx]; assert src_vt.idx == m.idx, "TASKS should be global"
    layers_stash = list(src_vt.Out['X'].keys())
    # è¿”å›vtçš„é¦–å±‚åœ¨layers_stashä¸­çš„ä¸‹æ ‡ï¼Œå¹¶+1
    src_spi = layers_stash.index(l) + 1
    # è‹¥æºtaskçš„é¦–å±‚å­˜åœ¨äº layers_stashåˆ—è¡¨ä¸­ï¼Œsrc_spi-1
    if src_vt.layers[0] in layers_stash:
        src_spi -= 1
    assert src_spi >= 0
    return src_vt, src_spi

# è¿”å›BWD vtå¯¹åº”çš„src_taskï¼Œå³å‘é€stashXçš„FWD vtï¼Œå’Œsrc_taskçš„æœ€åä¸€ä¸ªsubpack_idxï¼ˆç”¨äºåœ¨ç”±å„ä¸ªsubpacké¦–å±‚ç»„æˆçš„listä¸­å–å€¼ï¼‰
# ğŸ“Œä¸ºä»€ä¹ˆè¿”å›æœ€åä¸€ä¸ªsubpackçš„idï¼Œå› ä¸ºè¿™æ„å‘³ç€
def find_output_subpack_idx(vt, TASKS):
    l, m = vt.layers[0], vt.In['X'][vt.layers[0]]; assert m.medium == "MSG"
    # æºä»»åŠ¡(src_task)çš„idx
    src_vt = TASKS[m.idx]; assert src_vt.idx == m.idx, "TASKS should be global"
    # 
    src_spi = find_last_subpack_idx(src_vt)
    return src_vt, src_spi

def find_subpack_layers(vt, spi):
    if vt.type == "FWD":
        if not vt.Out['X']:
            assert spi == 0
            layers = vt.layers
        else:
            assert spi >= 0
            # åŠ ä¸Š[vt.layers[-1]+1]æ˜¾ç„¶æ˜¯ä¸ºäº†ä¸‹é¢çš„range(start, stop)å‡†å¤‡çš„ï¼Œ[vt.layers[-1]+1å°±æ˜¯é‚£ä¸ªstop
            layers_stash = list(vt.Out['X'].keys()) + [vt.layers[-1]+1]
            # è‹¥Out['X']ä¸­ä¸åŒ…å«è¯¥vtçš„é¦–å±‚ï¼Œè¿˜éœ€å°†é¦–å±‚åŠ å…¥åˆ°layers_stashåˆ—è¡¨ä¸­
            if vt.layers[0] not in layers_stash:
                layers_stash = [vt.layers[0]] + layers_stash
            # range(start, stop)
            layers = list(range(layers_stash[spi], layers_stash[spi+1]))
    else: # "BWD", "UPD"
        assert spi == 0
        layers = vt.layers
    return layers

class Event(object):
    def __init__(self, vt, ui, spi, stream, kind, ubs=None):
        self.vt = vt # affiliated vtask
        self.ui = ui # affiliated ubatch index
        self.spi = spi # affiliated subpack index
        self.stream = stream # "SwapIn"/"P2PIn"/"Compute" # for per-stream event queue
        self.kind = kind # "W"/"X"/"Y"/"FWD"/"BWD"
        # five tuple as id
        self.id = "%d.%d.%d.%s.%s"%(self.vt.idx, self.ui, self.spi, self.stream, self.kind)
        # microbatch size
        if ubs is None:
            self._find_ubs() # self.ubs = None or 2
        else:
            self.ubs = int(ubs) # override for MSG
        # subpack as event layers
        self._find_layers() # self.layers = [1] or [1,2,3]
        # dependency
        self.inputs = [] # required input events from other streams
        self.is_done = False # whether executed
        # p2p
        self.peer_id = None # peer event id
        self.pos = None # position idx in event queue
        # exec
        self.begin = 0.0 # begin time in sec
        self.dur = 0.0 # duration time in sec

    def _find_ubs(self):
        if self.kind in ["WB","DEL","ARD","dWB","Update"]:
            self.ubs = None
        elif self.kind in ["FWD","REC","BWD","sX","MSGsX","X","dX","MSGdX","Y","dY","MSGY"]:
            self.ubs = self.vt.ubatchszs[self.ui]
        else:
            raise NotImplementedError

    def _find_layers(self):
        if self.kind in ["WB","REC","BWD","DEL","ARD","dWB","Update"]:
            assert self.spi == 0
            self.layers = self.vt.layers
        elif self.kind in ["FWD"]:
            self.layers = find_subpack_layers(self.vt, self.spi)
        elif self.kind in ["sX","MSGsX"]:
            self.layers = [find_subpack_layers(self.vt, self.spi)[0]]
        elif self.kind in ["X","dX","MSGdX"]:
            assert self.spi == 0
            self.layers = [self.vt.layers[0]]
        elif self.kind in ["Y","dY","MSGY"]:
            assert self.spi >= 0
            self.layers = [self.vt.layers[-1]]
        else:
            raise NotImplementedError
            
    # ä¸ºinputså±æ€§æ·»åŠ ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œä»£è¡¨å½“å‰Eventéœ€è¦çš„ï¼ˆå…¶ä»–steamsçš„ï¼‰è¾“å…¥Event
    def inputs_add(self, vt, ui, spi, stream, kind):
        idx = vt.idx # if isinstance(vt, vTask) else vt
        # è¿”å›spiï¼ˆsubpack indexï¼‰ï¼Œå¯¹å‰å‘ä»»åŠ¡ï¼Œè¯¥å€¼å¯èƒ½éœ€è¦è¿›è¡Œè®¡ç®—ã€‚å¯¹BWDå’ŒUPDä»»åŠ¡ï¼Œè¿”å›çš„æ°¸è¿œæ˜¯0
        spi = find_last_subpack_idx(vt) if spi == -1 else spi
        # å°†è¾“å…¥å‚æ•°ç»„æˆä¸€ä¸ªå­—ç¬¦ä¸²åŠ å…¥åˆ°è°ƒç”¨è¯¥å‡½æ•°çš„Eventçš„inputså±æ€§ä¸­ï¼Œä»£è¡¨å½“å‰Eventéœ€è¦çš„ï¼ˆå…¶ä»–steamsçš„ï¼‰è¾“å…¥Event
        self.inputs.append("%d.%d.%d.%s.%s"%(idx, ui, spi, stream, kind))

    # å°†å‚æ•°evæ·»åŠ åˆ°è°ƒç”¨è¯¥å‡½æ•°çš„eventçš„inputsåˆ—è¡¨ä¸­
    def inputs_add_ev(self, ev):
        assert isinstance(ev, Event)
        self.inputs.append(ev)
            
    # 1.å°†è°ƒç”¨è¯¥æ–¹æ³•çš„Eventå®ä¾‹ï¼Œæ·»åŠ åˆ°eventsè¿™ä¸ªå­—å…¸ä¸­ã€‚{ id: Event() } 
    # 2.å°†Eventæ·»åŠ åˆ° self.stream è¿™ç§ç±»å‹çš„äº‹ä»¶é˜Ÿåˆ—ä¸­ã€‚per_stream_eventsï¼š{stream: [Event()]}
    # 3.å¯¹Eventçš„poså±æ€§(åœ¨é˜Ÿåˆ—ä¸­çš„ä¸‹æ ‡)èµ‹å€¼ï¼Œå³é˜Ÿåˆ—çš„æœ€åä¸€ä¸ªä½ç½®
    def add_to(self, events, per_stream_events):
        # å°†è°ƒç”¨è¯¥æ–¹æ³•çš„Eventå®ä¾‹ï¼Œæ·»åŠ åˆ°eventsè¿™ä¸ªå­—å…¸ä¸­ã€‚{ id: Event() } 
        events[self.id] = self
        # è‹¥Event.streamä¸åœ¨per_stream_eventsè¿™ä¸ªå­—å…¸ä¸­ï¼Œåœ¨å­—å…¸ä¸­æ·»åŠ é”®å€¼å¯¹ {self.streamï¼šdeque }
        if self.stream not in per_stream_events:
            per_stream_events[self.stream] = deque([])
        # å°†Eventæ·»åŠ åˆ° self.stream è¿™ç§ç±»å‹çš„äº‹ä»¶é˜Ÿåˆ—ä¸­
        per_stream_events[self.stream].append(self)
        # å¯¹Eventçš„poså±æ€§(åœ¨é˜Ÿåˆ—ä¸­çš„ä¸‹æ ‡)èµ‹å€¼ï¼Œå³é˜Ÿåˆ—çš„æœ€åä¸€ä¸ªä½ç½®
        self.pos = len(per_stream_events[self.stream])-1

    # å°†å¯¹åº”çš„é‚£ä¸ªp2pä»»åŠ¡ä»¥å­—ç¬¦ä¸²çš„å½¢å¼èµ‹ç»™è°ƒç”¨è¯¥å‡½æ•°çš„eventçš„peer_idå±æ€§
    def register_peer(self, TASKS, ui, spi, stream, kind):
        """ register the peer Event ID """
        assert self.peer_id is None, "only one peer"
        # find peer vt
        if stream == "P2PIn":
            assert self.stream == "P2POut"
            if kind == "dY":
                m = self.vt.Out['dX'][self.vt.layers[0]]   
            elif kind == "X":
                m = self.vt.Out['Y'][self.vt.layers[-1]]
            else:
                raise ValueError
            assert m.medium == "P2P"
        elif stream == "P2POut":
            assert self.stream == "P2PIn"
            if kind == "Y":
                m = self.vt.In['X'][self.vt.layers[0]]
            elif kind == "dX":
                m = self.vt.In['dY'][self.vt.layers[-1]]
            else:
                raise ValueError
            assert m.medium == "P2P"
        else:
            raise ValueError
        # å³å¯¹åº”å½“å‰ä»»åŠ¡çš„é‚£ä¸ªä»»åŠ¡
        peer_vt = TASKS[m.idx]; assert peer_vt.idx == m.idx, "TASKS is global"
        
        idx = peer_vt.idx
        # è¿”å›taskçš„æœ€åä¸€ä¸ªsubpack idï¼Œå³ä¸€ä¸ªtaskåŒ…å«å¤šå±‚ï¼Œè‹¥è¦ä¿å­˜å…¶ä¸­å¤šä¸ªå±‚çš„è¾“å…¥Xï¼Œåˆ™ä»æ¯ä¸ªå¯¹åº”çš„å±‚å¼€å§‹çš„ä¸€äº›å±‚è¢«ç§°ä¸ºsubpack
        # å¯¹å‰å‘ä»»åŠ¡ï¼Œè¯¥å€¼å¯èƒ½éœ€è¦è¿›è¡Œè®¡ç®—ã€‚å¯¹äºBWDå’ŒUPDä»»åŠ¡ï¼Œè¿”å›çš„æ°¸è¿œæ˜¯0
        spi = find_last_subpack_idx(peer_vt) if spi == -1 else spi
        # å°†å¯¹åº”çš„é‚£ä¸ªp2pä»»åŠ¡ä»¥å­—ç¬¦ä¸²çš„å½¢å¼èµ‹ç»™è°ƒç”¨è¯¥å‡½æ•°çš„eventçš„peer_idå±æ€§
        self.peer_id = "%d.%d.%d.%s.%s"%(idx, ui, spi, stream, kind)

    # 1.å°†å½“å‰äº‹ä»¶å¯¹åº”çš„P2Päº‹ä»¶çš„æ‰€æœ‰ä¾èµ–åŠ å…¥åˆ°å½“å‰äº‹ä»¶çš„ä¾èµ–ä¸­
    # 2.è‹¥å¯¹åº”çš„P2Päº‹ä»¶ä¸æ˜¯å…¶æ‰€åœ¨streamä¸­çš„ç¬¬1ä¸ªäº‹ä»¶ï¼Œè¿˜éœ€å°†P2Pæ‰€åœ¨çš„rankçš„streamä¸­çš„å‰ä¸€ä¸ªäº‹ä»¶åŠ å…¥åˆ°å½“å‰äº‹ä»¶çš„ä¾èµ–ä¸­
    # 3.æ¸…ç©ºå½“å‰äº‹ä»¶Inputsä¸­çš„é‡å¤ä¾èµ–ï¼Œå¹¶æŒ‰ç…§idè¿›è¡Œæ’åº
    def solve_peer(self, events, rank_stream_events):
        """ add peer's inputs and its previous stream Event to my inputs """
        if self.peer_id is None:
            return
        # è¿”å›å¯¹åº”çš„P2Päº‹ä»¶
        peer = events[self.peer_id]
        # å°†å¯¹åº”çš„P2Päº‹ä»¶çš„æ‰€æœ‰ä¾èµ–åŠ å…¥åˆ°å½“å‰äº‹ä»¶çš„ä¾èµ–ä¸­
        self.inputs += peer.inputs 
        # è‹¥å¯¹åº”çš„P2Päº‹ä»¶ä¸æ˜¯å…¶æ‰€åœ¨streamä¸­çš„ç¬¬1ä¸ªäº‹ä»¶ï¼Œè¿˜éœ€å°†P2Pæ‰€åœ¨çš„rankçš„streamä¸­çš„å‰ä¸€ä¸ªäº‹ä»¶åŠ å…¥åˆ°å½“å‰äº‹ä»¶çš„ä¾èµ–ä¸­
        if peer.pos-1 >= 0:
            self.inputs.append( 
                rank_stream_events[peer.vt.rank][peer.stream][peer.pos-1] )
        # æ¸…ç©ºé‡å¤ä¾èµ–å¹¶è½¬åŒ–ä¸ºåˆ—è¡¨
        self.inputs = list(set(self.inputs)) # remove double counting
        # å¯¹inputsäº†åˆ—è¡¨æŒ‰ç…§idè¿›è¡Œæ’åº
        self.inputs = sorted(self.inputs, key=lambda e: e.id) # for result matching
             
    # è¿”å›äº‹ä»¶çš„ç»“æŸäº‹ä»¶ï¼ˆç§’ï¼‰
    @property
    def end(self): # end time in sec
        return self.begin + self.dur

    def show_layers(self):
        # assert list(range(self.layers[0], self.layers[-1]+1)) == list(self.layers)
        if len(self.layers) == 0:
            return "L--"
        elif len(self.layers) == 1:
            return "L%d" % (self.layers[0])
        else:
            return "L%d-%d" % (self.layers[0], self.layers[-1])
    def __str__(self):
        ### id, ubs, layers, [inputs ids], done
        ss = "%s, %s, %s, [%s], %s"%(
              self.id, 
              'U--' if self.ubs is None else 'U%d'%self.ubs,
              self.show_layers(),
              ",".join(inev.id for inev in self.inputs),
              "@%.3f_dur%.3f"%(self.begin, self.dur) if self.is_done else "-")
        return ss
    @property
    def name(self): # for display in chrome
        return "t{} {} {} {}".format(
                self.vt.idx, 
                '' if self.ubs is None else '#%d(%d)'%(self.ui, self.ubs),
                self.show_layers(), 
                self.kind)
        # return "t{} #{} {} {}".format(
        #         self.vt.idx, self.ui, self.show_layers(), self.kind)
        
# 
class UBSConverter(object):
    def __init__(self, ubatchszs_fwd, ubatchszs_bwd, u_bwd, verbose=True):
        """ examples: 
                [4,4,1], [4,4,1], 4
                [4,4,1], [2,2,2,2,1], 2
                [4,4,4,1], [3,3,3,3,1], 3
                [3,3,3,3,1], [4,4,4,1], 4
                [2,2,2,2,1], [4,4,1], 4
        """
        assert sum(ubatchszs_fwd) == sum(ubatchszs_bwd)
        self.ubatchszs_fwd = ubatchszs_fwd
        self.ubatchszs_bwd = ubatchszs_bwd
        self.u_bwd = u_bwd
        self.verbose = verbose
        # convertion
        # å°†ubatchszs_fwdä¸­æ¯ä¸ªufwdæŒ‰ç…§u_bwdçš„å¤§å°æ‹†åˆ†æˆä¸€ä¸ªtupleï¼Œæ¯ä¸ªå€¼éƒ½æ˜¯u_bwdï¼Œæœ€åä¸€ä¸ªæ•°å¯èƒ½æ˜¯ä½™æ•°ï¼ˆå®é™…ä¸Šåº”è¯¥ä¸ä¼šå‡ºç°ä½™æ•°ï¼‰
        # ğŸ“Œåˆ†æï¼šç»è¿‡find_ubatchsizeså‡½æ•°(searcher.py)ç­›é€‰çš„å‰åå‘ubsizeåº”è¯¥ä¸ä¼šå‡ºç°è¿™ç§æƒ…å†µã€‚ä¸¤è€…éƒ½æ˜¯
        #         æŸä¸ªç›¸åŒåº•æ•°çš„æ¬¡å¹‚ï¼Œéƒ½èƒ½è¢«minibatchsizeæ•´é™¤ï¼Œè¯´æ˜äº’ç›¸ä¹‹é—´ä¹Ÿæ˜¯å¯ä»¥æ•´é™¤çš„
        self._convert_ubatchsize()
        # é€ ufwd çš„å»ºç«‹ï¼Œè¯¥ ufwd æ‹†åˆ†çš„æ¯ä¸ª u_bwd çš„å…¨å±€ä¸‹æ ‡ï¼Œ[[0,1](ç¬¬0ä¸ªufwdçš„ä¸‹æ ‡list),[2,3],...]
        self._map_idx_ufwd_to_ubwd()
        self._map_idx_ubwd_to_ufwd()
            
    def _concat(self, Cs):
        return int(sum(Cs))
    def _split(self, C, U):
        assert isinstance(C, int) and isinstance(U, int)
        if C >= U:
            if C % U == 0:
                ubatchszs = [U] * int(C/U)
            else:
                ubatchszs = [U] * int(C/U) + [ C%U ]
            assert sum(ubatchszs) == C
        else: # not sufficient to split
            ubatchszs = [C]
        return tuple(ubatchszs)
    
    # å°†ubatchszs_fwdä¸­æ¯ä¸ªufwdæŒ‰ç…§u_bwdçš„å¤§å°æ‹†åˆ†æˆä¸€ä¸ªtupleï¼Œæ¯ä¸ªå€¼éƒ½æ˜¯u_bwdï¼Œæœ€åä¸€ä¸ªæ•°å¯èƒ½æ˜¯ä½™æ•°ï¼ˆå®é™…ä¸Šåº”è¯¥ä¸ä¼šå‡ºç°ä½™æ•°ï¼‰
    # ğŸ“Œåˆ†æï¼šç»è¿‡find_ubatchsizeså‡½æ•°(searcher.py)ç­›é€‰çš„å‰åå‘ubsizeåº”è¯¥ä¸ä¼šå‡ºç°è¿™ç§æƒ…å†µã€‚ä¸¤è€…éƒ½æ˜¯
    #         æŸä¸ªç›¸åŒåº•æ•°çš„æ¬¡å¹‚ï¼Œéƒ½èƒ½è¢«minibatchsizeæ•´é™¤ï¼Œè¯´æ˜äº’ç›¸ä¹‹é—´ä¹Ÿæ˜¯å¯ä»¥æ•´é™¤çš„
    def _convert_ubatchsize(self):
        """ given ubatchszs, return per-ufwd converted list """
        per_ufwd_converted = [] # [[ubwd, ubwd], [ubwd, ubwd], [ubwd, 1]]
        
        residual = 0
        cnt_converted_ubwd = 0
        for ufwd in self.ubatchszs_fwd:
            # Use previous residual for split
            # å°†ufwd(ä¸€ä¸ªIntå€¼ï¼Œä»£è¡¨microbatch size)æŒ‰ç…§u_bwdçš„å¤§å°æ‹†åˆ†æˆä¸€ä¸ªtupleï¼Œæ¯ä¸ªå€¼éƒ½æ˜¯u_bwdï¼Œæœ€åä¸€ä¸ªæ•°å¯èƒ½æ˜¯ä½™æ•°
            split_u = self._split(self._concat((residual,ufwd)), self.u_bwd) # (c1,c2) or (c1,res) or (c1,) or (res,)
            residual = 0
            # Within split, check if each u is desired ubwd, if so make them as converted
            converted = []
            for j, u in enumerate(split_u):
                assert cnt_converted_ubwd < len(self.ubatchszs_bwd)
                desired_ubwd = self.ubatchszs_bwd[cnt_converted_ubwd]
                if u == desired_ubwd: # match
                    converted.append(u)
                    cnt_converted_ubwd += 1

                # è‹¥ufwdæŒ‰ç…§ubwdæ‹†åˆ†çš„æœ€åä¸€ä¸ªå€¼æ¯”ubatchszs_bwdä¸­çš„æœ€åä¸€ä¸ªå€¼è¦å°ï¼Œåˆ™å°†è¯¥å€¼èµ‹ç»™residualä½œä¸ºæ®‹ä½™å€¼
                # ğŸ“Œåˆ†æï¼šç»è¿‡find_ubatchsizeså‡½æ•°(searcher.py)ç­›é€‰çš„å‰åå‘ubsizeåº”è¯¥ä¸ä¼šå‡ºç°è¿™ç§æƒ…å†µã€‚ä¸¤è€…éƒ½æ˜¯
                #         æŸä¸ªç›¸åŒåº•æ•°çš„æ¬¡å¹‚ï¼Œéƒ½èƒ½è¢«minibatchsizeæ•´é™¤ï¼Œè¯´æ˜äº’ç›¸ä¹‹é—´ä¹Ÿæ˜¯å¯ä»¥æ•´é™¤çš„
                elif u < desired_ubwd: # residual
                    assert j == len(split_u)-1, "residual must be the last split"
                    residual = u
                else:
                    raise ValueError
            # Return converted
            # print("ufwd {} => ubwd {}".format(ufwd, converted))
            per_ufwd_converted.append(converted)
        self.per_ufwd_converted = per_ufwd_converted
        if self.verbose:
            print("[UBSConverter] per_ufwd_converted={}".format(self.per_ufwd_converted))

    # ç»™å®šufwdçš„microbatchçš„åºå·ï¼ˆç¬¬å‡ ä¸ªï¼‰ï¼Œè¿”å›è¯¥ufwdè½¬åŒ–åçš„ubwd list
    def find_converted(self, idx_ufwd):
        """ given microbatch idx of ufwd, return list of converted ubwd """
        return self.per_ufwd_converted[idx_ufwd]

    # é€ ufwd çš„å»ºç«‹ï¼Œè¯¥ ufwd æ‹†åˆ†çš„æ¯ä¸ª u_bwd çš„å…¨å±€ä¸‹æ ‡ï¼Œ[[0,1](ç¬¬0ä¸ªufwdçš„ä¸‹æ ‡list),[2,3],...]
    def _map_idx_ufwd_to_ubwd(self):
        ufwd_to_ubwd = [] # [[ubwd#0, ubwd#1], [ubwd#2,ubwd#3], [ubwd#4,ubwd#5]]
        assert len(self.ubatchszs_fwd) == len(self.per_ufwd_converted)
        cnt = 0
        # é€ ufwd çš„å»ºç«‹ï¼Œè¯¥ ufwd æ‹†åˆ†çš„æ¯ä¸ª u_bwd çš„å…¨å±€ä¸‹æ ‡ï¼Œ[[0,1](ç¬¬0ä¸ªufwdçš„ä¸‹æ ‡list),[2,3],...]
        for converted in self.per_ufwd_converted:
            ufwd_to_ubwd.append([cnt+i for i, _ in enumerate(converted)])
            cnt += len(converted)
        self.ufwd_to_ubwd = ufwd_to_ubwd
        assert cnt == len(self.ubatchszs_bwd)
        if self.verbose:
            print("[UBSConverter] idx of ufwd_to_ubwd={}".format(self.ufwd_to_ubwd))

    # ç»™å®šufwdçš„microbatchçš„åºå·ï¼ˆç¬¬å‡ ä¸ªï¼‰ï¼Œè¿”å›è¯¥ufwdè½¬åŒ–åçš„ubwd idx listï¼Œå³è½¬åŒ–åçš„ubwdåˆ—è¡¨ä¸­ï¼Œæ¯ä¸ªubwdçš„å…¨å±€ä¸‹æ ‡
    # [[0,1](ç¬¬0ä¸ªufwdçš„ä¸‹æ ‡list),[2,3],...]
    def find_idx_ubwd(self, idx_ufwd):
        """ given microbatch idx of ufwd, return list of converted ubwd idx"""
        return self.ufwd_to_ubwd[idx_ufwd]    

    # éå†æ¯ä¸ª ufwd è½¬æ¢æˆçš„ ubwd åˆ—è¡¨ã€‚å»ºç«‹åˆ—è¡¨ä¸­æ¯ä¸ª ubwd åˆ°å…¶å¯¹åº”çš„ ufwd çš„ä¸‹æ ‡çš„æ˜ å°„
    # [0,0,1,1,2,2,...]
    # [ufwd#0, ufwd#0, ufwd#1, ufwd#1, ufwd#2, ufwd#2]
    def _map_idx_ubwd_to_ufwd(self):
        ubwd_to_ufwd = [] # [ufwd#0, ufwd#0, ufwd#1, ufwd#1, ufwd#2, ufwd#2]
        assert len(self.ubatchszs_fwd) == len(self.per_ufwd_converted)
        # éå†æ¯ä¸ª ufwd è½¬æ¢æˆçš„ ubwd åˆ—è¡¨ã€‚å»ºç«‹åˆ—è¡¨ä¸­æ¯ä¸ª ubwd åˆ°å…¶å¯¹åº”çš„ ufwd çš„ä¸‹æ ‡çš„æ˜ å°„
        # [0,0,1,1,2,2,...]
        for idx_ufwd, converted in enumerate(self.per_ufwd_converted):
            for _ in range(len(converted)):
                ubwd_to_ufwd.append(idx_ufwd)
        self.ubwd_to_ufwd = ubwd_to_ufwd
        assert len(self.ubatchszs_bwd) == len(self.ubwd_to_ufwd)
        if self.verbose:
            print("[UBSConverter] idx of ubwd_to_ufwd={}".format(self.ubwd_to_ufwd))

    # ç»™å®šbwdvtçš„microbatch idxï¼Œè¿”å›äº§ç”Ÿè¯¥bwd microbatchçš„fwd microbatch idx
    def find_idx_ufwd(self, idx_ubwd):
        """ given microbatch idx of ubwd, return its producer idx of ufwd """
        return self.ubwd_to_ufwd[idx_ubwd]    

# 1.å®ä¾‹åŒ–ä¸€ä¸ªäº‹ä»¶Eventï¼Œè¡¨ç¤ºä¸€ä¸ªswapin WBçš„äº‹ä»¶
# 2.å°†ç”Ÿæˆçš„eventæ·»åŠ åˆ°eventå­—å…¸ { idï¼ˆä»£è¡¨ä¸€ä¸ªeventçš„å­—ç¬¦ä¸²ï¼‰: Event() } å’Œå¯¹åº”çš„äº‹ä»¶é˜Ÿåˆ—ä¸­ {self.stream: [Event()]}
#   å¹¶å°†eventçš„poså±æ€§(åœ¨é˜Ÿåˆ—ä¸­çš„ä¸‹æ ‡)ï¼Œè®¾ç½®ä¸ºäº‹ä»¶é˜Ÿåˆ—çš„æœ€åä¸€ä¸ªä½ç½®
#   2.1.è‹¥è¾“å…¥çš„taskçš„å·¦è¾¹è¿˜æœ‰taskï¼Œè¿˜ä¼šå¢åŠ ä¸€æ­¥é¢å¤–çš„æ“ä½œï¼Œåˆ›å»ºå…¶å·¦è¾¹ä»»åŠ¡çš„Eventçš„å­—ç¬¦ä¸²è¡¨ç¤º(ç”¨äºåˆ›å»ºeventå®ä¾‹çš„5ä¸ªå‚æ•°)ï¼Œ
#       åŠ å…¥åˆ°å½“å‰eventçš„inputsåˆ—è¡¨ä¸­ã€‚è¡¨ç¤ºCompute DELäº‹ä»¶æ‰§è¡Œå®Œäº†æ‰èƒ½å¼€å§‹æ‰§è¡ŒSwap In WBäº‹ä»¶ï¼ˆğŸ“Œå³ä¸Šä¸€ä¸ªä»»åŠ¡çš„æœ€åä¸€ä¸ªäº‹ä»¶ï¼‰
def In_WB(vt, events, stream_events, left_vt, delay_enqueue, prefetch_offload):
    # å®ä¾‹åŒ–ä¸€ä¸ªäº‹ä»¶Eventï¼Œè¡¨ç¤ºä¸€ä¸ªswapin WBçš„äº‹ä»¶
    ev_w = Event(vt, 0, 0, "SwapIn", "WB")
    # è‹¥vtçš„å‰ä¸€ä¸ªä»»åŠ¡ä¸å­˜åœ¨
    if left_vt is None:
        # 1.å°†è°ƒç”¨è¯¥æ–¹æ³•çš„Eventå®ä¾‹ï¼Œæ·»åŠ åˆ°eventsè¿™ä¸ªå­—å…¸ä¸­ã€‚events: { idï¼ˆä»£è¡¨ä¸€ä¸ªeventçš„å­—ç¬¦ä¸²ï¼‰: Event() } 
        # 2.å°†Eventæ·»åŠ åˆ° self.stream è¿™ç§ç±»å‹çš„äº‹ä»¶é˜Ÿåˆ—ä¸­ã€‚stream_eventsï¼š{self.stream: [Event()]}
        # 3.å¯¹Eventçš„poså±æ€§(åœ¨é˜Ÿåˆ—ä¸­çš„ä¸‹æ ‡)èµ‹å€¼ï¼Œå³é˜Ÿåˆ—çš„æœ€åä¸€ä¸ªä½ç½®
        ev_w.add_to(events, stream_events)
    # è¯¥å‚æ•°é»˜è®¤ä¸ºfalseï¼Œä¸ç”¨çœ‹
    elif prefetch_offload: # prefetch at left vt
        ev_w.inputs_add(left_vt, len(left_vt.ubatchszs)-1, -1, "Compute", left_vt.type)
        if not delay_enqueue: # vPP-["F", "Bc"]
            ev_w.add_to(events, stream_events)
        else: # vDP or vPP-"Bn"
            pass
    # è‹¥vtçš„å‰ä¸€ä¸ªä»»åŠ¡å­˜åœ¨ï¼ˆä¸”ä¸prefetch offloadï¼‰
    else: # no prefetch offload
        # è¿™äº”ä¸ªå‚æ•°ç›¸å½“äºå®šä¹‰äº†ä¸€ä¸ªEventï¼Œå°½ç®¡å‡½æ•°é‡Œæ²¡æœ‰çœŸæ­£çš„ç”Ÿæˆä¸€ä¸ªEvent
        # ä¸ºev_wçš„inputså±æ€§æ·»åŠ ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œä»£è¡¨å½“å‰Eventéœ€è¦çš„ï¼ˆå…¶ä»–streamsçš„ï¼‰è¾“å…¥ä¾èµ–äº‹ä»¶
        ev_w.inputs_add(left_vt, 0, 0, "Compute", "DEL")
        ev_w.add_to(events, stream_events)
    
    return ev_w

# 1.ä¸ºtaskçš„è¾“å…¥Xç”Ÿæˆä¸€ä¸ªevent
# 2.é’ˆå¯¹å…·ä½“çš„æƒ…å†µï¼Œä¸ºeventçš„inputså±æ€§èµ‹å€¼ï¼Œå³è¡¨ç¤ºå¯¹åº”å½“å‰è¾“å…¥äº‹ä»¶çš„è¾“å‡ºäº‹ä»¶
# 3.å°†ev_w_comp_outå‚æ•°ï¼ˆä¸€ä¸ªvtï¼‰åŠ å…¥åˆ°æ–°ç”Ÿæˆçš„eventçš„inputsåˆ—è¡¨ä¸­
# ğŸ“Œåˆ†æï¼šä¸ªäººè§‰å¾—subpack idxä¸äº§ç”Ÿå®é™…ä½œç”¨ï¼Œä»…è¡¨æ˜subpackçš„æ•°é‡ï¼ˆæ— è®ºå‘ä¸å‘é€ç¬¬0å±‚çš„stashX,å‰å‡ å±‚éƒ½ä¸ç®—ä¸€ä¸ªsubpackï¼‰
def In_X(vt, i, events, stream_events, left_vt, left2_vt, TASKS, ubscvt, ev_w, prefetch_offload, ev_w_comp_out):
    # assert ['F','Bc']
    # åŒ…å«è¾“å…¥æ•°æ®çš„ fwd ä»»åŠ¡
    if vt.has_data: # "Data"
        ev_x = Event(vt, i, 0, "SwapIn", "X")
        assert left_vt is None # 1st task

    # äº§ç”Ÿè¾“å…¥Xçš„taskå’Œvtä¸åœ¨ä¸€ä¸ªGPUä¸Šã€‚è¿™ç§æƒ…å†µåŒ…å«ï¼šä¸åŒ…å«è¾“å…¥æ•°æ®çš„FWDä»»åŠ¡ã€åŒ…å«lossè®¡ç®—å±‚çš„BWDä»»åŠ¡
    elif vt.In["X"][vt.layers[0]].medium == "P2P": # "P2PX"
        ev_x = Event(vt, i, 0, "P2PIn", "X")
        # ä¸ºev_xçš„peer_idå±æ€§èµ‹å€¼ï¼Œå³å°†ä»£è¡¨å¯¹åº”å½“å‰ä»»åŠ¡çš„p2pä»»åŠ¡ä»¥å­—ç¬¦ä¸²çš„å½¢å¼åŠ å…¥åˆ°ev_xçš„inputsåˆ—è¡¨ä¸­
        # ğŸ“Œï¼šåˆ†æï¼Œè¿™å…¶ä¸­çš„è¿”å›æœ€åä¸€ä¸ªsubpackçš„idæˆ‘å¯ä»¥ç†è§£ï¼Œæ¯•ç«Ÿè¦æŠŠæœ€åä¸€ä¸ªstashXå‘é€å‡ºå»ï¼Œåé¢æ‰æ˜¯
        #     P2PInçš„å‘ç”Ÿ
        ev_x.register_peer(TASKS, i, -1, "P2POut", "Y") # p2p dependency
        assert ubscvt is None

    # è¿™ç§æƒ…å†µæ˜¯BWDä»»åŠ¡ï¼Œè¿™ç§ä»»åŠ¡éœ€è¦å…¶å‰å‘ä»»åŠ¡çš„è¾“å…¥
    # ğŸ“Œåˆ†æï¼šå¯¹BWDçš„FWDï¼ˆå³é‡è®¡ç®—ä»»åŠ¡ï¼‰ï¼Œå¿…é¡»ç­‰å¾…å¯¹åº”çš„FWDä»»åŠ¡å‘é€å®Œæœ€åä¸€ä¸ªStashX
    # â“ï¼šè¿™æˆ‘å°±ä¸å¤ªç†è§£äº†ï¼Œä¸ºå•¥å¾—ç­‰æœ€åä¸€ä¸ªï¼Ÿ
    elif vt.In["X"][vt.layers[0]].medium == "MSG": # last fwd "MSG" of vPP
        ev_x = Event(vt, i, 0, "SwapIn", "X")
        # è¿”å›BWD vtå¯¹åº”çš„src_taskï¼Œå³å‘é€stashXçš„FWD vtï¼Œå’Œsrc_taskçš„æœ€åä¸€ä¸ªsubpack_idxï¼ˆç”¨äºåœ¨ç”±å„ä¸ªsubpacké¦–å±‚ç»„æˆçš„listä¸­å–å€¼ï¼‰
        src_vt, src_spi = find_output_subpack_idx(vt, TASKS)
        # ä¸ºev_wçš„inputså±æ€§æ·»åŠ ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œä»£è¡¨å½“å‰Eventä¾èµ–çš„ï¼ˆå…¶ä»–steamsçš„ï¼‰Event
        # å³CPU MSGYäº‹ä»¶å®Œæˆåï¼Œæ‰èƒ½å¼€å§‹SwapIn Xäº‹ä»¶
        ev_x.inputs_add(src_vt, i, src_spi, "CPU", "MSGY") # msg dependency

    # äº§ç”Ÿè¾“å…¥Xçš„taskå’Œvtåœ¨ä¸€ä¸ªGPUä¸Šï¼Œè¿™ç§æƒ…å†µå¯èƒ½ä¸ºï¼šä¸åŒ…å«è¾“å…¥æ•°æ®çš„FWDä»»åŠ¡ã€åŒ…å«lossè®¡ç®—å±‚çš„BWDä»»åŠ¡
    elif vt.In["X"][vt.layers[0]].medium == "SWP": # "LocalX" of vDP
        ev_x = Event(vt, i, 0, "SwapIn", "X")
        # if 'Bc':
        #     ui = i if ubscvt is None else ubscvt.find_idx_ufwd(i)
        # elif 'F':
        #     ui = i
        # ç»™å®šbwdvtçš„microbatch idxï¼Œè¿”å›äº§ç”Ÿè¯¥bwd microbatchçš„fwd microbatch idx
        ui = i if ubscvt is None else ubscvt.find_idx_ufwd(i)
        ev_x.inputs_add(left_vt, ui, -1, "SwapOut", "Y") # swap dependency
    else:
        raise ValueError
    
    # åœ¨gpt2çš„ä¾‹å­ä¸­è¯¥å‚æ•°é»˜è®¤ä¸ºfalseï¼Œæ‰§è¡Œelse
    if prefetch_offload:
        if i == 0:
            if left_vt is None: # 1st task
                ev_x.add_to(events, stream_events) 
            else: # prefetch at left vt
                if len(left_vt.ubatchszs) >= 2: # double buffer
                    ev_x.inputs_add(left_vt, len(left_vt.ubatchszs)-2, -1, "Compute", left_vt.type)
                else: # left_vt has only 1 ubatch
                    if left2_vt is not None:
                        ev_x.inputs_add(left2_vt, 0, 0, "Compute", "DEL")
                ev_x.add_to(events, stream_events)
                if ev_w is not None: # 'vDP'-['F','Bc']
                    ev_w.add_to(events, stream_events) 
                else: # vPP
                    pass
        elif i == 1:
            if left_vt is not None:
                ev_x.inputs_add(left_vt, 0, 0, "Compute", "DEL")
            ev_x.add_to(events, stream_events)
        else: # i >= 2
            ev_x.inputs_add(vt, i-2, -1, "Compute", vt.type)
            ev_x.add_to(events, stream_events)
    else: # no prefetch offload
        # if i == 0:
        #     assert ev_w is not None
        #     ev_x.inputs_add_ev(ev_w)
        # else: # i >= 1
        #     if ev_comp_out is not None:
        #         ev_x.inputs_add_ev(ev_comp_out) # if vDP, ev_out; if vPP, ev_comp
        #     else:
        #         ev_x.inputs_add(vt, i-1, -1, "Compute", vt.type) # if None dX
        if ev_w_comp_out is not None:
            # å°†å‚æ•°evæ·»åŠ åˆ°è°ƒç”¨è¯¥å‡½æ•°çš„eventçš„inputsåˆ—è¡¨ä¸­
            ev_x.inputs_add_ev(ev_w_comp_out)
        else: # if None dX
            ev_x.inputs_add(vt, i-1, -1, "Compute", vt.type)
        ev_x.add_to(events, stream_events)
    
    return ev_x

# 1.å®ä¾‹åŒ–ä¸€ä¸ªSwapIn sXäº‹ä»¶ï¼Œå¹¶åŠ å…¥åˆ°ä¸¤ä¸ªå­—å…¸ä¸­
# 2.å°†CPU MSGsXäº‹ä»¶æ·»åŠ åˆ°SwapIn sXäº‹ä»¶çš„è¾“å…¥ä¾èµ–ä¸­ï¼Œè¡¨ç¤ºCPU MSGsXäº‹ä»¶å®Œæˆåæ‰èƒ½æ‰§è¡ŒSwap In sXäº‹ä»¶
# 3.è‹¥iä¸º0ï¼Œå³æ‰§è¡Œçš„æ˜¯é¦–ä¸ªmicro batchï¼Œæ·»åŠ çš„ä¾èµ–äº‹ä»¶ä¸º Swapin WB
#   å¦åˆ™ï¼Œæ·»åŠ çš„ä¾èµ–äº‹ä»¶ä¸ºæ‰§è¡Œå‰é¢çš„micro batchçš„ Compute BWD äº‹ä»¶ï¼Œè¡¨ç¤ºå‰é¢çš„BWDç®—å®Œäº†æ‰èƒ½å¼€å§‹ SwapIn sXäº‹ä»¶
def In_sX(vt, i, events, stream_events, left_vt, left2_vt, src_vt, src_spi, prefetch_offload, ev_w_comp_out):
    # assert 'Bn'
    # å®ä¾‹åŒ–ä¸€ä¸ªSwapIn sXäº‹ä»¶
    ev_sx = Event(vt, i, 0, "SwapIn", "sX")
    # å°†CPU MSGsXäº‹ä»¶æ·»åŠ åˆ°SwapIn sXäº‹ä»¶çš„è¾“å…¥ä¾èµ–ä¸­ï¼Œè¡¨ç¤ºCPU MSGsXäº‹ä»¶å®Œæˆåæ‰èƒ½æ‰§è¡ŒSwap In sXäº‹ä»¶
    ev_sx.inputs_add(src_vt, i, src_spi, "CPU", "MSGsX") # swap dependency
    
    if prefetch_offload:
        if i == 0:
            if left_vt is None: # 1st task
                ev_sx.add_to(events, stream_events)
            else: # prefetch at left vt
                if len(left_vt.ubatchszs) >= 2: # double buffer
                    ev_sx.inputs_add(left_vt, len(left_vt.ubatchszs)-2, -1, "Compute", left_vt.type)
                else: # left_vt has only 1 ubatch
                    if left2_vt is not None:
                        ev_sx.inputs_add(left2_vt, 0, 0, "Compute", "DEL")
                ev_sx.add_to(events, stream_events)
        elif i == 1:
            if left_vt is not None:
                ev_sx.inputs_add(left_vt, 0, 0, "Compute", "DEL")
            ev_sx.add_to(events, stream_events)
        else: # i >= 2
            ev_sx.inputs_add(vt, i-2, 0, "Compute", vt.type)
            ev_sx.add_to(events, stream_events)
    else: # no prefetch offload
        # if i == 0:
        #     assert ev_w is not None
        #     ev_sx.inputs_add_ev(ev_w)
        # else: # i >= 1
        #     if ev_comp_out is not None:
        #         ev_sx.inputs_add_ev(ev_comp_out) # if vDP, ev_out; if vPP, ev_comp
        #     else:
        #         ev_x.inputs_add(vt, i-1, -1, "Compute", vt.type) # if None dX

        # è‹¥iä¸º0ï¼Œå³æ‰§è¡Œçš„æ˜¯é¦–ä¸ªmicro batchï¼Œæ·»åŠ çš„ä¾èµ–äº‹ä»¶ä¸º Swapin WB
        # å¦åˆ™ï¼Œæ·»åŠ çš„ä¾èµ–äº‹ä»¶ä¸ºæ‰§è¡Œå‰é¢çš„micro batchçš„ Compute BWD äº‹ä»¶ï¼Œè¡¨ç¤ºå‰é¢çš„BWDç®—å®Œäº†æ‰èƒ½å¼€å§‹ SwapIn sXäº‹ä»¶
        if ev_w_comp_out is not None:
            ev_sx.inputs_add_ev(ev_w_comp_out)
        else: # if None dX
            ev_sx.inputs_add(vt, i-1, -1, "Compute", vt.type)
        ev_sx.add_to(events, stream_events)
    
    return ev_sx

# ğŸ“ŒsXæ˜¯stashX
# 1.å®ä¾‹åŒ–ä¸€ä¸ªå‰å‘è®¡ç®—äº‹ä»¶
# 2.è‹¥micro batch idx = 0ï¼Œè¿˜è¦å°†ev_wäº‹ä»¶åŠ å…¥åˆ°å½“å‰äº‹ä»¶çš„inputså±æ€§ä¸­ï¼Œå³ ev_w ï¼ˆWBï¼šå‚æ•°å’Œbufferï¼‰ ä¸ºå½“å‰äº‹ä»¶çš„è¾“å…¥ä¾èµ–
# 3.å°†ev_xåŠ å…¥å½“å‰äº‹ä»¶çš„inputså±æ€§ä¸­ï¼Œå³ ev_x ï¼ˆX:æ¿€æ´»å€¼ï¼‰ ä¸ºå½“å‰äº‹ä»¶çš„è¾“å…¥ä¾èµ–
# 4.å°†ç”Ÿæˆçš„eventæ·»åŠ åˆ°eventå­—å…¸ { idï¼ˆä»£è¡¨ä¸€ä¸ªeventçš„å­—ç¬¦ä¸²ï¼‰: Event() } å’Œå¯¹åº”çš„äº‹ä»¶é˜Ÿåˆ—ä¸­ {self.stream: [Event()]}
#   å¹¶å°†eventçš„poså±æ€§(åœ¨é˜Ÿåˆ—ä¸­çš„ä¸‹æ ‡)ï¼Œè®¾ç½®ä¸ºäº‹ä»¶é˜Ÿåˆ—çš„æœ€åä¸€ä¸ªä½ç½®
# 5.è‹¥ä¸€ä¸ªtaskä¸­æœ‰å¤šå±‚çš„è¾“å…¥éƒ½ä¼šè¢«åå‘ä¼ æ’­æ—¶ç”¨åˆ°ï¼Œåˆ™ä»ç¬¬2ä¸ªéœ€è¦çš„å±‚å¼€å§‹ç›¸å½“äºå…¶ä»–çš„subpackï¼Œä¸ºå…¶åˆ›å»ºæ–°çš„eventï¼Œæ–°çš„eventçš„spi
#   ä»1å¼€å§‹ç´¯åŠ ï¼Œå³subpack1ã€subpack2ã€...
# 6.ä¸ºæ¯ä¸€ä¸ªå®ä¾‹åŒ–çš„eventæ·»åŠ ä¸€ä¸ªè¾“å…¥ä¾èµ–äº‹ä»¶ï¼Œå³Swapoutæ‰stashXã€‚â“è¿™ä¸ªç›´è§‰ä¸Šçœ‹èµ·æ¥åƒè¾“å‡ºä¾èµ–
def Compute_FWD(vt, i, events, stream_events, ev_w, ev_x, prefetch_offload):
    # 'F'
    spi = 0
    # å®ä¾‹åŒ–ä¸€ä¸ªå‰å‘è®¡ç®—äº‹ä»¶
    ev_fwd = Event(vt, i, spi, "Compute", "FWD") # subpack[0]
    # è‹¥micro batch idx = 0ï¼Œè¿˜è¦å°†ev_wäº‹ä»¶åŠ å…¥åˆ°å½“å‰äº‹ä»¶çš„inputså±æ€§ä¸­ï¼Œå³ ev_w ï¼ˆWBï¼šå‚æ•°å’Œbufferï¼‰ ä¸ºå½“å‰äº‹ä»¶çš„è¾“å…¥ä¾èµ–
    if i == 0:
        ev_fwd.inputs_add_ev(ev_w)
    # å°†ev_xåŠ å…¥å½“å‰äº‹ä»¶çš„inputså±æ€§ä¸­ï¼Œå³ ev_x ï¼ˆX:æ¿€æ´»å€¼ï¼‰ ä¸ºå½“å‰äº‹ä»¶çš„è¾“å…¥ä¾èµ–
    ev_fwd.inputs_add_ev(ev_x)
    # 1.å°†è°ƒç”¨è¯¥æ–¹æ³•çš„Eventå®ä¾‹ï¼Œæ·»åŠ åˆ°eventsè¿™ä¸ªå­—å…¸ä¸­ã€‚events: { idï¼ˆä»£è¡¨ä¸€ä¸ªeventçš„å­—ç¬¦ä¸²ï¼‰: Event() } 
    # 2.å°†Eventæ·»åŠ åˆ° self.stream è¿™ç§ç±»å‹çš„äº‹ä»¶é˜Ÿåˆ—ä¸­ã€‚stream_eventsï¼š{self.stream: [Event()]}
    # 3.å¯¹Eventçš„poså±æ€§(åœ¨é˜Ÿåˆ—ä¸­çš„ä¸‹æ ‡)èµ‹å€¼ï¼Œå³é˜Ÿåˆ—çš„æœ€åä¸€ä¸ªä½ç½®
    ev_fwd.add_to(events, stream_events)
    # sub-packing by StashX
    # å±‚å·ï¼Œmediumï¼ˆåª’ä»‹ï¼‰
    for l, m in vt.Out['X'].items(): # layers in ascending order
        spi += 1
        # è‹¥æ˜¯vtçš„ç¬¬0å±‚
        if l == vt.layers[0]: # reuse subpack[0]
            spi -= 1; assert spi == 0

        # æ‰§è¡Œåˆ°è¿™ï¼Œè¯´æ˜Out['X']ä¸­æœ‰å¤šä¸ªé”®å€¼å¯¹ï¼Œå³é™¤layer0å¤–ï¼Œè¿˜æœ‰å…¶ä»–å±‚çš„è¾“å…¥Xä¼šåœ¨åå‘ä¼ æ’­æ—¶ä½¿ç”¨ã€‚æ­¤æ—¶ï¼Œ
        # å®ä¾‹åŒ–æ–°çš„fwd eventï¼Œä»£è¡¨subpackï¼Œspiä»1å¼€å§‹ã€‚å¹¶å°†æ–°çš„eventåŠ å…¥åˆ°eventså’Œstream_eventså­—å…¸ä¸­
        # ğŸ“Œå¯è§ï¼Œæ¯ä¸ªFWDä»»åŠ¡ä¼šè¢«æ‹†è§£ä¸ºå¤šä¸ªFWDäº‹ä»¶ï¼Œå¯é€šè¿‡spiè¯†åˆ«å„ä¸ªè¢«æ‹†åˆ†çš„FWDäº‹ä»¶
        else: # create a subpack[1+]
            ev_fwd = Event(vt, i, spi, "Compute", "FWD")
            ev_fwd.add_to(events, stream_events)
        # è¯¥å‚æ•°é»˜è®¤ä¸ºfalseï¼Œå› æ­¤è¿™é‡Œæ‰§è¡Œ
        # ä¸ºev_fwdæ·»åŠ ä¸€ä¸ªè¾“å…¥ä¾èµ–eventï¼Œå³Swapoutæ‰stashXæ‰èƒ½ç»§ç»­è¿›è¡Œ FWD è®¡ç®—
        if not prefetch_offload:
            ev_fwd.inputs_add(vt, i, spi, "SwapOut", "sX")
    
    # è¿”å›æœ€åä¸€ä¸ª(spi)ev_fwd
    return ev_fwd

# å»ºç«‹swapout stashXå’ŒCPU MSGsXäº‹ä»¶ï¼Œä¸€ä¸ªvtä¼šå»ºç«‹å¤šä¸ªswapout sXäº‹ä»¶ï¼Œé¦–ä¸ªäº‹ä»¶çš„ä¾èµ–äº‹ä»¶ä¸ºev_xï¼Œåé¢çš„ä¾èµ–éƒ½ä¸º
# å‰é¢Compute FWDäº‹ä»¶ï¼Œå³FWDæ‰§è¡Œå®Œäº†æ‰èƒ½å¼€å§‹å¸è½½ï¼Œè€Œåå»ºç«‹ç›¸åº”çš„MSGsXäº‹ä»¶ï¼Œå…¶ä¾èµ–å³ä¸ºåˆšå»ºç«‹çš„swapoot sXäº‹ä»¶
# å¯¹æ¯ä¸€ä¸ªsubpack
# 1.å®ä¾‹åŒ–ä¸€ä¸ªswapout sXï¼ˆev_sxï¼‰äº‹ä»¶ï¼Œå¹¶å°†å…¶åŠ å…¥åˆ°ä¸¤ä¸ªå­—å…¸ä¸­ã€‚
#   1.1.è‹¥å½“å‰çš„subpackæ˜¯ç¬¬ä¸€ä¸ªsubpackï¼Œå³subpackæ˜¯ä»layer0å¼€å§‹çš„ï¼šå°† ev_xï¼ˆvtçš„è¾“å…¥Xäº‹ä»¶ï¼‰ æ·»åŠ åˆ°ev_sxçš„Inputså±æ€§ä¸­ï¼Œ
#       å³ev_xä¸ºå½“å‰äº‹ä»¶çš„è¾“å…¥ä¾èµ–äº‹ä»¶
    # ğŸ“Œåˆ†æï¼šæ˜¯æ­£ç¡®çš„ï¼Œè¿™ä¸ªswapoutæ˜¯FWDçš„é¦–å±‚ï¼Œæ ¹æœ¬æ²¡å¼€å§‹æ‰§è¡ŒFWD
#   1.2.è‹¥æ˜¯åé¢çš„subpackï¼Œæ·»åŠ  å‰ä¸€ä¸ªsubpackçš„å‰å‘è®¡ç®— äº‹ä»¶ä¸ºev_sxçš„éœ€æ±‚è¾“å…¥ä»»åŠ¡ã€‚å³å‰ä¸€ä¸ªsubpackçš„å‰å‘è®¡ç®—æ‰§è¡Œå®Œäº†ï¼Œæ‰èƒ½
#       å¼€å§‹å½“å‰subpackçš„swapout stashXä»»åŠ¡
# 2.å®ä¾‹åŒ–ä¸€ä¸ªCPUä¸Šçš„MSGsXäº‹ä»¶ï¼Œè¡¨ç¤ºCPUä¸Šå‘é€StashXçš„äº‹ä»¶
#   2.1.å°†æœ€åä¸€ä¸ªsubpackçš„ev_sxè®¾ç½®ä¸ºåˆšåˆšå®ä¾‹åŒ–çš„äº‹ä»¶çš„éœ€æ±‚è¾“å…¥äº‹ä»¶ï¼Œå³æš‚å­˜çš„X swapoutä»¥åCPUæ‰èƒ½å‘é€
# æœ€åè¿”å›MSGsXäº‹ä»¶
def Out_sX(vt, i, u, events, stream_events, left_vt, ubscvt, ev_x, prefetch_offload):
    # 'F'
    ev_msg = None
    spi = 0
    # sub-packing by StashX
    # å±‚å·ï¼Œmediumï¼ˆåª’ä»‹ï¼‰
    for l, m in vt.Out['X'].items(): # layers in ascending order
        spi += 1
        # ğŸ“Œå¯è§FWD vtçš„é¦–å±‚å¿…å®šä¼šå‘é€StashXï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼
        # â“ï¼šæ˜¯ä»€ä¹ˆé€»è¾‘è®©éƒ¨åˆ†BWDä»»åŠ¡çš„é¦–å±‚å¿…å®šæ˜¯FWDä»»åŠ¡çš„é¦–å±‚ï¼Ÿ
        # åˆ†æï¼šä¸ä¸€å®šæ˜¯å¿…é¡»ï¼Œè¿™é‡Œæ˜¯ifï¼Œæ²¡ifæ‰æ˜¯å¿…é¡»
        if l == vt.layers[0]: # reuse subpack[0]
            spi -= 1; assert spi == 0
            # å®ä¾‹åŒ–ä¸€ä¸ªswapout sXäº‹ä»¶
            ev_sx = Event(vt, i, spi, "SwapOut", "sX")
            # å°† ev_xï¼ˆvtçš„è¾“å…¥Xäº‹ä»¶ï¼‰ æ·»åŠ åˆ°ev_sxçš„Inputså±æ€§ä¸­ï¼Œå³ev_xä¸ºå½“å‰äº‹ä»¶çš„ä¾èµ–äº‹ä»¶
            ev_sx.inputs_add_ev(ev_x)
            if prefetch_offload:
                if i == 0:
                    if left_vt is not None:
                        ev_sx.inputs_add(left_vt, 0, 0, "Compute", "DEL")
                else:
                    ev_sx.inputs_add(vt, i-1, -1, "Compute", "FWD")
            ev_sx.add_to(events, stream_events)

        # æ‰§è¡Œåˆ°è¿™ï¼Œè¯´æ˜Out['X']ä¸­æœ‰å¤šä¸ªé”®å€¼å¯¹ï¼Œå³é™¤layer0å¤–ï¼Œè¿˜æœ‰å…¶ä»–å±‚çš„è¾“å…¥Xä¼šåœ¨åå‘ä¼ æ’­æ—¶ä½¿ç”¨ã€‚æ­¤æ—¶ï¼Œ
        # å®ä¾‹åŒ–æ–°çš„fwd eventï¼Œä»£è¡¨subpackï¼Œspiä»1å¼€å§‹ã€‚å¹¶å°†æ–°çš„eventåŠ å…¥åˆ°eventså’Œstream_eventså­—å…¸ä¸­
        else: # create a subpack[1+]
            ev_sx = Event(vt, i, spi, "SwapOut", "sX")
            # æ·»åŠ  å‰ä¸€ä¸ªsubpackçš„å‰å‘è®¡ç®— äº‹ä»¶ä¸ºev_sxçš„éœ€æ±‚è¾“å…¥ä»»åŠ¡
            ev_sx.inputs_add(vt, i, spi-1, "Compute", "FWD")
            # å°†åˆšåˆšå®ä¾‹åŒ–çš„ä¸‹ä¸€ä¸ªsubpackçš„SwapOut sXäº‹ä»¶æ·»åŠ åˆ°ä¸¤ä¸ªå­—å…¸ä¸­
            ev_sx.add_to(events, stream_events)
        # "MSGsX"
        assert m.medium == "MSG"
        # ç»™å®šufwdçš„microbatchçš„åºå·ï¼ˆç¬¬å‡ ä¸ªï¼‰ï¼Œè¿”å›è¯¥ufwdè½¬åŒ–åçš„ubwd idx listï¼Œå³è½¬åŒ–åçš„ubwdåˆ—è¡¨ä¸­ï¼Œæ¯ä¸ªubwdçš„å…¨å±€ä¸‹æ ‡
        # [[0,1](ç¬¬0ä¸ªufwdçš„ä¸‹æ ‡list),[2,3],...]
        indice_bwd = [i] if ubscvt is None else ubscvt.find_idx_ubwd(i)
        # ç»™å®šufwdçš„microbatchçš„åºå·ï¼ˆç¬¬å‡ ä¸ªï¼‰ï¼Œè¿”å›è¯¥ufwdè½¬åŒ–åçš„ubwd list
        us_bwd = [u] if ubscvt is None else ubscvt.find_converted(i)
        for i_bwd, u_bwd in zip(indice_bwd, us_bwd):
            # å®ä¾‹åŒ–ä¸€ä¸ªCPUä¸Šçš„MSGsXäº‹ä»¶
            # ğŸ“Œæ³¨æ„ï¼Œè¿™é‡Œä¼ å…¥çš„micro batch indexæ˜¯i_bwdï¼Œå³è¯¥äº‹ä»¶çš„ubiç›´æ¥å¯¹åº”BWDvtçš„ubi
            ev_msg = Event(vt, i_bwd, spi, "CPU", "MSGsX", ubs=u_bwd)     
            # å°†æœ€åä¸€ä¸ªsubpackçš„ev_sxè®¾ç½®ä¸ºåˆšåˆšå®ä¾‹åŒ–çš„äº‹ä»¶çš„éœ€æ±‚è¾“å…¥äº‹ä»¶ï¼Œå³æš‚å­˜çš„X swapoutä»¥åCPUæ‰èƒ½å‘é€
            ev_msg.inputs_add_ev(ev_sx)
            ev_msg.add_to(events, stream_events)
    
    return ev_msg

# ä¸¤ç§æƒ…å†µï¼š
# 1.è‹¥vtçš„Out['Y']æœ€åä¸€å±‚çš„åª’ä»‹ä¸ºP2P
#   1.1.å®ä¾‹åŒ–ä¸€ä¸ªP2Päº‹ä»¶ï¼Œå…¶spiä¸º ev_fwdï¼ˆfwdè®¡ç®—äº‹ä»¶ï¼‰çš„spiï¼Œå¹¶å°†å®ä¾‹åŒ–çš„äº‹ä»¶æ·»åŠ åˆ°ä¸¤ä¸ªå­—å…¸ä¸­
#   1.2.å°†ev_fwdæ·»åŠ åˆ°å½“å‰è¿™ä¸ªP2POut Yäº‹ä»¶çš„éœ€æ±‚è¾“å…¥åˆ—è¡¨ä¸­ï¼Œè¡¨ç¤ºå‰å‘è®¡ç®—çš„äº‹ä»¶å®Œæˆåæ‰èƒ½å¼€å§‹P2POut
#   1.3.æ­¤å¤–ï¼Œè¿˜è¦å°†å¯¹åº”çš„é‚£ä¸ªp2pä»»åŠ¡ä»¥å­—ç¬¦ä¸²çš„å½¢å¼èµ‹ç»™è°ƒç”¨è¯¥å‡½æ•°çš„eventçš„peer_idå±æ€§
# 2.è‹¥Out['Y']æœ€åä¸€å±‚çš„åª’ä»‹ä¸ºMSGï¼Œè¿™ç§æƒ…å†µä¸ºæœ€åä¸€ä¸ªfwd
#   2.1.å®ä¾‹åŒ–ä¸€ä¸ªSwap out Yäº‹ä»¶ï¼Œå…¶spiä¸º ev_fwdï¼ˆfwdè®¡ç®—äº‹ä»¶ï¼‰çš„spiï¼Œå¹¶å°†å®ä¾‹åŒ–çš„äº‹ä»¶æ·»åŠ åˆ°ä¸¤ä¸ªå­—å…¸ä¸­ã€‚
#   2.2.å°†ev_fwdæ·»åŠ åˆ°å½“å‰è¿™ä¸ªSwapout Yäº‹ä»¶çš„éœ€æ±‚è¾“å…¥åˆ—è¡¨ä¸­ï¼Œè¡¨ç¤ºå‰å‘è®¡ç®—çš„äº‹ä»¶å®Œæˆåæ‰èƒ½æ‰§è¡ŒCPUä¸Šå‘é€Yçš„äº‹ä»¶
#   2.3.å®ä¾‹åŒ–ä¸€ä¸ªCPU MSGYäº‹ä»¶ï¼Œå¯èƒ½ä»£è¡¨CPUä¸Šè¾“å‡ºæˆ–è¾“å…¥Yçš„äº‹ä»¶ã€‚å°†åˆšåˆšå®ä¾‹åŒ–çš„Swap out Yäº‹ä»¶æ·»åŠ åˆ°MSGYäº‹ä»¶çš„inputsåˆ—è¡¨ä¸­ï¼Œ
#       è¡¨ç¤ºSwapout Yä¹‹åæ‰èƒ½æ‰§è¡ŒCPUä¸ŠMSGYäº‹ä»¶
def Out_Y(vt, i, u, events, stream_events, ubscvt, TASKS, ev_fwd):
    # 'F'
    # è‹¥Out['Y']æœ€åä¸€å±‚çš„åª’ä»‹ä¸ºP2P
    if vt.Out["Y"][vt.layers[-1]].medium == "P2P": # P2PY
        # å®ä¾‹åŒ–ä¸€ä¸ªP2Päº‹ä»¶ï¼Œå…¶spiä¸º ev_fwdï¼ˆfwdè®¡ç®—äº‹ä»¶ï¼‰çš„spi
        ev_y = Event(vt, i, ev_fwd.spi, "P2POut", "Y")
        # å°†å¯¹åº”çš„é‚£ä¸ªp2pä»»åŠ¡ä»¥å­—ç¬¦ä¸²çš„å½¢å¼èµ‹ç»™è°ƒç”¨è¯¥å‡½æ•°çš„eventçš„peer_idå±æ€§
        ev_y.register_peer(TASKS, i, 0, "P2PIn", "X")
        # å°†ev_fwdæ·»åŠ åˆ°å½“å‰è¿™ä¸ªP2POut Yäº‹ä»¶çš„éœ€æ±‚è¾“å…¥åˆ—è¡¨ä¸­ï¼Œè¡¨ç¤ºå‰å‘è®¡ç®—çš„äº‹ä»¶å®Œæˆåæ‰èƒ½å¼€å§‹P2POut
        ev_y.inputs_add_ev(ev_fwd) 
        # å°†å®ä¾‹åŒ–çš„äº‹ä»¶æ·»åŠ åˆ°ä¸¤ä¸ªå­—å…¸ä¸­
        ev_y.add_to(events, stream_events)

    # è‹¥Out['Y']æœ€åä¸€å±‚çš„åª’ä»‹ä¸ºMSGï¼Œè¿™ç§æƒ…å†µä¸ºæœ€åä¸€ä¸ªfwd
    # ğŸ“Œäº‹å®ä¸Šï¼ŒFWDå‘é€Yçš„åª’ä»‹æ ¹æœ¬å°±ä¸ä¼šæ˜¯MSG
    elif vt.Out["Y"][vt.layers[-1]].medium == "MSG": # last fwd MSG
        # å®ä¾‹åŒ–ä¸€ä¸ªSwap out Yäº‹ä»¶
        ev_y = Event(vt, i, ev_fwd.spi, "SwapOut", "Y")
        ev_y.inputs_add_ev(ev_fwd)
        ev_y.add_to(events, stream_events)
        # "MSGY"
        # å¯¹æœ€åä¸€fwdä»»åŠ¡ï¼Œè¿˜éœ€åˆ›å»ºCPU MSGYäº‹ä»¶ï¼Œå¯èƒ½ä»£è¡¨CPUä¸Šè¾“å‡ºæˆ–è¾“å…¥Yçš„äº‹ä»¶
        indice_bwd = [i] if ubscvt is None else ubscvt.find_idx_ubwd(i)
        us_bwd = [u] if ubscvt is None else ubscvt.find_converted(i)
        for i_bwd, u_bwd in zip(indice_bwd, us_bwd):
            ev_msg = Event(vt, i_bwd, ev_fwd.spi, "CPU", "MSGY", ubs=u_bwd)            
            # å°†ev_yæ·»åŠ åˆ°MSGYäº‹ä»¶çš„inputsåˆ—è¡¨ä¸­ï¼Œè¡¨ç¤ºSwapout Yä¹‹åæ‰èƒ½æ‰§è¡ŒCPUä¸Šå‘é€Yçš„äº‹ä»¶
            ev_msg.inputs_add_ev(ev_y)
            ev_msg.add_to(events, stream_events)
    elif vt.Out["Y"][vt.layers[-1]].medium == "SWP": # vDP only
        ev_y = Event(vt, i, ev_fwd.spi, "SwapOut", "Y")
        # å³FWDå®Œæˆåï¼Œæ‰èƒ½Swapout Y
        ev_y.inputs_add_ev(ev_fwd) 
        ev_y.add_to(events, stream_events)
    else:
        raise ValueError
    
    return ev_y

# 1.è‹¥taskçš„In['dY']çš„æœ€åä¸€å±‚åª’ä»‹ä¸ºP2Pï¼Œå®ä¾‹åŒ–ä¸€ä¸ªP2PIn dYäº‹ä»¶å¹¶åŠ å…¥åˆ°ä¸¤ä¸ªå­—å…¸ä¸­ï¼Œå°†å¯¹åº”çš„é‚£ä¸ªp2pä»»åŠ¡ä»¥å­—ç¬¦ä¸²çš„å½¢å¼èµ‹ç»™
#   è°ƒç”¨è¯¥å‡½æ•°çš„eventçš„peer_idå±æ€§
#   vDPï¼šè‹¥taskçš„In['dY']çš„æœ€åä¸€å±‚åª’ä»‹ä¸ºSwapInï¼Œ...ï¼Œå°†å…¶å·¦è¾¹taskçš„SwapOut dXäº‹ä»¶åŠ å…¥åˆ°è¾“å…¥ä¾èµ–ä¸­
# 2.å°† Compute REC äº‹ä»¶åŠ å…¥åˆ°P2PIn dYçš„ä¾èµ–äº‹ä»¶ä¸­ï¼Œè¡¨ç¤ºå½“å‰ä»»åŠ¡çš„ç¬¬iä¸ªubatchçš„åå‘Compute RECäº‹ä»¶å®Œæˆåï¼Œ
#   æ‰èƒ½å¼€å§‹å½“å‰ubatchä¸Šçš„In dYäº‹ä»¶
def In_dY(vt, i, events, stream_events, left_vt, left2_vt, TASKS, ev_w, prefetch_after_rec, prefetch_offload):
    # assert 'Bn'
    if vt.In["dY"][vt.layers[-1]].medium == "P2P": # P2PdY
        # å®ä¾‹åŒ–ä¸€ä¸ªP2PIn dYäº‹ä»¶
        ev_dy = Event(vt, i, 0, "P2PIn", "dY")
        # å°†å¯¹åº”çš„é‚£ä¸ªp2pä»»åŠ¡ä»¥å­—ç¬¦ä¸²çš„å½¢å¼èµ‹ç»™è°ƒç”¨è¯¥å‡½æ•°çš„eventçš„peer_idå±æ€§
        ev_dy.register_peer(TASKS, i, 0, "P2POut", "dX")
    elif vt.In["dY"][vt.layers[-1]].medium == "SWP": # LocaldY of vDP only
        # å®ä¾‹åŒ–ä¸€ä¸ªSwapIn dYäº‹ä»¶
        ev_dy = Event(vt, i, 0, "SwapIn", "dY")
        # å°†å…¶å·¦è¾¹taskçš„SwapOut dXäº‹ä»¶åŠ å…¥åˆ°è¾“å…¥ä¾èµ–ä¸­
        ev_dy.inputs_add(left_vt, i, 0, "SwapOut", "dX") # swap dependency
        assert left_vt is not None
    else:
        assert False
    
    if prefetch_offload:
        if i == 0:
            if left_vt is None: # 1st task
                ev_dy.add_to(events, stream_events)
            else: # prefetch at left vt
                if prefetch_after_rec or (left_vt.type == "BWD" and not left_vt.has_criterion): # prefetch_after_rec: True for vDP, False for vPP
                    ev_dy.inputs_add(left_vt, len(left_vt.ubatchszs)-1, -1, "Compute", "REC")
                else: # FWD or BWD(criterion)
                    if len(left_vt.ubatchszs) >= 2: # double buffer
                        ev_dy.inputs_add(left_vt, len(left_vt.ubatchszs)-2, -1, "Compute", left_vt.type)
                    else: # left_vt has only 1 ubatch
                        if left2_vt is not None:
                            ev_dy.inputs_add(left2_vt, 0, 0, "Compute", "DEL")
                ev_dy.add_to(events, stream_events)
                ev_w.add_to(events, stream_events)
        else: 
            ev_dy.inputs_add(vt, i-1, 0, "Compute", "REC")
            ev_dy.add_to(events, stream_events)
    else:
        # å°† Compute REC äº‹ä»¶åŠ å…¥åˆ°P2PIn dYçš„ä¾èµ–äº‹ä»¶ä¸­ï¼Œè¡¨ç¤ºå½“å‰ä»»åŠ¡çš„ç¬¬iä¸ªubatchçš„åå‘Compute RECäº‹ä»¶å®Œæˆåï¼Œ
        # æ‰èƒ½å¼€å§‹å½“å‰ubatchä¸Šçš„In dYäº‹ä»¶
        ev_dy.inputs_add(vt, i, 0, "Compute", "REC")
        ev_dy.add_to(events, stream_events)
    
    return ev_dy

# 1.å®ä¾‹åŒ–ä¸€ä¸ªCompute RECäº‹ä»¶(é‡è®¡ç®—äº‹ä»¶)ï¼Œå¹¶å°†å…¶åŠ å…¥åˆ°ä¸¤ä¸ªå­—å…¸ä¸­
# 2.è‹¥å½“å‰æ˜¯é¦–ä¸ªmicro batchï¼Œéœ€å°†ev_wï¼ˆå³SwapIn WBï¼‰äº‹ä»¶ä½œä¸ºè¾“å…¥ä¾èµ–
# 3.å®ä¾‹åŒ–ä¸€ä¸ªCompute BWDäº‹ä»¶ï¼Œå¹¶å°†å…¶åŠ å…¥åˆ°ä¸¤ä¸ªå­—å…¸ä¸­
# è¿”å›è¿ä¸ªäº‹ä»¶ï¼šCpmpute RECäº‹ä»¶ã€Compute BWDäº‹ä»¶
def Compute_BWD(vt, i, events, stream_events, ev_w, ev_x, ev_dy):
    # å®ä¾‹åŒ–ä¸€ä¸ªCompute RECäº‹ä»¶
    # å¾ˆæ˜¾ç„¶æ˜¯é‡è®¡ç®—äº‹ä»¶
    ev_rec = Event(vt, i, 0, "Compute", "REC")
    # è‹¥å½“å‰æ˜¯é¦–ä¸ªmicro batchï¼Œéœ€å°†ev_wï¼ˆå³SwapIn WBï¼‰äº‹ä»¶ä½œä¸ºè¾“å…¥ä¾èµ–
    if i == 0:
        ev_rec.inputs_add_ev(ev_w)
    # å°†è¾“å…¥Xäº‹ä»¶ä½œä¸ºä¾èµ–
    ev_rec.inputs_add_ev(ev_x) # Bc: inputX, Bn: stashX
    ev_rec.add_to(events, stream_events)
    
    # å®ä¾‹åŒ–ä¸€ä¸ªCompute BWDäº‹ä»¶
    ev_bwd = Event(vt, i, 0, "Compute", "BWD")
    if ev_dy is not None: # "Bn"
        ev_bwd.inputs_add_ev(ev_dy)
    ev_bwd.add_to(events, stream_events)
    
    # è¿”å›è¿ä¸ªäº‹ä»¶ï¼šCpmpute RECäº‹ä»¶ã€Compute BWDäº‹ä»¶
    return ev_rec, ev_bwd

# ä¸¤ç§æƒ…å†µ
# 1.è‹¥ä»»åŠ¡çš„Out[dX]çš„é¦–å±‚çš„åª’ä»‹ä¸ºP2P
#   1.1.å®ä¾‹åŒ–ä¸€ä¸ªP2POut dXäº‹ä»¶ ev_dxï¼Œå¹¶åŠ å…¥åˆ°ä¸¤ä¸ªå­—å…¸ä¸­
#   1.2.å°†å¯¹åº”çš„é‚£ä¸ªp2pä»»åŠ¡ä»¥å­—ç¬¦ä¸²çš„å½¢å¼èµ‹ç»™è°ƒç”¨è¯¥å‡½æ•°çš„ ev_dx çš„peer_idå±æ€§
#   1.3.å°† ev_bwdï¼ˆå³ç¬¬iä¸ª compute BWDäº‹ä»¶ï¼‰ä½œä¸ºå½“å‰äº‹ä»¶çš„è¾“å…¥ä»¥æ¥
# 2.è‹¥ä»»åŠ¡çš„Out[dX]çš„é¦–å±‚çš„åª’ä»‹ä¸ºSWPï¼Œè¯´æ˜ä¸ºvDP
#   2.1.å®ä¾‹åŒ–ä¸€ä¸ªSwapOut dXä»»åŠ¡,å¹¶åŠ å…¥åˆ°ä¸¤ä¸ªå­—å…¸ä¸­
#   2.2.å°† ev_bwdï¼ˆå³ç¬¬iä¸ª compute BWDäº‹ä»¶ï¼‰ä½œä¸ºå½“å‰äº‹ä»¶çš„è¾“å…¥ä»¥æ¥
def Out_dX(vt, i, events, stream_events, TASKS, ev_bwd):
    if vt.layers[0] in vt.Out["dX"]:
        # assert not vt.has_data
        if vt.Out["dX"][vt.layers[0]].medium == "P2P": # P2PdX
            ev_dx = Event(vt, i, 0, "P2POut", "dX")
            ev_dx.register_peer(TASKS, i, -1, "P2PIn", "dY")
            ev_dx.inputs_add_ev(ev_bwd)
            ev_dx.add_to(events, stream_events)
        elif vt.Out["dX"][vt.layers[0]].medium == "SWP": # vDP only
            ev_dx = Event(vt, i, 0, "SwapOut", "dX")
            ev_dx.inputs_add_ev(ev_bwd)
            ev_dx.add_to(events, stream_events)
        else:
            assert False
    else:
        ev_dx = None
    
    return ev_dx

def Compute_ARD(vt, events, stream_events, num_gpus, prefetch_offload, ev_dx):
    # assert 'vDP'-['Bc','Bn']
    if num_gpus > 1:
        ev_ard = Event(vt, 0, 0, "Compute", "ARD")
        ev_ard.add_to(events, stream_events)
        if not prefetch_offload and ev_dx is not None:
            ev_ard.inputs_add_ev(ev_dx)
    else:
        ev_ard = None
    
    return ev_ard

# å®ä¾‹åŒ–ä¸€ä¸ªSwapOut dWBäº‹ä»¶ï¼Œå°†å…¶åŠ å…¥ä¸¤ä¸ªå­—å…¸ä¸­ï¼Œå¹¶å°†æœ€åä¸€åå‘è®¡ç®—äº‹ä»¶ä½œä¸ºè¯¥äº‹ä»¶çš„è¾“å…¥ä¾èµ–
def Out_dWB(vt, events, stream_events, ev_bwd, ev_ard, prefetch_offload, ev_dx):
    # assert ["Bc",'Bn']
    ev_dw = Event(vt, 0, 0, "SwapOut", "dWB")
    ev_dw.inputs_add_ev(ev_bwd)
    if ev_ard is not None: # 'vDP' and num_gpus > 1
        ev_dw.inputs_add_ev(ev_ard)
    elif not prefetch_offload and ev_dx is not None: # 'vDP' and num_gpus == 1
        ev_dw.inputs_add_ev(ev_dx)
    ev_dw.add_to(events, stream_events)
    
    return ev_dw

# 
def Compute_DEL(vt, events, stream_events, ev_dw, prefetch_offload, ev_y):
    # å®ä¾‹åŒ–ä¸€ä¸ªCompute DELäº‹ä»¶
    ev_del = Event(vt, 0, 0, "Compute", "DEL")
    # åå‘ä¼ æ’­æ—¶å‘ç”Ÿï¼šè‹¥ev_dwå­˜åœ¨ï¼ˆSwapOut dWBäº‹ä»¶ï¼‰ï¼Œå°†å…¶ä½œä¸ºè¯¥äº‹ä»¶çš„è¾“å…¥ä¾èµ–
    if ev_dw is not None: # 'Bc','Bn'
        ev_del.inputs_add_ev(ev_dw)
    elif not prefetch_offload and ev_y is not None: # 'F' 
        ev_del.inputs_add_ev(ev_y)
    # 1.å°†è°ƒç”¨è¯¥æ–¹æ³•çš„Eventå®ä¾‹ï¼Œæ·»åŠ åˆ°eventsè¿™ä¸ªå­—å…¸ä¸­ã€‚{ id: Event() } 
    # 2.å°†Eventæ·»åŠ åˆ° self.stream è¿™ç§ç±»å‹çš„äº‹ä»¶é˜Ÿåˆ—ä¸­ã€‚per_stream_eventsï¼š{stream: [Event()]}
    # 3.å¯¹Eventçš„poså±æ€§(åœ¨é˜Ÿåˆ—ä¸­çš„ä¸‹æ ‡)èµ‹å€¼ï¼Œå³é˜Ÿåˆ—çš„æœ€åä¸€ä¸ªä½ç½®
    ev_del.add_to(events, stream_events)
    
    return ev_del

# 1.å®ä¾‹åŒ–ä»¥ä¸€ä¸ªCPU Updateäº‹ä»¶ï¼Œå¹¶å°†å…¶åŠ å…¥åˆ°ä¸¤ä¸ªå­—å…¸ä¸­
# 2.å°†SwapOut dWBäº‹ä»¶ä½œä¸ºå½“å‰äº‹ä»¶çš„ä¾èµ–äº‹ä»¶
def CPU_Update(vt, events, stream_events, left_vt):
    assert left_vt is not None and left_vt.layers == vt.layers
    # å®ä¾‹åŒ–ä»¥ä¸€ä¸ªCPU Updateäº‹ä»¶
    ev = Event(vt, 0, 0, "CPU", "Update")
    # å°†SwapOut dWBäº‹ä»¶ä½œä¸ºå½“å‰äº‹ä»¶çš„ä¾èµ–äº‹ä»¶
    ev.inputs_add(left_vt, 0, 0, "SwapOut", "dWB")
    ev.add_to(events, stream_events)
    
    return ev

class Dispatcher(object):
    def __init__(self, rank_stream_events):# { rank: { stream: [Event()] }
        self.event_queues = deque([]) # non-empty event queues across all ranks
        #                    [ rank: {stream: [Event()], ... } , ... ]
        for stream_events in rank_stream_events.values(): # can be empty rank
            # eq:ä¸€ä¸ªrankä¸­çš„streamå¯¹åº”çš„è£…ç€eventçš„list 
            # eqæ˜¯ä¸€ä¸ªdeque:
            # [Event(),...]
            for eq in stream_events.values():
                assert len(eq) != 0
                self.event_queues.append(eq)
        # for rank, stream_events in rank_stream_events.items(): 
        #     for k in [k for k, v in stream_events.items() if v == []]:
        #         del stream_events[k]
        # for k in [k for k, v in rank_stream_events.items() if not v]:
        #     del rank_stream_events[k]
        self.num_streams = len(self.event_queues) # statisics
        print(f".....num_streams:{self.num_streams}")

    # 
    def _check_inputs(self, ev):
        if ev.inputs == []:
            return True
        else:
            return min([inev.is_done for inev in ev.inputs]) 
            # return min([self.events[id].is_done for id in ev.inputs]) 
            # Any False -> False; All True -> True
            
    # éå† event_queues ä¸­æ‰€æœ‰çš„listï¼Œç›´åˆ°æŸä¸ªlistçš„é¦–ä¸ªeventæ²¡æœ‰è¾“å…¥ä¾èµ–ï¼Œè¿”å›è¯¥event
    # è‹¥ä¸å­˜åœ¨è¿™æ ·ä¸€ä¸ªäº‹ä»¶ï¼Œåˆ™è¿”å›æ‰€æœ‰stream listçš„é¦–ä¸ªevent
    def dispatch(self):
        # è‹¥event_queuesä¸­æ²¡æœ‰ä»»ä½•event dequeäº†ï¼Œç›´æ¥è¿”å›doneå­—ç¬¦ä¸²
        if len(self.event_queues) == 0:
            return "done" # all events dispatched
        # æœ€å¤§æ­¥æ•°ä¸ºï¼Œevent_queuesÃ—2ï¼Œå³æ‰€æœ‰GPUä¸Šæ‰€æœ‰çš„streamçš„æ•°é‡Ã—2
        # åˆ†æğŸ“Œï¼šforå¾ªç¯çš„ä½œç”¨æ˜¯ä¿è¯æ‰€æœ‰çš„event dequeéƒ½è¢«éå†ä¸€éï¼Œç¡®ä¿èƒ½returnä¸€ä¸ªev
        #         å°½ç®¡æ˜¯ä¸€ä¸ªforå¾ªç¯ï¼Œä½†æœ¬æ„æ˜¯åªè¿”å›ä¸€ä¸ªevï¼Œå¹¶ä¸æ˜¯è¦è¿”å›æ‰€æœ‰éå†åˆ°çš„ev
        max_step = len(self.event_queues)*2
        for _ in range(max_step):
            # try a non-empty queue
            # ä»event_queuesä¸­å¼¹å‡ºä¸€ä¸ªdeque, å³æŸä¸ªrankçš„è£…ç€æŸä¸ªstreamæ‰€æœ‰eventçš„list
            events = self.event_queues.popleft() # round-robin abitration
            # è‹¥ events[0]ï¼Œå³ä¸€ä¸ªrankä¸Šçš„æŸä¸ªstreamä¸Šçš„é¦–ä¸ªäº‹ä»¶ï¼Œæ²¡æœ‰è¾“å…¥ä¾èµ–ï¼Œæˆ–å…¶ä¾èµ–å…¨éƒ¨æ‰§è¡Œå®Œäº†ï¼Œåˆ™æ‰§è¡Œï¼š
            if self._check_inputs(events[0]): # event found
                # å¼¹å‡ºeventsåˆ—è¡¨çš„ç¬¬ä¸€ä¸ªevent
                ev = events.popleft()
                # è‹¥eventsä¸­è¿˜æœ‰å…¶ä»–eventï¼Œé‡æ–°å°†eventsåˆ—è¡¨æ”¾å› event_queues åé¢
                if len(events) != 0:
                    self.event_queues.append(events)
                # è¿”å›è¯¥evï¼Œç”¨äºæ¨¡æ‹Ÿè¯¥evçš„æ‰§è¡Œæ—¶é—´
                return ev # dispatch a single event
            # è‹¥listçš„é¦–ä¸ªäº‹ä»¶æœ‰è¾“å…¥ä¾èµ–è¿˜æ²¡æ‰§è¡Œå®Œï¼Œåˆ™é‡æ–°æŠŠè¯¥listæ”¾å›é˜Ÿåˆ—ä¸­
            self.event_queues.append(events)
        # deadlock 
        # è‹¥æ²¡æœ‰æ‰¾åˆ°ä¸€ä¸ªæ²¡æœ‰è¾“å…¥ä¾èµ–çš„äº‹ä»¶ï¼Œåˆ™è¿”å›æ‰€æœ‰stream listçš„é¦–ä¸ªevent
        return [events[0] for events in self.event_queues] # dealock events

class Executor(object):
    def __init__(self, args, non_empty_gpus, CONFIGS, TASKS, rank_stream_events):
        self.prof = args.prof
        self.bw_swap = args.bw_swap
        self.bw_p2p = args.bw_p2p
        self.bw_msg = args.bw_msg
        self.time_del = args.time_del # è®¾ç½®å¥½çš„å€¼ï¼Œé»˜è®¤ä¸º0.04
        self.mode = CONFIGS["mode"]
        self.N = non_empty_gpus # CONFIGS["N"]
        self.R = CONFIGS["R"]
        self.TASKS = TASKS; assert TASKS[-1].idx == len(TASKS)-1, "TASKS is global"
        self.use_random = args.use_random
        if self.use_random:
            random.seed(args.seed)
            np.random.seed(args.seed)
        # { rank : { stream : last Event's end time } or {} }
        self.rank_stream_endtime = ODict()
        for r, stream_events in rank_stream_events.items(): # can be empty rank
            self.rank_stream_endtime[r] = ODict()
            for s in stream_events.keys():
                self.rank_stream_endtime[r][s] = 0.0 # sec
        # { rank : compute time accumulated }
        self.rank_compute = ODict()
        for r in rank_stream_events.keys(): # can be empty rank
            self.rank_compute[r] = 0.0 # sec
        # count executed events
        self.cnt = 0 
    
    # ç›´æ¥æ‹¿åˆ°æˆ–æ ¹æ®å¸¦å®½è®¡ç®—äº‹ä»¶çš„æŒç»­æ—¶é—´
    def _duration(self, ev):
        ubs = ev.ubs
        l_start, l_end = ev.layers[0], ev.layers[-1] # subpack layers
        # ğŸ“ŒRECä¹Ÿåšå’ŒFWDç›¸åŒçš„äº‹æƒ…ï¼ŒçŒœæµ‹RECæ˜¯recompute
        # ç­”ï¼šRECå°±æ˜¯RECompute
        if ev.kind in ["FWD","REC"]:
            # æ ¹æ®type, ubatchsizeä» ç¬¬2é˜¶æ®µ ä¿å­˜çš„classä¸­å–å‡º [start_id, end_id] è¿™å‡ å±‚ä¿å­˜çš„æ—¶é—´ï¼ˆtypeä¸ºFWD/BWD/UDPï¼‰
            return time_of_pack(self.prof, "FWD", ubs, l_start, l_end, interp_ubatchsize=True) # sec
        elif ev.kind == "BWD":
            # åå‘ä¼ æ’­çš„æ—¶é—´åŒ…å«äº†è¯¥å±‚é‡è®¡ç®—çš„æ—¶é—´ï¼Œå› æ­¤è¦å‡å»å‰å‘è®¡ç®—çš„æ—¶é—´
            return time_of_pack(self.prof, "BWD", ubs, l_start, l_end,     interp_ubatchsize=True) - \
            time_of_pack(self.prof, "FWD", ubs, l_start, l_end,     interp_ubatchsize=True)
        
        # è‹¥åœ¨2é˜¶æ®µæ²¡æœ‰ä¸º
        elif ev.kind == "Update":
            return time_of_pack(self.prof, 'UPD', None, l_start, l_end, offload_optim=True)
        # åˆ é™¤äº‹ä»¶èŠ±è´¹çš„æ—¶é—´ï¼Œdelete
        elif ev.kind == "DEL":
            return self.time_del # sec # empirical value
        # 
        elif ev.kind == "ARD":
            W = model_size_of_pack(self.prof, 'W', l_start, l_end) # bytes
            B = model_size_of_pack(self.prof, 'B', l_start, l_end) # bytes
            return 2.*(self.N-1)/self.N*(W+B)/self.bw_p2p # sec
        
        # WBå’Œå…¶å¯¼æ•°ï¼Œåªèƒ½ä»¥swapçš„æ–¹å¼é€šä¿¡ï¼Œé™¤ä»¥çš„å¸¦å®½ä¸ºself.bw_swap/self.N
        elif ev.kind in ["WB","dWB"]:
            W = model_size_of_pack(self.prof, 'W', l_start, l_end) # bytes
            B = model_size_of_pack(self.prof, 'B', l_start, l_end) # bytes
            return float(W+B)/(self.bw_swap/self.N) # FWD-SwapIn/BWD-SwapIn/BWD-SwapOut in vDP/vPP
        
        # è‹¥streamçš„åå­—ä»¥Swapå¼€å§‹ï¼Œé™¤ä»¥çš„å¸¦å®½ä¸ºself.bw_swap/self.N
        # è‹¥streamçš„åå­—ä»¥P2På¼€å§‹ï¼Œé™¤ä»¥çš„å¸¦å®½ä¸ºself.bw_p2p
        elif ev.kind in ["sX","X","dX"]:
            X = self.prof["XMETA"].get_bytes(ubs, l_start, interp=True)
            if ev.stream.startswith("Swap"):
                return float(X)/(self.bw_swap/self.N) # FWD/BWD SwapIn/SwapOut in vDP/vPP
            elif ev.stream.startswith("P2P"):
                return float(X)/(self.bw_p2p) # FWD-P2PIn/BWD-P2POut in vPP
            else:
                raise NotImplementedError 
            
        # è‹¥streamçš„åå­—ä»¥Swapå¼€å§‹ï¼Œé™¤ä»¥çš„å¸¦å®½ä¸ºself.bw_swap/self.N
        # è‹¥streamçš„åå­—ä»¥P2På¼€å§‹ï¼Œé™¤ä»¥çš„å¸¦å®½ä¸ºself.bw_p2p
        elif ev.kind in ["Y","dY"]:
            Y = self.prof["XMETA"].get_bytes(ubs, l_end+1, interp=True) \
                if l_end+1 < self.R else 0. 
            if ev.stream.startswith("Swap"):
                return float(Y)/(self.bw_swap/self.N) # FWD-SwapOut/BWD-SwapIn in vDP
            elif ev.stream.startswith("P2P"):
                return float(Y)/(self.bw_p2p) # FWD-P2PIn/BWD-P2POut in vPP 
            else:
                raise NotImplementedError 
            
        # MSGé™¤ä»¥çš„å¸¦å®½ä¸º (self.bw_msg/self.N)
        elif ev.kind.startswith("MSG"): # ["MSGsX","MSGdX","MSGY"]
            kind = ev.kind.replace("MSG","")
            if kind == "sX":
                # å³æ‰¾åˆ°å¯¹åº”ä»»åŠ¡çš„GPUåºå·ï¼ŒæŸ¥çœ‹ä¸¤è€…æ˜¯å¦åœ¨ä¸€ä¸ªGPUä¸Šï¼Œè‹¥åœ¨ï¼Œåˆ™éœ€è¦ä¼ è¾“çš„æ•°æ®é‡ä¸º0
                if self.TASKS[ev.vt.Out["X"][l_start].idx].rank == ev.vt.rank:
                    M = 0. # self send
                else:
                    # l_startè¿™ä¸€å±‚åœ¨ubsä¸‹çš„ è¾“å…¥ çš„å¤§å°
                    M = self.prof["XMETA"].get_bytes(ubs, l_start, interp=True)

            # ğŸ“Œå®é™…ä¸Šï¼ŒdXçš„åª’ä»‹å°±ä¸å¯èƒ½æ˜¯MSG
            elif kind == "dX":
                if self.TASKS[ev.vt.Out["dX"][l_start].idx].rank == ev.vt.rank:
                    M = 0. # self send
                else:
                    M = self.prof["XMETA"].get_bytes(ubs, l_start, interp=True)

            # ğŸ“Œå®é™…ä¸Šï¼ŒYçš„åª’ä»‹å°±ä¸å¯èƒ½æ˜¯MSG
            elif kind in "Y":
                if self.TASKS[ev.vt.Out["Y"][l_end].idx].rank == ev.vt.rank:
                    M = 0. # self send
                else:
                    M = self.prof["XMETA"].get_bytes(ubs, l_end+1, interp=True) \
                        if l_end+1 < self.R else 0.
            else:
                raise NotImplementedError
            return float(M)/(self.bw_msg/self.N)*2. # CPU memory is half-duplex
        else:
            raise NotImplementedError 
            
    # 1.æ‹¿åˆ°evçš„èµ·äº‹æ—¶é—´ï¼ševçš„èµ·å§‹æ—¶é—´ä¸ºå…¶æ‰€æœ‰ä¾èµ–äº‹ä»¶çš„ç»“æŸæ—¶é—´å’Œevæ‰€åœ¨çš„rankä¸Šæ‰€åœ¨streamçš„ç»“æŸæ—¶é—´ä¸­çš„æœ€å¤§å€¼
    # 2.è®¡ç®—evçš„æŒç»­æ—¶é—´ï¼šç›´æ¥æ‹¿åˆ°æˆ–æ ¹æ®å¸¦å®½è®¡ç®—äº‹ä»¶çš„æŒç»­æ—¶é—´
    # 3.æ›´æ–°evæ‰€åœ¨çš„rankä¸Šæ‰€åœ¨streamçš„ç»“æŸæ—¶é—´ï¼Œå³evçš„ç»“æŸæ—¶é—´
    # 4.ev.is_done = True
    # 5.æ›´æ–°è¯¥GPUä¸Šçš„æ€»è®¡ç®—æ—¶é—´
    # 6.æ›´æ–°æ‰§è¡Œè¿‡çš„eventæ•°
    def execute(self, ev):
        # æ‹¿åˆ°evçš„èµ·äº‹æ—¶é—´ï¼š
        # evçš„èµ·å§‹æ—¶é—´ä¸ºå…¶æ‰€æœ‰ä¾èµ–äº‹ä»¶çš„ç»“æŸæ—¶é—´å’Œevæ‰€åœ¨çš„rankä¸Šæ‰€åœ¨streamçš„ç»“æŸæ—¶é—´ä¸­çš„æœ€å¤§å€¼
        ev.begin = max([inev.end for inev in ev.inputs] + 
                       [self.rank_stream_endtime[ev.vt.rank][ev.stream]])
        # è®¡ç®—evçš„æŒç»­æ—¶é—´
        # è¯¥å‚æ•°é»˜è®¤ä¸ºfalseï¼Œç•¥
        if self.use_random:
            ev.dur = random.uniform(0, 1.0) # sec
            if ev.stream.startswith("P2P"):
                ev.dur = 0.5
        else:
            # ç›´æ¥æ‹¿åˆ°æˆ–æ ¹æ®å¸¦å®½è®¡ç®—äº‹ä»¶çš„æŒç»­æ—¶é—´
            ev.dur = self._duration(ev) # sec
        ev.is_done = True
        # æ›´æ–°evæ‰€åœ¨çš„rankä¸Šæ‰€åœ¨streamçš„ç»“æŸæ—¶é—´ï¼Œå³evçš„ç»“æŸæ—¶é—´
        # ev.endæ˜¯ä¸€ä¸ªå‡½æ•°ï¼šreturn self.begin + self.dur
        self.rank_stream_endtime[ev.vt.rank][ev.stream] = ev.end
        # æ›´æ–°GPUä¸Šçš„æ€»è®¡ç®—æ—¶é—´
        if ev.kind in ["FWD","REC","BWD"]:
            self.rank_compute[ev.vt.rank] += ev.dur
        # æ›´æ–°æ‰§è¡Œè¿‡çš„eventæ•°
        self.cnt += 1
    
    def end(self):
        ### end time
        # æ¯ä¸ªrankä¸­æ‰€æœ‰streamä¸­æœ€å¤§çš„ç»“æŸæ—¶é—´
        self.per_rank_endtime = []
        # ODict:{stream:endtimeï¼Œ...}
        # stream_endtimeï¼šå¯¹åº”ä¸€ä¸ªrankçš„å­—å…¸ï¼Œé‡Œé¢è£…ç€å¤šä¸ªå½¢å¦‚ stream:endtime çš„é”®å€¼å¯¹ 
        for stream_endtime in self.rank_stream_endtime.values(): # can be empty rank
            # æ‹¿åˆ°å½“å‰rankä¸Šæ‰€æœ‰streamä¸­æœ€å¤§çš„ç»“æŸæ—¶é—´
            if stream_endtime:
                et = max([endtime for endtime in stream_endtime.values()])
            else: # empty rank
                et = 1.E-10 # zero
            # å°†æ‹¿åˆ°çš„æ—¶é—´æ”¾åˆ°Listä¸­
            self.per_rank_endtime.append(et)
        # å¾—åˆ°å…¨å±€çš„endtimeï¼Œå³æ‰€æœ‰rankçš„æ‰€æœ‰streamä¸­æœ€å¤§çš„ç»“æŸæ—¶é—´
        self.global_endtime = max(self.per_rank_endtime)
        ### end idle ratio
        # å¯¹æ¯ä¸€ä¸ªrankçš„æœ€ç»ˆendtimeï¼Œè®¡ç®—å…¶ç»“æŸåidleçš„æ¯”ç‡ï¼Œå³ç­‰å¾…æ—¶é—´/æ€»çš„æ‰§è¡Œæ—¶é—´(å…¨å±€endtime)
        self.per_rank_endidle = [ (self.global_endtime - et) / self.global_endtime 
                                    for et in self.per_rank_endtime ]
        # å¾—åˆ°æœ€å¤§çš„per_rank_endidle
        self.max_endidle = max(self.per_rank_endidle)
        # è®¡ç®—å¹³å‡çš„idleæ¯”ç‡ï¼Œå³æ¯ä¸ªrankä¸Šæ¯ä¸ªæµä¸­æœ€å¤§çš„ç»“æŸæ—¶é—´åè¿˜éœ€ç­‰å¾…çš„æ—¶é—´/global_endtimeçš„å‡å€¼
        self.avg_endidle = sum(self.per_rank_endidle)/len(self.per_rank_endidle)
        ### compute ratio
        num_ranks = len(self.rank_compute)
        # è®¡ç®—æ¯ä¸ªGPUè®¡ç®—æ—¶é—´å æ€»æ—¶é—´çš„æ¯”ä¾‹ï¼Œå³æ¯ä¸€ä¸ªGPUä¸Šæ€»çš„è®¡ç®—æ—¶é—´/global_endtimeã€‚å°†è¿™äº›æ¯”ç‡åŠ èµ·æ¥/GPUæ€»æ•°ï¼Œ
        # å¾—åˆ°å¹³å‡çš„è®¡ç®—å å…¨å±€æ€»æ—¶é—´çš„æ¯”ä¾‹
        self.avg_compute_to_globaltime = sum([ ct/self.global_endtime 
                                            for ct in self.rank_compute.values() ]) \
                                            / num_ranks
        # è®¡ç®—æ¯ä¸ªGPUä¸Šè®¡ç®—æ—¶é—´ä¸è¯¥GPUä¸Šæ€»æ—¶é—´çš„æ¯”å€¼ï¼ŒåŠ åœ¨ä¸€èµ·å†é™¤ä»¥GPUæ•°é‡ã€‚å³å¹³å‡çš„è®¡ç®—å’Œå•ä¸ªGPUä¸Šçš„æ€»æ—¶é—´çš„å æ¯”
        self.avg_compute_to_ranktime = sum([ct/et 
                                            for ct, et in zip(self.rank_compute.values(), self.per_rank_endtime)]) \
                                            / num_ranks
    
def print_events(events):
    print("------- Event: ID, Inputs, Done, Name -------")
    for id, ev in events.items(): 
        assert id == ev.id
        print("%s, '%s'" % (ev, ev.name))
    print()

def print_rank_stream_events(rank_stream_events):
    for rank, per_stream_events in rank_stream_events.items(): 
        print("------- Rank %d's Stream : [Events] -------" % rank)
        for stream, events in per_stream_events.items():
            print("%s: [%s]" % (stream, ", ".join(ev.id for ev in events) ))
    print()

def debug(non_empty_gpus, events, rank_stream_events):
    non_empty_rank = 0
    for stream_events in rank_stream_events.values():
        if stream_events:
            non_empty_rank += 1
    assert non_empty_rank == non_empty_gpus
    print("[DEBUG] non_empty_gpus check: passed")
    for stream_events in rank_stream_events.values(): 
        for eq in stream_events.values():
            for e in eq:
                assert id(events[e.id]) == id(e), "%s vs %s"%(events[e.id], e)
    print("[DEBUG] same reference test: passed")
    for ev in events.values(): 
        for inev in ev.inputs:
            assert isinstance(inev, Event), "!! {} is not Event".format(inev)
    for stream_events in rank_stream_events.values():
        for eq in stream_events.values():
            for e in eq:
                for inev in e.inputs:
                    assert isinstance(inev, Event), "!! {} is not Event".format(inev)
    print("[DEBUG] inputs are events: passed")

class CofTask(object):
    """ The memory cost of a task.
        Assumption:
        0) math equation modeled cost
        1) optimizer on CPU
        2) equal ubatch size in a group, FWD or BWD
        3) vPP always use P2P for input and output
        4) ignore T
        base version:
        5) fetch W
        6) prefetch X with double buffering
        7) no prefetch X across Tasks
        8) offload Y with double buffering
        9) offload X with double buffering
    """
    def __init__(self, prof, mode, num_layers):
        self.prof = prof
        self.mode = mode
        self.R = num_layers
                
    def __call__(self, vt):
        l_start, l_end = vt.layers[0], vt.layers[-1]
        if vt.type == 'UPD':
            return 0.
            # Ctask = memory_of_pack(self.prof, 'UPD', None, l_start, l_end, offload_optim=self.offload_optim) # bytes
            # return float(Ctask)
        
        assert vt.type in ['FWD','BWD']
        # microbatch size
        ubs = vt.ubatchszs[0]
        # size
        # è¾“å…¥çš„å¤§å°
        InputX = self.prof["XMETA"].get_bytes(ubs, l_start, interp=True)
        # è‹¥vtçš„é¦–å±‚ä¸æ˜¯ç¬¬0å±‚ï¼Œåˆ™å…¶è¾“å‡ºçš„dXçš„å¤§å°å’Œä¼ å…¥çš„InputXçš„å¤§å°ç›¸åŒï¼ˆç¬¬0å±‚ä¸ä¼šå¾€å‰ä¼ dXäº†ï¼Œæ‰€ä»¥æ˜¯0ï¼‰
        dX = InputX if l_start != 0 else 0. 
        W = model_size_of_pack(self.prof, 'W', l_start, l_end) # bytes
        B = model_size_of_pack(self.prof, 'B', l_start, l_end) # bytes
        # è‹¥ä¸æ˜¯æœ€åä¸€å±‚ï¼Œå³è®¡ç®—æŸå¤±çš„å±‚ï¼Œè¿”å›l_end+1å±‚çš„è¾“å…¥ï¼Œå³l_endå±‚çš„è¾“å‡º
        # å¦åˆ™è¿”å›0
        Y = self.prof["XMETA"].get_bytes(ubs, l_end+1, interp=True) \
            if l_end != self.R-1 else 0. 
        # ä¼ è¿›æ¥çš„dYçš„å¤§å°å’Œä¼ å‡ºå»çš„Yçš„å¤§å°ç›¸åŒ
        dY = Y
        if vt.type == 'FWD':
            StashX = sum([ self.prof["XMETA"].get_bytes(ubs, l, interp=True) 
                            for l in vt.Out['X'].keys() ])       
        else:
            StashX = InputX # critierion or non-criterion
        # memory
        # å¯¹FWDï¼ŒBWDï¼šè¿”å›æ•´ä¸ªè®¡ç®—è¿‡ç¨‹ä¸­[l_start, l_end]äº§ç”Ÿçš„æ˜¾å­˜å ç”¨
        # å¯¹UDPï¼šè¿”å›0 ï¼Œå› ä¸ºä¼˜åŒ–å™¨è¢«å¸è½½åˆ°cpuäº†
        # â“ä¸åŒ…å«l_startçš„è¾“å…¥å—ï¼Ÿ
        Ccompute = memory_of_pack(self.prof, vt.type, ubs, l_start, l_end, interp_ubatchsize=True) # bytes
        # if vt.type == 'FWD' and vt.has_data:
        #     Ccompute -= InputX
        
        Ctask = 0.
        if self.mode == 'vPP' and vt.type == 'FWD':
            Ctask += InputX
            Ctask += Ccompute
            Ctask += Y
            Ctask += StashX    
        elif self.mode == 'vPP' and vt.type == 'BWD':
            Ctask += StashX*2 # include grad
            Ctask += dY
            Ctask += Ccompute
            Ctask += dX # â“ï¼šä¸Šé¢stashXä¸æ˜¯Ã—2äº†å—ï¼Œè¿™å—æ˜¯ä¸æ˜¯é‡å¤äº†
        elif self.mode == 'vDP' and vt.type == 'FWD':
            Ctask += InputX
            Ctask += Ccompute
            Ctask += Y
            Ctask += StashX
        elif self.mode == 'vDP' and vt.type == 'BWD': 
            Ctask += StashX*2 # include grad
            Ctask += dY
            Ctask += Ccompute
            Ctask += dX
        else:
            raise NotImplementedError
        return Ctask # bytes
