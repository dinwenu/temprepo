# Copyright (c) Microsoft Corporation.
# Licensed under the MIT license.

import os
import copy
import gc
import threading
import queue  # æ·»åŠ è¿™ä¸€è¡Œ
from collections import OrderedDict as ODict

import torch

from torch.cuda.nvtx import range_push as nvtx_range_push 
from torch.cuda.nvtx import range_pop as nvtx_range_pop 

from task_data_struct import Medium, vTask
import threadsafe_data_struct

import time

if os.environ.get('CUDA_LAUNCH_BLOCKING') in ['1','True', True]:
    MEMCPY_NONBLK = False
else:
    MEMCPY_NONBLK = True

# å°†cpuä¸Šæœ¬åœ°æ¨¡å‹çš„å‚æ•°å’Œbufferç§»åŠ¨åˆ°å›ºå®šå†…å­˜ä¸­ï¼Œä»¥ä¾¿æ›´é«˜æ•ˆåœ°å°†å‚æ•°ä¼ è¾“åˆ° GPUï¼Œå› ä¸ºåœ¨ä¼ è¾“æ—¶æ— éœ€é‡æ–°åˆ†é…å†…å­˜
def convert_to_pinned(local_model_cpu):
    ''' in-place convert a local model cpu to a pinned model (params and buffers: pinned, local, CPU, no grad) '''
    @torch.no_grad()
    def fn(m): # m = each module
        for key, param in m._parameters.items(): # OrderedDict([('weight', Parameter), ('bias', Parameter)])
            if param is not None:
                # no grad
                assert param.grad is None, "convert to pinned model requires no grad in input model"
                param.detach_()
                assert not param.requires_grad
                # pin param
                # pin_memory() æ˜¯ PyTorch ä¸­ Tensor å¯¹è±¡çš„ä¸€ä¸ªæ–¹æ³•ï¼Œç”¨äºå°†å¼ é‡å›ºå®šåœ¨å†…å­˜ä¸­çš„ç‰¹å®šä½ç½®ï¼Œ
                # ä¾‹å¦‚é’‰åœ¨ GPU å†…å­˜æˆ–å›ºå®šå†…å­˜ï¼ˆpinned memoryï¼‰ä¸­
                param.data = param.pin_memory() # in-place update and let python do the gc 
        for key, buf in m._buffers.items(): # OrderedDict([('running_mean', tensor), ('running_var', tensor), ('num_batches_tracked', tensor)])
            if buf is not None:
                assert not buf.requires_grad # buffer has no grad
                m._buffers[key] = buf.pin_memory() # in-place update and let python do the gc 
                assert not m._buffers[key].requires_grad
    local_model_cpu.apply(fn) # Applies ``fn`` recursively to every submodule (as returned by ``.children()`` as well as self.
    gc.collect()

class SharedOptimCPU(object):
    """ A wrapper class of shared optimizer (referring to each shared vlayer) on CPU.
        Data structure:
        o	a multiprocess-shared vlayer and optimizer
        o	a process-local pinned .grad as input buffer
        o	a process-local pinned model (param and buffs) as output buffer
        TODO: decouple pinned_model from here
    """
    # å°†å±‚çš„å‚æ•°å¯¹åº”çš„ä¼˜åŒ–å™¨çŠ¶æ€å…¨éƒ¨æ”¾å…¥å…±äº«å†…å­˜
    @torch.no_grad()
    def __init__(self, shared_model, optimizer, id=-1):
        """ Call this in parent process and before fork/spawn subprocess """ 
        self.id = id # vlayer_id
        if optimizer is None: # this wrapper is only for pinned model
            self.shared_model = shared_model
            self.shared_optimizer = None
            # print("[SharedOptimizer][id%d] optimizer is None; for pinned model only."%self.id)
        else:
            # confirm model and optimizer are on CPU
            # ç¡®ä¿å½“å‰è¿™ä¸ªå±‚çš„å‚æ•°å’Œå¯¹åº”çš„ä¼˜åŒ–å™¨çŠ¶æ€éƒ½ä¸åœ¨GPUä¸Š
            for param in shared_model.parameters():
                assert not param.is_cuda and param.is_shared()
            for param, state in optimizer.state.items():
                for k, v in state.items():
                    # print("..............:", self.id)
                    # print(k)
                    # print(v)
                    if isinstance(v, torch.Tensor):
                        assert not v.data.is_cuda
            # 1) create zero gradient 
            # å°†å‚æ•°çš„æ¢¯åº¦åˆå§‹åŒ–ä¸ºä¸å‚æ•°æ•°æ®å½¢çŠ¶ç›¸åŒçš„å…¨é›¶å¼ é‡
            for param in shared_model.parameters():
                param.grad = torch.zeros_like(param.data) # == torch.zeros(input.size(), input.dtype, input.layout, input.device, requires_grad=False)
                # Note: "param.grad = tensor" works, but "param.data.grad = tensor" doesn't work
                # Note: id(param.grad) == id(param.data.grad)
            # 2) force initialization of optimizer states (Bert, GPT2, Adam, SGD)
            # è°ƒç”¨ä¸€æ¬¡ä¼˜åŒ–å™¨çš„ step æ–¹æ³•ï¼Œä»¥å¼ºåˆ¶åˆå§‹åŒ–ä¼˜åŒ–å™¨çŠ¶æ€
            # print(f"ä¼˜åŒ–å™¨åˆå§‹åŒ–ä¹‹å‰ï¼š{optimizer.state}")
            # å¼ºåˆ¶åˆå§‹åŒ–ä¹‹å‰ï¼Œè¿™ä¸ªå­—å…¸æ˜¯ç©ºçš„
            # å¦å¤–éœ€è¦æ³¨æ„ï¼Œè¿™ä¸ªå­—å…¸å¯èƒ½æœ‰å¤šä¸ªé”®å€¼å¯¹ï¼Œå³å¤šä¸ª å‚æ•°ï¼š{step:,'exp_avg','exp_avg_sq'}
            optimizer.step() 
            # print(f"ä¼˜åŒ–å™¨åˆå§‹åŒ–ä¹‹åï¼š{optimizer.state}")
            # 3) move optimzer.state to shared memory
            # å°†ä¼˜åŒ–å™¨çŠ¶æ€æ”¾å…¥å…±äº«å†…å­˜ï¼ˆç”šè‡³è¿stepæ•°ä¹Ÿæ”¾è¿›å»äº†ï¼‰
            # print("[SharedOptimizer] sharing optimizer:")
            for param, state in optimizer.state.items(): # self.state = { param : {"step": 0, "exp_avg": tensor, "exp_avg_sq": tensor} } # per-param's optimization state (e.g, momentum_buffer, exp_avg, etc.). 
                # print("\toptimzer.state[{}]".format(param.data.shape))
                for k, v in state.items():
                    # å°†ä¸€é˜¶åŠ¨é‡å’ŒäºŒé˜¶åŠ¨é‡åŠ å…¥åˆ°å…±äº«å†…å­˜
                    if isinstance(v, torch.Tensor):
                        # num_elements = v.numel()
                        # element_size = v.element_size()
                        # memory_size_mb = (num_elements * element_size) / (1024 * 1024)
                        # print("å½“å‰ Tensor å ç”¨çš„å†…å­˜å¤§å°:", memory_size_mb, "MB")
                        # 
                        v.share_memory_(); assert v.is_shared()
                        # print("\t\t{}: {} moved to shared memory".format(k,v.shape))

                    # å°† step çš„å€¼æ¢æˆtensorå€¼ï¼Œä¹Ÿæ”¾å…¥å…±äº«å†…å­˜ 
                    elif isinstance(v, int): # or isinstance(v, float):
                        # option-1: modify optimizer code by v = mp.Value('i', 0) and v.value +=1 # ref: https://github.com/leonardo0lyj/myPT_V0.4_NetTensor/blob/master/MyCommon/MyCommon.py
                        # option-2*: cast it to scalar tensor for sharing and cast it back with .item() during usage 
                        # (checked: BertAdam)
                        state[k] = torch.tensor(v, dtype=torch.int64) # if isinstance(v, int) else torch.float64) 
                        state[k].share_memory_(); assert state[k].is_shared()
                        # print("\t\t{}: {} convert to scalar tensor and moved to shared memory".format(k,state[k]))
                    else:
                        raise ValueError("Unknown optimizer-state type {}:{}".format(k,v))
            # 4) move optimzer.hyperparams to shared memory? No. They are constant (Bert, GPT2, Adam, SGD)
            # 5) clean up gradient
            # å°†å±‚çš„å‚æ•°çš„æ¢¯åº¦ç½®ä¸ºNoneï¼Œç›¸å½“äºæ¸…ç©ºæ¢¯åº¦
            for param in shared_model.parameters():
                param.grad = None
                assert param.grad is None, "cannot None grad?"
            # æ‰‹åŠ¨è§¦å‘åƒåœ¾å›æ”¶
            gc.collect()
            # optimizer.zero_grad()
            self.shared_model = shared_model
            self.shared_optimizer = optimizer
            # print(f"self.shared_optimizer.param_groups:{self.shared_optimizer.param_groups}")
            # print(f"self.shared_optimizer.param_groups[0]:{self.shared_optimizer.param_groups[0]}")
            # exit(0)
            # print("[SharedOptimizer][id%d] sharing optimizer done."%self.id)
    
    # 1.ä¿é™©æ“ä½œï¼Œç¡®ä¿é€»è¾‘æ­£ç¡®ï¼ˆç¡®ä¿å‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€éƒ½åœ¨shared memoryä¸Šï¼Œå¦å¤–ç¡®ä¿param_groups[0]ä¸­é™¤paramsè¿™ä¸ªkeyå¤–å…¶ä»–çš„keyçš„valueä¸æ˜¯tensorï¼‰
    # 2.æ·±åº¦æ‹·è´modelï¼Œå…¶å®å°±æ˜¯ä¸€ä¸ªå±‚ï¼ˆself.shared_modelï¼‰
    # 3.å°†å¤åˆ¶çš„å±‚çš„å‚æ•°å’Œbufferç§»åŠ¨åˆ°å›ºå®šå†…å­˜ä¸­ï¼Œä»¥ä¾¿æ›´é«˜æ•ˆåœ°å°†å‚æ•°ä¼ è¾“åˆ° GPUï¼Œå› ä¸ºåœ¨ä¼ è¾“æ—¶æ— éœ€é‡æ–°åˆ†é…å†…å­˜
    @torch.no_grad()
    def init_in_subproc(self, rank=-1, world_size=-1, no_pin_model=False, no_pin_grad_buf=False):
        """ Call this on entering subprocess """
        self.rank, self.world_size = rank, world_size
        self.no_pin_model = no_pin_model
        self.no_pin_grad_buf = no_pin_grad_buf

        # è¿™ä¸ªifå°±æ˜¯ä¸ªä¿é™©ï¼Œç¡®ä¿å‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€éƒ½åœ¨shared memoryä¸Šï¼Œå¦å¤–ç¡®ä¿param_groups[0]ä¸­é™¤paramsè¿™ä¸ªkeyå¤–
        # å…¶ä»–çš„keyçš„valueä¸æ˜¯tensor
        if self.shared_optimizer is not None:
            # confirm model and optimizer are shared     
            for param in self.shared_model.parameters():
                assert param.data.is_shared()
                assert param.requires_grad 
                # assert param.grad is None, "{}".format(param.grad) # by default, gradient is process specific
            # print("[SharedOptimizer] rank{}'s model is shared".format(self.rank))
            for param, state in self.shared_optimizer.state.items(): # self.state = { param : {"step": 0, "exp_avg": tensor, "exp_avg_sq": tensor} } # per-param's optimization state (e.g, momentum_buffer, exp_avg, etc.). 
                for k, v in state.items():
                    assert isinstance(v, torch.Tensor) and v.is_shared()
            # param_groupsæ˜¯ä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼Œparam_groups[0]æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­åŒ…å«æ¨¡å‹çš„paramsä»¥åŠä¸€äº›ä¼˜åŒ–å™¨çš„å‚æ•°ï¼Œ
            # é€šè¿‡è°ƒæ•´è¿™äº›å‚æ•°å¯ä»¥å®ç°ä¼˜åŒ–å™¨å¯¹è¿™ä¸€éƒ¨åˆ†paramsæ›´çµæ´»çš„æ§åˆ¶
            for k, v in self.shared_optimizer.param_groups[0].items():    
                if k != 'params': # 'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0005, 'amsgrad': False
                    assert (not isinstance(v, torch.Tensor)) # or (isinstance(v, torch.Tensor) and v.is_shared())
                # ref1: https://pytorch.org/docs/1.5.0/_modules/torch/optim/optimizer.html#Optimizer.state_dict
                # ref2: https://pytorch.org/docs/1.5.0/_modules/torch/optim/adam.html#Adam
            # print("[SharedOptimizer] rank{}'s optimizer is shared".format(self.rank))
            
            # initialize local pinned .grad # Trimed
            # for param in self.shared_model.parameters():
            #     assert param.requires_grad
            #     param.grad = torch.zeros(param.shape, dtype=param.dtype, device="cpu", requires_grad=False).pin_memory()
            #     assert not param.grad.is_shared() and param.grad.is_pinned()
            # print("[SharedOptimizer][id%d] rank%d initialized local pinned .grad"%(self.id, self.rank))

        # è¯¥å‚æ•°é»˜è®¤ä¸ºfalse
        if self.no_pin_model:
            self.pinned_model = None
        # è¯¥å‚æ•°é»˜è®¤ä¸ºfalseï¼Œæ‰§è¡Œelse
        else:
            # initialize local pinned model (params and buffs)
            # with torch.no_grad():
            # æ·±åº¦æ‹·è´model
            self.pinned_model = copy.deepcopy(self.shared_model)
            # å°†cpuä¸Šæœ¬åœ°modelçš„å‚æ•°å’Œbufferç§»åŠ¨åˆ°å›ºå®šå†…å­˜ä¸­ï¼Œä»¥ä¾¿æ›´é«˜æ•ˆåœ°å°†å‚æ•°ä¼ è¾“åˆ° GPUï¼Œå› ä¸ºåœ¨ä¼ è¾“æ—¶æ— éœ€é‡æ–°åˆ†é…å†…å­˜
            convert_to_pinned(self.pinned_model) # in-place convert a local model cpu to a pinned model
            # print("[SharedOptimizer][id%d] rank%d initialized local pinned model"%(self.id, self.rank))
            # for s_param, p_param in zip(self.shared_model.parameters(), self.pinned_model.parameters()):
            #     print("Values equal:", torch.all(s_param == p_param))
            #     print("Same object:", s_param.data_ptr() == p_param.data_ptr())
            #     print(p_param)

    # å°†pinned memory (shared_model.pinned_buf) ä¸­ä¿å­˜çš„buffer tensorå¤åˆ¶åˆ°ä½äºå…±äº«å†…å­˜çš„
    # æ¨¡å‹(å°±æ˜¯ä¸€å±‚)çš„ buffer ä¸­ï¼Œå³shared_model.named_buffers()
    # shared_model.named_buffers()
    @torch.no_grad()
    def update_buf(self):
        """ In-place copy buffer from local pinned buf to shared model """  
        if self.no_pin_grad_buf:
            return
        
        # è‹¥shared_modelä¸­ï¼ˆæ”¾åœ¨å…±äº«å†…å­˜ä¸­çš„vlayerï¼‰æœ‰pinned bufè¿™ä¸ªå±æ€§ï¼Œ
        else:
            assert hasattr(self.shared_model, "pinned_buf")
            named_pin_buf = self.shared_model.pinned_buf
            for name, shared_buf in self.shared_model.named_buffers():
                if shared_buf is not None:    
                    shared_buf.data.copy_(named_pin_buf[name].data, non_blocking=MEMCPY_NONBLK)
                else:
                    assert named_pin_buf[name] is None, "local pinned buffer must match shared model"

        # for shared_buf, pinned_buf in zip(self.shared_model.buffers(), self.pinned_model.buffers()):
        #     shared_buf.data.copy_(pinned_buf.data, non_blocking=MEMCPY_NONBLK) # inplace copy from pinned memory to shared memory # nonblocking useless
        #     assert pinned_buf.is_pinned() and (not pinned_buf.requires_grad)
    
    @torch.no_grad()
    def step(self, zero_grad=False):
        if self.shared_optimizer is not None:
            self.shared_optimizer.step()
            if zero_grad:

                self.shared_optimizer.zero_grad()
        # confirm local .grad is still pinned
        # for param in self.shared_model.parameters():
        #     assert param.grad.is_pinned()
        # print("[SharedOptimizer] rank{} steped shared optimizer".format(self.rank))
    
    # å°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹(åœ¨pinned memoryä¸­)ä¸­
    @torch.no_grad()
    def sync_pinned_model(self):
        """ In-place copy from shared model to local pinned model """  
        if self.no_pin_model:
            return
        #
        for pinned_param, shared_param in zip(self.pinned_model.parameters(), self.shared_model.parameters()):
            pinned_param.data.copy_(shared_param.data, non_blocking=MEMCPY_NONBLK) # inplace copy from shared memory to pinned memory # nonblocking useless
            assert pinned_param.is_pinned() and (not pinned_param.requires_grad) and shared_param.requires_grad
        for pinned_buf, shared_buf in zip(self.pinned_model.buffers(), self.shared_model.buffers()):
            pinned_buf.data.copy_(shared_buf.data, non_blocking=MEMCPY_NONBLK) # inplace copy from shared memory to pinned memory  # nonblocking useless
            assert pinned_buf.is_pinned() and (not pinned_buf.requires_grad)
        # print("[SharedOptimizer] rank{} synced pinned model".format(self.rank))






# ğŸ“
class PinnedBufferInformation(object):
    
    def __init__(self, layer_count, transformer_layer, rank):
        self.layer_count = layer_count
        self.transformer_layer = transformer_layer
        self.rank = rank

        self.swap_element_size = torch.tensor([], dtype=torch.float32).element_size()
        self.aligned_bytes = 1024
        self.numel_alignment = self.aligned_bytes // self.swap_element_size

        # for id in range(self.layer_count):
        #     self.pinned_model.append(PinnedModel())

        # ä¸€ä¸ªtransformerå±‚å†…çš„paramåˆ°å…¶å‚æ•°é‡çš„æ˜ å°„
        self.param_idx_in_layer_to_numel = {}
        self.param_idx_in_layer_to_aligned_numel = {}
        self.param_idx_to_start_pos = {}

        self.buffer_size = self.cal_pinned_buffer_size()
        self.buffers_size = self.buffer_size * self.layer_count

        self.layer_idx_to_buffer_start_pos = {}

        self.buf_start_pos = 0

        for idx in range(self.layer_count):
            self.layer_idx_to_buffer_start_pos[idx] = idx * self.buffer_size


    # ç»Ÿè®¡éœ€è¦å¤šå¤§çš„å†…å­˜ï¼ˆåŒ…æ‹¬è¡¥é½çš„éƒ¨åˆ†ï¼‰
    def cal_pinned_buffer_size(self):
        total_aligned_size = 0
        # è®¡ç®—ä¸€ä¸ªtransformerå±‚çš„å‚æ•°å¤§å°ï¼ˆå†…éƒ¨çš„æ¯ä¸ªparamå•ç‹¬è¿›è¡Œå¯¹é½ï¼‰
        global_param_idx = 0
        for m in self.transformer_layer.modules():

            for id, (key, param) in enumerate(m._parameters.items()):
                param_size = param.numel()
                self.param_idx_in_layer_to_numel[global_param_idx] = param_size
                aligned_size = self._io_aligned_numel(param_size)
                self.param_idx_in_layer_to_aligned_numel[global_param_idx] = aligned_size
                self.param_idx_to_start_pos[global_param_idx] = total_aligned_size
                total_aligned_size += aligned_size
                global_param_idx += 1

            for key, buf in m._buffers.items():
                buf_size = buf.numel()
                self.param_idx_in_layer_to_numel[global_param_idx] = buf_size
                aligned_size = self._io_aligned_numel(buf_size)
                self.param_idx_in_layer_to_aligned_numel[global_param_idx] = aligned_size
                self.param_idx_to_start_pos[global_param_idx] = total_aligned_size
                total_aligned_size += aligned_size
                global_param_idx += 1

        print(f"rank:{self.rank}, å•å±‚transformeræ¨¡å‹éœ€è¦çš„å¯¹é½å­—å‚æ•°é‡:{total_aligned_size}, {total_aligned_size*4/1024/1024}MB")
        return total_aligned_size

    def get_buffer_size(self):
        return self.buffer_size

    def get_buffers_size(self):
        return self.buffers_size

    # 
    def _io_aligned_numel(self, numel):
        # å…ƒç´ æ•°é‡ % å¯¹é½å…ƒç´ æ•°é‡
        remainder = numel % self.numel_alignment
        return numel if remainder == 0 else (numel + self.numel_alignment - remainder)
    
    def get_layer_start_pos_in_buffers(self, layer_idx):
        return self.layer_idx_to_buffer_start_pos[layer_idx]
    
    def get_param_start_pos(self, param_idx):
        return self.param_idx_to_start_pos[param_idx]
    
    def get_param_size(self, param_idx):
        return self.param_idx_in_layer_to_numel[param_idx]

    def get_param_aligned_size(self, param_idx):
        return self.param_idx_in_layer_to_aligned_numel[param_idx]
    

# ä¸Šé¢é‚£ä¸€ä¸ªæ˜¯ä»¥sub layerä¸ºç²’åº¦çš„å¸è½½ï¼Œç°åœ¨ä¸€æ¬¡å¸è½½æ•´ä¸ªtransformerå±‚
class PinnedBufferInformation_2(object):
    
    def __init__(self, layer_count, transformer_layer, rank):
        self.layer_count = layer_count
        self.transformer_layer = transformer_layer
        self.rank = rank

        self.swap_element_size = torch.tensor([], dtype=torch.float32).element_size()
        self.aligned_bytes = 1024
        self.numel_alignment = self.aligned_bytes // self.swap_element_size

        # ä¸€ä¸ªtransformerå±‚å†…çš„paramåˆ°å…¶å‚æ•°é‡çš„æ˜ å°„
        self.param_idx_in_layer_to_numel = {}
        self.param_idx_to_start_pos = {}

        self.layer_size, self.buffer_size = self.cal_pinned_buffer_size()
        
        self.buffers_size = self.buffer_size * self.layer_count

        self.layer_idx_to_buffer_start_pos = {}

        self.buf_start_pos = 0

        for idx in range(self.layer_count):
            self.layer_idx_to_buffer_start_pos[idx] = idx * self.buffer_size


    # ç»Ÿè®¡éœ€è¦å¤šå¤§çš„å†…å­˜ï¼ˆåŒ…æ‹¬è¡¥é½çš„éƒ¨åˆ†ï¼‰
    def cal_pinned_buffer_size(self):
        total_size = 0
        # è®¡ç®—ä¸€ä¸ªtransformerå±‚çš„å‚æ•°å¤§å°
        global_param_idx = 0
        for m in self.transformer_layer.modules():

            for id, (key, param) in enumerate(m._parameters.items()):
                param_size = param.numel()
                self.param_idx_in_layer_to_numel[global_param_idx] = param_size

                self.param_idx_to_start_pos[global_param_idx] = total_size
                total_size += param_size
                global_param_idx += 1

            for key, buf in m._buffers.items():
                buf_size = buf.numel()
                self.param_idx_in_layer_to_numel[global_param_idx] = buf_size
                self.param_idx_to_start_pos[global_param_idx] = total_size
                total_size += buf_size
                global_param_idx += 1

        aligned_total_size = self._io_aligned_numel(total_size)
        print(f"rank:{self.rank}, å•å±‚transformeræ¨¡å‹åŸæœ¬çš„å‚æ•°é‡{total_size} ,éœ€è¦çš„å¯¹é½å­—å‚æ•°é‡:{aligned_total_size}, {total_size*4/1024/1024}MB")
        
        return total_size, aligned_total_size

    def get_layer_size(self):
        return self.layer_size

    def get_buffer_size(self):
        return self.buffer_size

    def get_buffers_size(self):
        return self.buffers_size

    # 
    def _io_aligned_numel(self, numel):
        # å…ƒç´ æ•°é‡ % å¯¹é½å…ƒç´ æ•°é‡
        remainder = numel % self.numel_alignment
        return numel if remainder == 0 else (numel + self.numel_alignment - remainder)
    
    def get_layer_start_pos_in_buffers(self, layer_idx):
        return self.layer_idx_to_buffer_start_pos[layer_idx]
    
    def get_param_start_pos(self, param_idx):
        return self.param_idx_to_start_pos[param_idx]
    
    def get_param_size(self, param_idx):
        return self.param_idx_in_layer_to_numel[param_idx]

# åŒbufferï¼Œä¸€ä¸ªbufferå¸è½½æ—¶ï¼Œå¦ä¸€ä¸ªbufferå¯ä»¥è¯»å–
class PinnedBufferInformation_double_buffer(object):
    def __init__(self, layer_count, transformer_layer, rank, num_buffers=2):
        self.layer_count = layer_count
        self.transformer_layer = transformer_layer
        self.rank = rank
        self.num_buffers = num_buffers

        self.swap_element_size = torch.tensor([], dtype=torch.float32).element_size()
        self.aligned_bytes = 1024
        self.numel_alignment = self.aligned_bytes // self.swap_element_size
        
        # ä¸€ä¸ªtransformerå±‚å†…çš„paramåˆ°å…¶å‚æ•°é‡çš„æ˜ å°„
        self.param_idx_in_layer_to_numel = {}
        self.param_idx_to_start_pos = {}

        # ä¸€å±‚transformeræ¨¡å‹çš„å¤§å°
        self.layer_size, self.aligned_layer_size = self.cal_pinned_buffer_size()
        # åˆå§‹åŒ–æ¯ä¸ªbufferçš„ä¿¡æ¯
        self.buffer_info = self._initialize_buffer_info()

        self.buffer_size = self.layer_count * self.aligned_layer_size

    def _initialize_buffer_info(self):
        """ä¸ºæ¯ä¸ªbufferåˆå§‹åŒ–ç›¸åŒçš„ä¿¡æ¯"""
        buffer_info = {}
        current_offset = 0
        for buffer_id in range(self.num_buffers):
            buffer_info[buffer_id] = {
                'layer_sizes': {},  # layer_idx -> size mapping
                'layer_offsets': {},  # layer_idx -> offset mapping
            }
            # è®¡ç®—æ¯ä¸ªlayerçš„å¤§å°å’Œåç§»é‡
            for layer_idx in range(self.layer_count):
                buffer_info[buffer_id]['layer_sizes'][layer_idx] = self.layer_size
                buffer_info[buffer_id]['layer_offsets'][layer_idx] = current_offset
                current_offset += self.aligned_layer_size
        return buffer_info
    
    def cal_pinned_buffer_size(self):
        total_size = 0
        # è®¡ç®—ä¸€ä¸ªtransformerå±‚çš„å‚æ•°å¤§å°
        global_param_idx = 0
        for m in self.transformer_layer.modules():

            for id, (key, param) in enumerate(m._parameters.items()):
                param_size = param.numel()
                self.param_idx_in_layer_to_numel[global_param_idx] = param_size

                self.param_idx_to_start_pos[global_param_idx] = total_size
                total_size += param_size
                global_param_idx += 1

            for key, buf in m._buffers.items():
                buf_size = buf.numel()
                self.param_idx_in_layer_to_numel[global_param_idx] = buf_size
                self.param_idx_to_start_pos[global_param_idx] = total_size
                total_size += buf_size
                global_param_idx += 1

        aligned_total_size = self._io_aligned_numel(total_size)
        print(f"rank:{self.rank}, å•å±‚transformeræ¨¡å‹åŸæœ¬çš„å‚æ•°é‡{total_size} ,éœ€è¦çš„å¯¹é½å­—å‚æ•°é‡:{aligned_total_size}, {total_size*4/1024/1024}MB")
        
        return total_size, aligned_total_size

    # æ ¹æ®buffer_idå’Œlayer_idxè·å–å¯¹åº”çš„buffer
    def get_buffer(self, buffer_id, layer_idx):
        return self.buffer_info[buffer_id]['layer_offsets'][layer_idx]
    
    def get_layer_size(self):
        return self.layer_size

    def get_aligned_layer_size(self):
        return self.aligned_layer_size

    def get_buffers_size(self):
        """è¿”å›æ‰€æœ‰bufferéœ€è¦çš„æ€»å¤§å°"""
        return self.layer_count * self.num_buffers * self.aligned_layer_size  # æ‰€æœ‰bufferå¤§å°ç›¸åŒ
    
    def get_buffer_start_pos(self, buffer_id):
        return self.buffer_info[buffer_id]['layer_offsets'][0]
    
    def get_layer_start_pos_in_buffers(self, buffer_id, layer_idx):
        return self.buffer_info[buffer_id]['layer_offsets'][layer_idx]

    def get_param_start_pos(self, param_idx):
        return self.param_idx_to_start_pos[param_idx]
    
    def get_param_size(self, param_idx):
        return self.param_idx_in_layer_to_numel[param_idx]

    # 
    def _io_aligned_numel(self, numel):
        # å…ƒç´ æ•°é‡ % å¯¹é½å…ƒç´ æ•°é‡
        remainder = numel % self.numel_alignment
        return numel if remainder == 0 else (numel + self.numel_alignment - remainder)

class SharedOptimCPU_for_worker5(object):
    """ A wrapper class of shared optimizer (referring to each shared vlayer) on CPU.
        Data structure:
        o	a multiprocess-shared vlayer and optimizer
        o	a process-local pinned .grad as input buffer
        o	a process-local pinned model (param and buffs) as output buffer
        TODO: decouple pinned_model from here
    """
    # å°†å±‚çš„å‚æ•°å¯¹åº”çš„ä¼˜åŒ–å™¨çŠ¶æ€å…¨éƒ¨æ”¾å…¥å…±äº«å†…å­˜
    @torch.no_grad()
    def __init__(self, shared_model, optimizer, id=-1):
        """ Call this in parent process and before fork/spawn subprocess """ 
        self.id = id # vlayer_id
        if optimizer is None: # this wrapper is only for pinned model
            self.shared_model = shared_model
            self.shared_optimizer = None
            # print("[SharedOptimizer][id%d] optimizer is None; for pinned model only."%self.id)
        else:
            # confirm model and optimizer are on CPU
            # ç¡®ä¿å½“å‰è¿™ä¸ªå±‚çš„å‚æ•°å’Œå¯¹åº”çš„ä¼˜åŒ–å™¨çŠ¶æ€éƒ½ä¸åœ¨GPUä¸Š
            for param in shared_model.parameters():
                assert not param.is_cuda and param.is_shared()
            for param, state in optimizer.state.items():
                for k, v in state.items():
                    # print("..............:", self.id)
                    # print(k)
                    # print(v)
                    if isinstance(v, torch.Tensor):
                        assert not v.data.is_cuda
            # 1) create zero gradient 
            # å°†å‚æ•°çš„æ¢¯åº¦åˆå§‹åŒ–ä¸ºä¸å‚æ•°æ•°æ®å½¢çŠ¶ç›¸åŒçš„å…¨é›¶å¼ é‡
            for param in shared_model.parameters():
                param.grad = torch.zeros_like(param.data) # == torch.zeros(input.size(), input.dtype, input.layout, input.device, requires_grad=False)
                # Note: "param.grad = tensor" works, but "param.data.grad = tensor" doesn't work
                # Note: id(param.grad) == id(param.data.grad)
            # 2) force initialization of optimizer states (Bert, GPT2, Adam, SGD)
            # è°ƒç”¨ä¸€æ¬¡ä¼˜åŒ–å™¨çš„ step æ–¹æ³•ï¼Œä»¥å¼ºåˆ¶åˆå§‹åŒ–ä¼˜åŒ–å™¨çŠ¶æ€
            # print(f"ä¼˜åŒ–å™¨åˆå§‹åŒ–ä¹‹å‰ï¼š{optimizer.state}")
            # å¼ºåˆ¶åˆå§‹åŒ–ä¹‹å‰ï¼Œè¿™ä¸ªå­—å…¸æ˜¯ç©ºçš„
            # å¦å¤–éœ€è¦æ³¨æ„ï¼Œè¿™ä¸ªå­—å…¸å¯èƒ½æœ‰å¤šä¸ªé”®å€¼å¯¹ï¼Œå³å¤šä¸ª å‚æ•°ï¼š{step:,'exp_avg','exp_avg_sq'}
            optimizer.step() 
            # print(f"ä¼˜åŒ–å™¨åˆå§‹åŒ–ä¹‹åï¼š{optimizer.state}")
            # 3) move optimzer.state to shared memory
            # å°†ä¼˜åŒ–å™¨çŠ¶æ€æ”¾å…¥å…±äº«å†…å­˜ï¼ˆç”šè‡³è¿stepæ•°ä¹Ÿæ”¾è¿›å»äº†ï¼‰
            # print("[SharedOptimizer] sharing optimizer:")
            for param, state in optimizer.state.items(): # self.state = { param : {"step": 0, "exp_avg": tensor, "exp_avg_sq": tensor} } # per-param's optimization state (e.g, momentum_buffer, exp_avg, etc.). 
                # print("\toptimzer.state[{}]".format(param.data.shape))
                for k, v in state.items():
                    # å°†ä¸€é˜¶åŠ¨é‡å’ŒäºŒé˜¶åŠ¨é‡åŠ å…¥åˆ°å…±äº«å†…å­˜
                    if isinstance(v, torch.Tensor):
                        # num_elements = v.numel()
                        # element_size = v.element_size()
                        # memory_size_mb = (num_elements * element_size) / (1024 * 1024)
                        # print("å½“å‰ Tensor å ç”¨çš„å†…å­˜å¤§å°:", memory_size_mb, "MB")
                        # 
                        v.share_memory_(); assert v.is_shared()
                        # print("\t\t{}: {} moved to shared memory".format(k,v.shape))

                    # å°† step çš„å€¼æ¢æˆtensorå€¼ï¼Œä¹Ÿæ”¾å…¥å…±äº«å†…å­˜ 
                    elif isinstance(v, int): # or isinstance(v, float):
                        # option-1: modify optimizer code by v = mp.Value('i', 0) and v.value +=1 # ref: https://github.com/leonardo0lyj/myPT_V0.4_NetTensor/blob/master/MyCommon/MyCommon.py
                        # option-2*: cast it to scalar tensor for sharing and cast it back with .item() during usage 
                        # (checked: BertAdam)
                        state[k] = torch.tensor(v, dtype=torch.int64) # if isinstance(v, int) else torch.float64) 
                        state[k].share_memory_(); assert state[k].is_shared()
                        # print("\t\t{}: {} convert to scalar tensor and moved to shared memory".format(k,state[k]))
                    else:
                        raise ValueError("Unknown optimizer-state type {}:{}".format(k,v))
            # 4) move optimzer.hyperparams to shared memory? No. They are constant (Bert, GPT2, Adam, SGD)
            # 5) clean up gradient
            # å°†å±‚çš„å‚æ•°çš„æ¢¯åº¦ç½®ä¸ºNoneï¼Œç›¸å½“äºæ¸…ç©ºæ¢¯åº¦
            for param in shared_model.parameters():
                param.grad = None
                assert param.grad is None, "cannot None grad?"
            # æ‰‹åŠ¨è§¦å‘åƒåœ¾å›æ”¶
            gc.collect()
            # optimizer.zero_grad()
            self.shared_model = shared_model
            self.shared_optimizer = optimizer
            # print(f"self.shared_optimizer.param_groups:{self.shared_optimizer.param_groups}")
            # print(f"self.shared_optimizer.param_groups[0]:{self.shared_optimizer.param_groups[0]}")
            # exit(0)
            # print("[SharedOptimizer][id%d] sharing optimizer done."%self.id)
    
    # 1.ä¿é™©æ“ä½œï¼Œç¡®ä¿é€»è¾‘æ­£ç¡®ï¼ˆç¡®ä¿å‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€éƒ½åœ¨shared memoryä¸Šï¼Œå¦å¤–ç¡®ä¿param_groups[0]ä¸­é™¤paramsè¿™ä¸ªkeyå¤–å…¶ä»–çš„keyçš„valueä¸æ˜¯tensorï¼‰
    # 2.æ·±åº¦æ‹·è´modelï¼Œå…¶å®å°±æ˜¯ä¸€ä¸ªå±‚ï¼ˆself.shared_modelï¼‰
    # 3.å°†å¤åˆ¶çš„å±‚çš„å‚æ•°å’Œbufferç§»åŠ¨åˆ°å›ºå®šå†…å­˜ä¸­ï¼Œä»¥ä¾¿æ›´é«˜æ•ˆåœ°å°†å‚æ•°ä¼ è¾“åˆ° GPUï¼Œå› ä¸ºåœ¨ä¼ è¾“æ—¶æ— éœ€é‡æ–°åˆ†é…å†…å­˜
    @torch.no_grad()
    def init_in_subproc(self, id, cpu_layers, rank=-1, world_size=-1, no_pin_model=False, no_pin_grad_buf=False):
        """ Call this on entering subprocess """
        self.rank, self.world_size = rank, world_size
        self.no_pin_model = no_pin_model
        self.no_pin_grad_buf = no_pin_grad_buf

        # è¿™ä¸ªifå°±æ˜¯ä¸ªä¿é™©ï¼Œç¡®ä¿å‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€éƒ½åœ¨shared memoryä¸Šï¼Œå¦å¤–ç¡®ä¿param_groups[0]ä¸­é™¤paramsè¿™ä¸ªkeyå¤–
        # å…¶ä»–çš„keyçš„valueä¸æ˜¯tensor
        if self.shared_optimizer is not None:
            # confirm model and optimizer are shared     
            for param in self.shared_model.parameters():
                assert param.data.is_shared()
                assert param.requires_grad 
                # assert param.grad is None, "{}".format(param.grad) # by default, gradient is process specific
            # print("[SharedOptimizer] rank{}'s model is shared".format(self.rank))
            for param, state in self.shared_optimizer.state.items(): # self.state = { param : {"step": 0, "exp_avg": tensor, "exp_avg_sq": tensor} } # per-param's optimization state (e.g, momentum_buffer, exp_avg, etc.). 
                for k, v in state.items():
                    assert isinstance(v, torch.Tensor) and v.is_shared()
            # param_groupsæ˜¯ä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼Œparam_groups[0]æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­åŒ…å«æ¨¡å‹çš„paramsä»¥åŠä¸€äº›ä¼˜åŒ–å™¨çš„å‚æ•°ï¼Œ
            # é€šè¿‡è°ƒæ•´è¿™äº›å‚æ•°å¯ä»¥å®ç°ä¼˜åŒ–å™¨å¯¹è¿™ä¸€éƒ¨åˆ†paramsæ›´çµæ´»çš„æ§åˆ¶
            for k, v in self.shared_optimizer.param_groups[0].items():    
                if k != 'params': # 'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0005, 'amsgrad': False
                    assert (not isinstance(v, torch.Tensor)) # or (isinstance(v, torch.Tensor) and v.is_shared())
                # ref1: https://pytorch.org/docs/1.5.0/_modules/torch/optim/optimizer.html#Optimizer.state_dict
                # ref2: https://pytorch.org/docs/1.5.0/_modules/torch/optim/adam.html#Adam
            # print("[SharedOptimizer] rank{}'s optimizer is shared".format(self.rank))
            
            # initialize local pinned .grad # Trimed
            # for param in self.shared_model.parameters():
            #     assert param.requires_grad
            #     param.grad = torch.zeros(param.shape, dtype=param.dtype, device="cpu", requires_grad=False).pin_memory()
            #     assert not param.grad.is_shared() and param.grad.is_pinned()
            # print("[SharedOptimizer][id%d] rank%d initialized local pinned .grad"%(self.id, self.rank))

        # åºŸå¼ƒ
        # ğŸ“è®°ä½å½“å‰å±‚å„ä¸ªparamåŸå§‹çš„å½¢çŠ¶
        # for param in self.shared_model.parameters():
        #     param.ds_shape = param.shape
        # for name, buffer in self.shared_model.named_buffers():
        #     # print(f"Buffer name: {name}")
        #     # print(f"Buffer shape: {buffer.shape}")
        #     buffer.ds_shape = buffer.shape

        # è¯¥å‚æ•°é»˜è®¤ä¸ºfalse
        if self.no_pin_model:
            self.pinned_model = None
        # è¯¥å‚æ•°é»˜è®¤ä¸ºfalseï¼Œæ‰§è¡Œelse
        elif id in cpu_layers:
             # initialize local pinned model (params and buffs)
            # with torch.no_grad():
            # æ·±åº¦æ‹·è´model
            # print(f"rank{self.rank}æ‹·è´ç¬¬{id}å±‚:{self.shared_model}")
            self.pinned_model = copy.deepcopy(self.shared_model)
            # å°†cpuä¸Šæœ¬åœ°modelçš„å‚æ•°å’Œbufferç§»åŠ¨åˆ°å›ºå®šå†…å­˜ä¸­ï¼Œä»¥ä¾¿æ›´é«˜æ•ˆåœ°å°†å‚æ•°ä¼ è¾“åˆ° GPUï¼Œå› ä¸ºåœ¨ä¼ è¾“æ—¶æ— éœ€é‡æ–°åˆ†é…å†…å­˜
            convert_to_pinned(self.pinned_model) # in-place convert a local model cpu to a pinned model
            # print("[SharedOptimizer][id%d] rank%d initialized local pinned model"%(self.id, self.rank))
        # è‹¥å½“å‰éå†åˆ°çš„layerä¸å±äºå½“å‰rankï¼Œåˆ™ä¸ä¼šå¯¹è¯¥layeråˆ›å»ºä¸€ä¸ªpinnedç‰ˆæœ¬
        else:
            self.pinned_model = None

    # é‡æ–°åˆå§‹åŒ–ä¼˜åŒ–å™¨
    def re_init(self):
        for param in self.shared_model.parameters():
            assert param.data.is_shared()
            assert param.requires_grad 
        for param, state in self.shared_optimizer.state.items():
            for k, v in state.items():
                assert isinstance(v, torch.Tensor) and v.is_shared()

        self.pinned_model = copy.deepcopy(self.shared_model)
        convert_to_pinned(self.pinned_model)
        

    # å°†pinned memory (shared_model.pinned_buf) ä¸­ä¿å­˜çš„buffer tensorå¤åˆ¶åˆ°ä½äºå…±äº«å†…å­˜çš„
    # æ¨¡å‹(å°±æ˜¯ä¸€å±‚)çš„ buffer ä¸­ï¼Œå³shared_model.named_buffers()
    # shared_model.named_buffers()
    @torch.no_grad()
    def update_buf(self):
        """ In-place copy buffer from local pinned buf to shared model """  
        if self.no_pin_grad_buf:
            return
        
        # è‹¥shared_modelä¸­ï¼ˆæ”¾åœ¨å…±äº«å†…å­˜ä¸­çš„vlayerï¼‰æœ‰pinned bufè¿™ä¸ªå±æ€§ï¼Œ
        else:
            assert hasattr(self.shared_model, "pinned_buf")
            named_pin_buf = self.shared_model.pinned_buf
            for name, shared_buf in self.shared_model.named_buffers():
                if shared_buf is not None:    
                    shared_buf.data.copy_(named_pin_buf[name].data, non_blocking=MEMCPY_NONBLK)
                else:
                    assert named_pin_buf[name] is None, "local pinned buffer must match shared model"

        # for shared_buf, pinned_buf in zip(self.shared_model.buffers(), self.pinned_model.buffers()):
        #     shared_buf.data.copy_(pinned_buf.data, non_blocking=MEMCPY_NONBLK) # inplace copy from pinned memory to shared memory # nonblocking useless
        #     assert pinned_buf.is_pinned() and (not pinned_buf.requires_grad)
    
    @torch.no_grad()
    def step(self, zero_grad=False):
        if self.shared_optimizer is not None:
            self.shared_optimizer.step()
            if zero_grad:

                self.shared_optimizer.zero_grad()
        # confirm local .grad is still pinned
        # for param in self.shared_model.parameters():
        #     assert param.grad.is_pinned()
        # print("[SharedOptimizer] rank{} steped shared optimizer".format(self.rank))
    
    # å°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹(åœ¨pinned memoryä¸­)ä¸­
    @torch.no_grad()
    def sync_pinned_model(self):
        """ In-place copy from shared model to local pinned model """  
        if self.no_pin_model:
            return
        #
        for pinned_param, shared_param in zip(self.pinned_model.parameters(), self.shared_model.parameters()):
            pinned_param.data.copy_(shared_param.data, non_blocking=MEMCPY_NONBLK) # inplace copy from shared memory to pinned memory # nonblocking useless
            assert pinned_param.is_pinned() and (not pinned_param.requires_grad) and shared_param.requires_grad
        for pinned_buf, shared_buf in zip(self.pinned_model.buffers(), self.shared_model.buffers()):
            pinned_buf.data.copy_(shared_buf.data, non_blocking=MEMCPY_NONBLK) # inplace copy from shared memory to pinned memory  # nonblocking useless
            assert pinned_buf.is_pinned() and (not pinned_buf.requires_grad)
        # print("[SharedOptimizer] rank{} synced pinned model".format(self.rank))

    @torch.no_grad()
    def sync_pinned_buffer(self, pinned_buffer):
        for pinned_param, shared_param in zip(pinned_buffer.parameters(), self.shared_model.parameters()):
            print(f"rank:{self.rank}, pinned_param:{pinned_param}, shared_param:{shared_param}, is shared?{shared_param.is_shared()}")
            pinned_param.data.copy_(shared_param.view(-1).data, non_blocking=MEMCPY_NONBLK) # inplace copy from shared memory to pinned memory  # nonblocking useless
            assert pinned_param.is_pinned() and (not pinned_param.requires_grad) and shared_param.requires_grad
        for pinned_buf, shared_buf in zip(pinned_buffer.buffers(), self.shared_model.buffers()):
            pinned_buf.data.copy_(shared_buf.view(-1).data, non_blocking=MEMCPY_NONBLK) # inplace copy from shared memory to pinned memory  # nonblocking useless
            assert pinned_buf.is_pinned() and (not pinned_buf.requires_grad)

# æš‚æ—¶åºŸå¼ƒï¼Œå› ä¸ºä¼˜åŒ–å™¨çš„çŠ¶æ€å¯ä»¥å°±è£…åœ¨shared memoryä¸Šä¸ç”¨ç®¡
class PinnedOptimCPU(object):
    """ A wrapper class of shared optimizer (referring to each shared vlayer) on CPU.
        Data structure:
        o	a multiprocess-shared vlayer and optimizer
        o	a process-local pinned .grad as input buffer
        o	a process-local pinned model (param and buffs) as output buffer
        TODO: decouple pinned_model from here
    """
    # å°†å±‚çš„å‚æ•°å¯¹åº”çš„ä¼˜åŒ–å™¨çŠ¶æ€å…¨éƒ¨æ”¾å…¥å…±äº«å†…å­˜
    @torch.no_grad()
    def __init__(self, shared_model, optimizer, id=-1):
        """ Call this in parent process and before fork/spawn subprocess """ 
        self.id = id # vlayer_id
        if optimizer is None: # this wrapper is only for pinned model
            self.shared_model = shared_model
            self.shared_optimizer = None
            # print("[SharedOptimizer][id%d] optimizer is None; for pinned model only."%self.id)
        else:
            # confirm model and optimizer are on CPU
            # ç¡®ä¿å½“å‰è¿™ä¸ªå±‚çš„å‚æ•°å’Œå¯¹åº”çš„ä¼˜åŒ–å™¨çŠ¶æ€éƒ½ä¸åœ¨GPUä¸Š
            for param in shared_model.parameters():
                assert not param.is_cuda and param.is_shared()
            for param, state in optimizer.state.items():
                for k, v in state.items():
                    # print("..............:", self.id)
                    # print(k)
                    # print(v)
                    if isinstance(v, torch.Tensor):
                        assert not v.data.is_cuda
            # 1) create zero gradient 
            # å°†å‚æ•°çš„æ¢¯åº¦åˆå§‹åŒ–ä¸ºä¸å‚æ•°æ•°æ®å½¢çŠ¶ç›¸åŒçš„å…¨é›¶å¼ é‡
            for param in shared_model.parameters():
                param.grad = torch.zeros_like(param.data) # == torch.zeros(input.size(), input.dtype, input.layout, input.device, requires_grad=False)
                # Note: "param.grad = tensor" works, but "param.data.grad = tensor" doesn't work
                # Note: id(param.grad) == id(param.data.grad)
            # 2) force initialization of optimizer states (Bert, GPT2, Adam, SGD)
            # è°ƒç”¨ä¸€æ¬¡ä¼˜åŒ–å™¨çš„ step æ–¹æ³•ï¼Œä»¥å¼ºåˆ¶åˆå§‹åŒ–ä¼˜åŒ–å™¨çŠ¶æ€
            # print(f"ä¼˜åŒ–å™¨åˆå§‹åŒ–ä¹‹å‰ï¼š{optimizer.state}")
            # å¼ºåˆ¶åˆå§‹åŒ–ä¹‹å‰ï¼Œè¿™ä¸ªå­—å…¸æ˜¯ç©ºçš„
            # å¦å¤–éœ€è¦æ³¨æ„ï¼Œè¿™ä¸ªå­—å…¸å¯èƒ½æœ‰å¤šä¸ªé”®å€¼å¯¹ï¼Œå³å¤šä¸ª å‚æ•°ï¼š{step:,'exp_avg','exp_avg_sq'}
            optimizer.step() 
            # print(f"ä¼˜åŒ–å™¨åˆå§‹åŒ–ä¹‹åï¼š{optimizer.state}")
            # 3) move optimzer.state to shared memory
            # å°†ä¼˜åŒ–å™¨çŠ¶æ€æ”¾å…¥å…±äº«å†…å­˜ï¼ˆç”šè‡³è¿stepæ•°ä¹Ÿæ”¾è¿›å»äº†ï¼‰
            # print("[SharedOptimizer] sharing optimizer:")
            for param, state in optimizer.state.items(): # self.state = { param : {"step": 0, "exp_avg": tensor, "exp_avg_sq": tensor} } # per-param's optimization state (e.g, momentum_buffer, exp_avg, etc.). 
                # print("\toptimzer.state[{}]".format(param.data.shape))
                for k, v in state.items():
                    # å°†ä¸€é˜¶åŠ¨é‡å’ŒäºŒé˜¶åŠ¨é‡åŠ å…¥åˆ°å…±äº«å†…å­˜
                    if isinstance(v, torch.Tensor):
                        # num_elements = v.numel()
                        # element_size = v.element_size()
                        # memory_size_mb = (num_elements * element_size) / (1024 * 1024)
                        # print("å½“å‰ Tensor å ç”¨çš„å†…å­˜å¤§å°:", memory_size_mb, "MB")
                        # 
                        v.share_memory_(); assert v.is_shared()
                        # print("\t\t{}: {} moved to shared memory".format(k,v.shape))

                    # å°† step çš„å€¼æ¢æˆtensorå€¼ï¼Œä¹Ÿæ”¾å…¥å…±äº«å†…å­˜ 
                    elif isinstance(v, int): # or isinstance(v, float):
                        # option-1: modify optimizer code by v = mp.Value('i', 0) and v.value +=1 # ref: https://github.com/leonardo0lyj/myPT_V0.4_NetTensor/blob/master/MyCommon/MyCommon.py
                        # option-2*: cast it to scalar tensor for sharing and cast it back with .item() during usage 
                        # (checked: BertAdam)
                        state[k] = torch.tensor(v, dtype=torch.int64) # if isinstance(v, int) else torch.float64) 
                        state[k].share_memory_(); assert state[k].is_shared()
                        # print("\t\t{}: {} convert to scalar tensor and moved to shared memory".format(k,state[k]))
                    else:
                        raise ValueError("Unknown optimizer-state type {}:{}".format(k,v))
            # 4) move optimzer.hyperparams to shared memory? No. They are constant (Bert, GPT2, Adam, SGD)
            # 5) clean up gradient
            # å°†å±‚çš„å‚æ•°çš„æ¢¯åº¦ç½®ä¸ºNoneï¼Œç›¸å½“äºæ¸…ç©ºæ¢¯åº¦
            for param in shared_model.parameters():
                param.grad = None
                assert param.grad is None, "cannot None grad?"
            # æ‰‹åŠ¨è§¦å‘åƒåœ¾å›æ”¶
            gc.collect()
            # optimizer.zero_grad()
            self.shared_model = shared_model
            self.shared_optimizer = optimizer
            # print(f"self.shared_optimizer.param_groups:{self.shared_optimizer.param_groups}")
            # print(f"self.shared_optimizer.param_groups[0]:{self.shared_optimizer.param_groups[0]}")
            # exit(0)
            # print("[SharedOptimizer][id%d] sharing optimizer done."%self.id)

    # ğŸ“åºŸå¼ƒ, æˆ‘ä»¬ä¸å¸è½½ä¼˜åŒ–å™¨çŠ¶æ€, æ²¡å¿…è¦æŠŠä¼˜åŒ–å™¨ç§»åŠ¨åˆ°Pinned memory
    # å°†ä¸€å±‚çš„shared optimizerè½¬åŒ–ä¸ºpinned optimizer
    def from_shared_to_pinned(self):
        if self.shared_optimizer is not None:
            for param, state in self.shared_optimizer.state.items(): # self.state = { param : {"step": 0, "exp_avg": tensor, "exp_avg_sq": tensor} } # per-param's optimization state (e.g, momentum_buffer, exp_avg, etc.). 
                # print("\toptimzer.state[{}]".format(param.data.shape))
                for k, v in state.items():
                    # å°†ä¸€é˜¶åŠ¨é‡å’ŒäºŒé˜¶åŠ¨é‡åŠ å…¥åˆ°å…±äº«å†…å­˜
                    if isinstance(v, torch.Tensor):
                        # num_elements = v.numel()
                        # element_size = v.element_size()
                        # memory_size_mb = (num_elements * element_size) / (1024 * 1024)
                        # print("å½“å‰ Tensor å ç”¨çš„å†…å­˜å¤§å°:", memory_size_mb, "MB")
                        # 
                        v.pin_memory(); assert v.is_pinned()
                        # print("\t\t{}: {} moved to shared memory".format(k,v.shape))

                    # å°† step çš„å€¼æ¢æˆtensorå€¼ï¼Œä¹Ÿæ”¾å…¥å…±äº«å†…å­˜ 
                    elif isinstance(v, int): # or isinstance(v, float):
                        # option-1: modify optimizer code by v = mp.Value('i', 0) and v.value +=1 # ref: https://github.com/leonardo0lyj/myPT_V0.4_NetTensor/blob/master/MyCommon/MyCommon.py
                        # option-2*: cast it to scalar tensor for sharing and cast it back with .item() during usage 
                        # (checked: BertAdam)
                        state[k] = torch.tensor(v, dtype=torch.int64) # if isinstance(v, int) else torch.float64) 
                        state[k].pin_memory(); assert state[k].is_pinned()
                        # print("\t\t{}: {} convert to scalar tensor and moved to shared memory".format(k,state[k]))
                    else:
                        raise ValueError("Unknown optimizer-state type {}:{}".format(k,v))
            gc.collect()
            self.pinned_optimizer = self.shared_optimizer
            self.shared_optimizer = None

    # ğŸ“
    # å¯¹ä¸€ç›´æ”¾åœ¨cpuä¸Šçš„å±‚ï¼Œä¾ç„¶ä¼šåˆ›å»ºlayerçš„pinned ç‰ˆæœ¬
    # å¦åˆ™ï¼Œç›´æ¥å°†shared optimizerè½¬åŒ–ä¸ºpinned optimizerï¼Œå¹¶ä¸”ä¸åˆ›å»ºpinned modelï¼ˆlayerçš„pinnedç‰ˆæœ¬ï¼‰
    @torch.no_grad()
    def init_in_subproc(self, id, cpu_layers, rank=-1, world_size=-1, no_pin_model=False, no_pin_grad_buf=False):
        """ Call this on entering subprocess """
        self.rank, self.world_size = rank, world_size
        self.no_pin_model = no_pin_model
        self.no_pin_grad_buf = no_pin_grad_buf

        # 
        # if id not in cpu_layers:
        #     self.from_shared_to_pinned()

        # è¿™ä¸ªifå°±æ˜¯ä¸ªä¿é™©ï¼Œç¡®ä¿å‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€éƒ½åœ¨shared memoryä¸Šï¼Œå¦å¤–ç¡®ä¿param_groups[0]ä¸­é™¤paramsè¿™ä¸ªkeyå¤–
        # å…¶ä»–çš„keyçš„valueä¸æ˜¯tensor
        if self.shared_optimizer is not None:
            # confirm model and optimizer are shared     
            for param in self.shared_model.parameters():
                assert param.data.is_shared()
                assert param.requires_grad 
                # assert param.grad is None, "{}".format(param.grad) # by default, gradient is process specific
            # print("[SharedOptimizer] rank{}'s model is shared".format(self.rank))
            for param, state in self.shared_optimizer.state.items(): # self.state = { param : {"step": 0, "exp_avg": tensor, "exp_avg_sq": tensor} } # per-param's optimization state (e.g, momentum_buffer, exp_avg, etc.). 
                for k, v in state.items():
                    assert isinstance(v, torch.Tensor) and v.is_shared()
            # param_groupsæ˜¯ä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼Œparam_groups[0]æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­åŒ…å«æ¨¡å‹çš„paramsä»¥åŠä¸€äº›ä¼˜åŒ–å™¨çš„å‚æ•°ï¼Œ
            # é€šè¿‡è°ƒæ•´è¿™äº›å‚æ•°å¯ä»¥å®ç°ä¼˜åŒ–å™¨å¯¹è¿™ä¸€éƒ¨åˆ†paramsæ›´çµæ´»çš„æ§åˆ¶
            for k, v in self.shared_optimizer.param_groups[0].items():    
                if k != 'params': # 'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0005, 'amsgrad': False
                    assert (not isinstance(v, torch.Tensor)) # or (isinstance(v, torch.Tensor) and v.is_shared())
        # elif self.pinned_optimizer is not None:
        #     for param in self.pinned_optimizer.parameters():
        #         assert param.data.is_pinned()
        #         assert param.requires_grad 
        #         # assert param.grad is None, "{}".format(param.grad) # by default, gradient is process specific
        #     # print("[SharedOptimizer] rank{}'s model is shared".format(self.rank))
        #     for param, state in self.pinned_optimizer.state.items(): # self.state = { param : {"step": 0, "exp_avg": tensor, "exp_avg_sq": tensor} } # per-param's optimization state (e.g, momentum_buffer, exp_avg, etc.). 
        #         for k, v in state.items():
        #             assert isinstance(v, torch.Tensor) and v.is_pinned()
        #     # param_groupsæ˜¯ä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼Œparam_groups[0]æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­åŒ…å«æ¨¡å‹çš„paramsä»¥åŠä¸€äº›ä¼˜åŒ–å™¨çš„å‚æ•°ï¼Œ
        #     # é€šè¿‡è°ƒæ•´è¿™äº›å‚æ•°å¯ä»¥å®ç°ä¼˜åŒ–å™¨å¯¹è¿™ä¸€éƒ¨åˆ†paramsæ›´çµæ´»çš„æ§åˆ¶
        #     for k, v in self.pinned_optimizer.param_groups[0].items():    
        #         if k != 'params': # 'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0005, 'amsgrad': False
        #             assert (not isinstance(v, torch.Tensor))

        # è¯¥å‚æ•°é»˜è®¤ä¸ºfalse
        if self.no_pin_model:
            self.pinned_model = None
        # è¯¥å‚æ•°é»˜è®¤ä¸ºfalseï¼Œæ‰§è¡Œelse
        elif id in cpu_layers:
             # initialize local pinned model (params and buffs)
            # with torch.no_grad():
            # æ·±åº¦æ‹·è´model
            # print(f"rank{self.rank}æ‹·è´ç¬¬{id}å±‚:{self.shared_model}")
            self.pinned_model = copy.deepcopy(self.shared_model)
            # å°†cpuä¸Šæœ¬åœ°modelçš„å‚æ•°å’Œbufferç§»åŠ¨åˆ°å›ºå®šå†…å­˜ä¸­ï¼Œä»¥ä¾¿æ›´é«˜æ•ˆåœ°å°†å‚æ•°ä¼ è¾“åˆ° GPUï¼Œå› ä¸ºåœ¨ä¼ è¾“æ—¶æ— éœ€é‡æ–°åˆ†é…å†…å­˜
            convert_to_pinned(self.pinned_model) # in-place convert a local model cpu to a pinned model
            # print("[SharedOptimizer][id%d] rank%d initialized local pinned model"%(self.id, self.rank))
        # è‹¥å½“å‰éå†åˆ°çš„layerä¸å±äºå½“å‰rankï¼Œåˆ™ä¸ä¼šå¯¹è¯¥layeråˆ›å»ºä¸€ä¸ªpinnedç‰ˆæœ¬
        else:
            self.pinned_model = None

    # å°†pinned memory (shared_model.pinned_buf) ä¸­ä¿å­˜çš„buffer tensorå¤åˆ¶åˆ°ä½äºå…±äº«å†…å­˜çš„
    # æ¨¡å‹(å°±æ˜¯ä¸€å±‚)çš„ buffer ä¸­ï¼Œå³shared_model.named_buffers()
    # shared_model.named_buffers()
    @torch.no_grad()
    def update_buf(self):
        """ In-place copy buffer from local pinned buf to shared model """  
        if self.no_pin_grad_buf:
            return
        
        # è‹¥shared_modelä¸­ï¼ˆæ”¾åœ¨å…±äº«å†…å­˜ä¸­çš„vlayerï¼‰æœ‰pinned bufè¿™ä¸ªå±æ€§ï¼Œ
        else:
            assert hasattr(self.shared_model, "pinned_buf")
            named_pin_buf = self.shared_model.pinned_buf
            for name, shared_buf in self.shared_model.named_buffers():
                if shared_buf is not None:    
                    shared_buf.data.copy_(named_pin_buf[name].data, non_blocking=MEMCPY_NONBLK)
                else:
                    assert named_pin_buf[name] is None, "local pinned buffer must match shared model"

        # for shared_buf, pinned_buf in zip(self.shared_model.buffers(), self.pinned_model.buffers()):
        #     shared_buf.data.copy_(pinned_buf.data, non_blocking=MEMCPY_NONBLK) # inplace copy from pinned memory to shared memory # nonblocking useless
        #     assert pinned_buf.is_pinned() and (not pinned_buf.requires_grad)
    
    @torch.no_grad()
    def step(self, zero_grad=False):
        if self.shared_optimizer is not None:
            self.shared_optimizer.step()
            if zero_grad:

                self.shared_optimizer.zero_grad()
        # confirm local .grad is still pinned
        # for param in self.shared_model.parameters():
        #     assert param.grad.is_pinned()
        # print("[SharedOptimizer] rank{} steped shared optimizer".format(self.rank))
    
    # å°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹(åœ¨pinned memoryä¸­)ä¸­
    @torch.no_grad()
    def sync_pinned_model(self):
        """ In-place copy from shared model to local pinned model """  
        if self.no_pin_model:
            return
        #
        for pinned_param, shared_param in zip(self.pinned_model.parameters(), self.shared_model.parameters()):
            pinned_param.data.copy_(shared_param.data, non_blocking=MEMCPY_NONBLK) # inplace copy from shared memory to pinned memory # nonblocking useless
            assert pinned_param.is_pinned() and (not pinned_param.requires_grad) and shared_param.requires_grad
        for pinned_buf, shared_buf in zip(self.pinned_model.buffers(), self.shared_model.buffers()):
            pinned_buf.data.copy_(shared_buf.data, non_blocking=MEMCPY_NONBLK) # inplace copy from shared memory to pinned memory  # nonblocking useless
            assert pinned_buf.is_pinned() and (not pinned_buf.requires_grad)
        # print("[SharedOptimizer] rank{} synced pinned model".format(self.rank))



""" CPU update and sync model in background thread """
class UpdateInBkgd(object):
    """ Handles CPU update model in background thread for runtime.py 
        Assumption:
            0) simliar to FIFO queue. put each task, and get updated task. 
            1) no sync_pinned_model(), which should be moved to next FWD/BWD's SwapIn
        NOTE: move vt.medium check back to runtime by reducing granularity to vLayer?
    """
    def __init__(self, swapout_stream, shared_optimizer, lr_scheduler, rank, nvprof=False):
        self.swapout_stream = swapout_stream # å®é™…ä¸ºé»˜è®¤è®¡ç®—æµ
        self.shared_optimizer = shared_optimizer
        self.lr_scheduler = lr_scheduler
        self.rank = rank
        self.nvprof = nvprof
        # initialize
        # å®ä¾‹åŒ–ä¸€ä¸ªçº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—ï¼Œç”¨äºput
        self.put_queue = threadsafe_data_struct.Queue() # [vtask1, vtask2, ...] # between main and update thread
        # å®ä¾‹åŒ–ä¸€ä¸ªçº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—ï¼Œç”¨äºget
        self.get_queue = threadsafe_data_struct.Queue() # [vtask1.idx, vtask2.idx, ...] # between update and main thread
        # åˆ›å»ºä¸€ä¸ªupdateçº¿ç¨‹
        self.update_thread = threading.Thread(target=self._thread_func)
        self.update_thread.daemon = True
        # å¼€å¯updateçº¿ç¨‹
        self.update_thread.start()
        # print("[UpdateInBkgd] rank{} started update_thread".format(self.rank))
        # 
        self.the_last_put = None

    # ä¸æ–­å°è¯•ä»put_queueé˜Ÿåˆ—ä¸­æ‹¿å–ä»»åŠ¡ï¼Œå¯¹æ¯ä¸ªä»»åŠ¡æ‰§è¡Œï¼š
    # 1.ç­‰å¾…å½“å‰streamä¸­çš„æ‰€æœ‰æ“ä½œå…¨éƒ¨å®Œæˆï¼Œç„¶åæ‰ä¼šç»§ç»­æ‰§è¡Œåç»­çš„ä»£ç ã€‚å³ç­‰å¾…dW,B'è¢«swapåˆ°pinned memoryä¸­
    # 2.å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†cpuä¸Šshared_model.pinned_bufä¸­çš„æ•°æ®å¤åˆ¶åˆ°shared_modelå…±äº«å†…å­˜çš„vlayerçš„ buffer ä¸­ï¼Œ
    #   å³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
    # 3.æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
    # 4.å°†å®Œæˆçš„ä»»åŠ¡çš„idxåŠ å…¥åˆ°get_queueé˜Ÿåˆ—ä¸­
    def _thread_func(self):
        """ This method is to be executed from a daemon thread. """
        while True: # for each incoming task 
            # æ‹¿åˆ°put_queueä¸­çš„ç¬¬ä¸€ä¸ªvtask
            # è‹¥é˜Ÿåˆ—ä¸­æ²¡æœ‰ä»»åŠ¡ï¼Œä¼šä¸€ç›´ç­‰å¾…ï¼Œç›´åˆ°å‡ºç°ä»»åŠ¡æ­¤å¤„æ‰ä¼šç»§ç»­è¿›è¡Œ
            vt = self.put_queue.remove() # blocking
            if self.nvprof: nvtx_range_push("__task{}({}) UPD(W)".format(vt.idx, vt.show_layers())) 
            # åœ¨é»˜è®¤æµä¸Šé˜»å¡ï¼Œç›´åˆ°å…¶ä¸­æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚å®é™…æƒ…å†µæ˜¯è¯¥çº¿ç¨‹åœ¨swapout dW Båå·¥ä½œï¼Œå…¶å®å°±æ˜¯åœ¨ç­‰é»˜è®¤æµä¸Šçš„swap outå®Œæˆ
            self._wait_swapout()
            # å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†cpu pinned memoryä¸­çš„bufferæ•°æ®å¤åˆ¶åˆ°
            # ä½äºå…±äº«å†…å­˜çš„ layer è‡ªèº«çš„ buffer ä¸­ï¼Œå³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
            self._update_buf(vt) # if using local pinned model for B'
            # æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
            self._step(vt)
            # ä»»åŠ¡çš„idxåŠ å…¥åˆ°get_queueé˜Ÿåˆ—ä¸­
            self.get_queue.add(vt.idx)
            if self.nvprof: nvtx_range_pop() 

    # åœ¨é»˜è®¤æµä¸Šé˜»å¡ï¼Œç›´åˆ°å…¶ä¸­æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚å®é™…æƒ…å†µæ˜¯è¯¥çº¿ç¨‹åœ¨swapout dW Båå·¥ä½œï¼Œå…¶å®å°±æ˜¯åœ¨ç­‰é»˜è®¤æµä¸Šçš„swap outå®Œæˆ
    def _wait_swapout(self):
        """ Wait swap out (dW,B') to complete (and reside in pinned memory) """
        self.swapout_stream.synchronize() # Wait for all the kernels in this stream to complete. # (maybe use cuda event in future)

    # å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†pinned memoryä¸­çš„bufferæ•°æ®å¤åˆ¶åˆ°shared_modelå…±äº«å†…å­˜çš„vlayerçš„ buffer ä¸­ï¼Œ
    # å³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
    @torch.no_grad()
    def _update_buf(self, vt):
        """ update B of this pack """  
        # è°ƒç”¨vtä¸­çš„æ‰€æœ‰çš„layerçš„
        for l in vt.layers:
            # å°†pinned memory (shared_model.pinned_buf) ä¸­ä¿å­˜çš„buffer tensorå¤åˆ¶åˆ°ä½äºå…±äº«å†…å­˜çš„
            # æ¨¡å‹(å°±æ˜¯ä¸€å±‚)çš„ buffer ä¸­ï¼Œå³shared_model.named_buffers() 
            self.shared_optimizer[l].update_buf()
    
    # æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
    @torch.no_grad()
    def _step(self, vt):
        """ update W,K of this pack """  
        for l in vt.layers:
            assert vt.In['dW'][l].medium == "LOC"
            assert vt.In['W'][l].medium == "SHM"  
            assert vt.In['K'][l].medium == "SHM"
            assert vt.Out['W'][l].medium == "SHM"
            assert vt.Out['K'][l].medium == "SHM" 
            # ä½¿ç”¨å…±äº«ä¼˜åŒ–å™¨æ›´æ–°å‚æ•°
            self.shared_optimizer[l].step() # Update shared model and optim using swap-out'ed local .grad
            # å¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œåˆ™è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
            if self.lr_scheduler != []: # "gpt2_huggingface"
                if self.lr_scheduler[l] is not None:
                    assert self.shared_optimizer[l].shared_optimizer is not None
                    self.lr_scheduler[l].step() 
                else:
                    assert self.shared_optimizer[l].shared_optimizer is None
        # print("[UpdateInBkgd] rank{} updated task{}({})".format(self.rank, vt.idx, vt.show_layers()))

    # å°†ç»™å®šçš„vtæ”¾å…¥åˆ°put_queueé˜Ÿåˆ—ä¸­ï¼ŒåŒæ—¶å°†self.the_last_put è®¾ç½®ä¸º vt.idxã€‚
    # ğŸ“Œè¿™æ„å‘³ç€UpdateInBkgdå®ä¾‹çš„çº¿ç¨‹ä¼šå¼€å§‹æ‰§è¡Œvtä¸Šçš„layerçš„bufferä»å›ºå®šå†…å­˜åˆ°å…±äº«å†…å­˜çš„å¤åˆ¶ï¼Œä»¥åŠåœ¨shared_memoryä¸Šè¿›è¡Œå‚æ•°çš„æ›´æ–°
    def iput(self, vt):
        ''' Call by main thread. Nonblocking.'''
        assert isinstance(vt, vTask)
        self.put_queue.add(vt)
        self.the_last_put = vt.idx

    def get(self):
        ''' Call by main thread. Blocking. Return vt.idx. '''
        return self.get_queue.remove()
    
    # ç­‰å¾…æœ€åä¸€ä¸ªæ”¾è¿›put_queueä¸­çš„ä»»åŠ¡ä»get_queueä¸­æ‹¿å‡ºæ¥ï¼Œå³æ‰§è¡Œå®Œæˆ
    def synchronize(self): 
        ''' Call by main thread. Blocking. Wait for all tasks in put_queue to complete. '''
        # depends on Assumption #0; wait for the last put idx 
        if self.the_last_put is None:
            return
        # print("[UpdateInBkgd] rank{} synchronize until task{}".format(self.rank,self.the_last_put))
        while True:
            vt_idx = self.get_queue.remove()
            if vt_idx == self.the_last_put:
                break
        # print("[UpdateInBkgd] rank{} has got task{}".format(self.rank,self.the_last_put))

def unified_ray_get(futs):
    for item in futs:
        if isinstance(item, tuple) and len(item) == 2:
            stream, event = item
            stream.wait_event(event)
        else:
            item.result()

def _layer_waiting_futs(_layer, _layer_id):
    assert hasattr(_layer, "_gl_futs_offloading_at_bwd"), "layer_{} has not attribute: _gl_futs_offloading_at_bwd".format(_layer_id)
    unified_ray_get(_layer._gl_futs_offloading_at_bwd)
    del _layer._gl_futs_offloading_at_bwd


############################ my version #######################################
# ä¸»è¦æ˜¯æ·»åŠ æ–°çš„å±æ€§ local_modelï¼Œç”¨äºåœ¨UDPæ—¶ç­‰å¾…å¯¹åº”å±‚çš„å¸è½½å’Œåˆ é™¤å®Œæˆ
class UpdateInBkgd_2(object):
    """ Handles CPU update model in background thread for runtime.py 
        Assumption:
            0) simliar to FIFO queue. put each task, and get updated task. 
            1) no sync_pinned_model(), which should be moved to next FWD/BWD's SwapIn
        NOTE: move vt.medium check back to runtime by reducing granularity to vLayer?
    """
    def __init__(self, swapout_stream, shared_optimizer, local_model, lr_scheduler, rank, nvprof=False):
        self.swapout_stream = swapout_stream # å®é™…ä¸ºé»˜è®¤è®¡ç®—æµ
        self.shared_optimizer = shared_optimizer
        self.lr_scheduler = lr_scheduler
        self.rank = rank
        self.nvprof = nvprof
        # initialize
        # å®ä¾‹åŒ–ä¸€ä¸ªçº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—ï¼Œç”¨äºput
        self.put_queue = threadsafe_data_struct.Queue() # [vtask1, vtask2, ...] # between main and update thread
        # å®ä¾‹åŒ–ä¸€ä¸ªçº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—ï¼Œç”¨äºget
        self.get_queue = threadsafe_data_struct.Queue() # [vtask1.idx, vtask2.idx, ...] # between update and main thread
        # åˆ›å»ºä¸€ä¸ªupdateçº¿ç¨‹
        self.update_thread = threading.Thread(target=self._thread_func)
        self.update_thread.daemon = True
        # å¼€å¯updateçº¿ç¨‹
        self.update_thread.start()
        # print("[UpdateInBkgd] rank{} started update_thread".format(self.rank))
        # 
        self.the_last_put = None

        self.local_model = local_model

    # ä¸æ–­å°è¯•ä»put_queueé˜Ÿåˆ—ä¸­æ‹¿å–ä»»åŠ¡ï¼Œå¯¹æ¯ä¸ªä»»åŠ¡æ‰§è¡Œï¼š
    # 1.ç­‰å¾…å½“å‰streamä¸­çš„æ‰€æœ‰æ“ä½œå…¨éƒ¨å®Œæˆï¼Œç„¶åæ‰ä¼šç»§ç»­æ‰§è¡Œåç»­çš„ä»£ç ã€‚å³ç­‰å¾…dW,B'è¢«swapåˆ°pinned memoryä¸­
    # 2.å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†cpuä¸Šshared_model.pinned_bufä¸­çš„æ•°æ®å¤åˆ¶åˆ°shared_modelå…±äº«å†…å­˜çš„vlayerçš„ buffer ä¸­ï¼Œ
    #   å³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
    # 3.æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
    # 4.å°†å®Œæˆçš„ä»»åŠ¡çš„idxåŠ å…¥åˆ°get_queueé˜Ÿåˆ—ä¸­
    def _thread_func(self):
        """ This method is to be executed from a daemon thread. """
        while True: # for each incoming task 
            # æ‹¿åˆ°put_queueä¸­çš„ç¬¬ä¸€ä¸ªvtask
            # è‹¥é˜Ÿåˆ—ä¸­æ²¡æœ‰ä»»åŠ¡ï¼Œä¼šä¸€ç›´ç­‰å¾…ï¼Œç›´åˆ°å‡ºç°ä»»åŠ¡æ­¤å¤„æ‰ä¼šç»§ç»­è¿›è¡Œ
            vt = self.put_queue.remove() # blocking
            if self.nvprof: nvtx_range_push("__task{}({}) UPD(W)".format(vt.idx, vt.show_layers())) 
            # å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†cpu pinned memoryä¸­çš„bufferæ•°æ®å¤åˆ¶åˆ°
            # ä½äºå…±äº«å†…å­˜çš„ layer è‡ªèº«çš„ buffer ä¸­ï¼Œå³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
            self._update_buf(vt) # if using local pinned model for B'
            # æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
            self._step(vt)
            # ä»»åŠ¡çš„idxåŠ å…¥åˆ°get_queueé˜Ÿåˆ—ä¸­
            self.get_queue.add(vt.idx)
            if self.nvprof: nvtx_range_pop() 

    # åœ¨é»˜è®¤æµä¸Šé˜»å¡ï¼Œç›´åˆ°å…¶ä¸­æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚å®é™…æƒ…å†µæ˜¯è¯¥çº¿ç¨‹åœ¨swapout dW Båå·¥ä½œï¼Œå…¶å®å°±æ˜¯åœ¨ç­‰é»˜è®¤æµä¸Šçš„swap outå®Œæˆ
    def _wait_swapout(self, vt, layer_id):
        """ Wait swap out (dW,B') to complete (and reside in pinned memory) """
        if self.nvprof: nvtx_range_push("__task{}(L{}) UPD(W): waiting swap and delete finish".format(vt.idx, layer_id)) 
        _layer_waiting_futs(self.local_model[layer_id].model, layer_id)
        if self.nvprof: nvtx_range_pop() 

    # å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†pinned memoryä¸­çš„bufferæ•°æ®å¤åˆ¶åˆ°shared_modelå…±äº«å†…å­˜çš„vlayerçš„ buffer ä¸­ï¼Œ
    # å³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
    @torch.no_grad()
    def _update_buf(self, vt):
        """ update B of this pack """  
        # è°ƒç”¨vtä¸­çš„æ‰€æœ‰çš„layerçš„
        for l in vt.layers:
            if l != vt.layers[0]:
                print(f"rank:{self.rank}, å¼€å§‹ç­‰å¾…layer{l}çš„å¸è½½å®Œæˆ")
                self._wait_swapout(vt, l)
            # å°†pinned memory (shared_model.pinned_buf) ä¸­ä¿å­˜çš„buffer tensorå¤åˆ¶åˆ°ä½äºå…±äº«å†…å­˜çš„
            # æ¨¡å‹(å°±æ˜¯ä¸€å±‚)çš„ buffer ä¸­ï¼Œå³shared_model.named_buffers() 
            self.shared_optimizer[l].update_buf()
    
    # æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
    @torch.no_grad()
    def _step(self, vt):
        """ update W,K of this pack """  
        # print(f"rank:{self.rank}, æ›´æ–°å‰çš„å‚æ•°å’Œbuffer, {vt.show_layers()}({vt.type})")
        # for l in vt.layers:
        #     for name,param in self.shared_optimizer[l].shared_model.named_parameters():
        #         print(f"rank:{self.rank}, L({l}), Parameter {name} is {param}")
        #     for name, shared_buf in self.shared_optimizer[l].shared_model.named_buffers():
        #         if shared_buf is not None:    
        #             print(f"rank:{self.rank}, L({l}), buffer {name} is {shared_buf}")
        # torch.set_printoptions(precision=15)
        # print(f"rank:{self.rank}, åœ¨stepä¹‹å‰æ‰“å°CPUä¸Šçš„æ¢¯åº¦, {vt.show_layers()}({vt.type})")
        # for l in vt.layers:
        #     for name,param in self.shared_optimizer[l].shared_model.named_parameters():
        #         print(f"rank:{self.rank}, L({l}), Parameter {name} is {param.grad}")
        for l in vt.layers:
            assert vt.In['dW'][l].medium == "LOC"
            assert vt.In['W'][l].medium == "SHM"  
            assert vt.In['K'][l].medium == "SHM"
            assert vt.Out['W'][l].medium == "SHM"
            assert vt.Out['K'][l].medium == "SHM" 

            # ä½¿ç”¨å…±äº«ä¼˜åŒ–å™¨æ›´æ–°å‚æ•°
            self.shared_optimizer[l].step() # Update shared model and optim using swap-out'ed local .grad
            # å¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œåˆ™è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
            if self.lr_scheduler != []: # "gpt2_huggingface"
                if self.lr_scheduler[l] is not None:
                    assert self.shared_optimizer[l].shared_optimizer is not None
                    self.lr_scheduler[l].step() 
                else:
                    assert self.shared_optimizer[l].shared_optimizer is None
        # print("[UpdateInBkgd] rank{} updated task{}({})".format(self.rank, vt.idx, vt.show_layers()))

        # print(f"rank:{self.rank}, æ›´æ–°åçš„å‚æ•°å’Œbuffer, {vt.show_layers()}({vt.type})")
        # for l in vt.layers:
        #     for name,param in self.shared_optimizer[l].shared_model.named_parameters():
        #         print(f"rank:{self.rank}, L({l}), Parameter {name} is {param}")
        #     for name, shared_buf in self.shared_optimizer[l].shared_model.named_buffers():
        #         if shared_buf is not None:    
        #             print(f"rank:{self.rank}, L({l}), buffer {name} is {shared_buf}")

    # å°†ç»™å®šçš„vtæ”¾å…¥åˆ°put_queueé˜Ÿåˆ—ä¸­ï¼ŒåŒæ—¶å°†self.the_last_put è®¾ç½®ä¸º vt.idxã€‚
    # ğŸ“Œè¿™æ„å‘³ç€UpdateInBkgdå®ä¾‹çš„çº¿ç¨‹ä¼šå¼€å§‹æ‰§è¡Œvtä¸Šçš„layerçš„bufferä»å›ºå®šå†…å­˜åˆ°å…±äº«å†…å­˜çš„å¤åˆ¶ï¼Œä»¥åŠåœ¨shared_memoryä¸Šè¿›è¡Œå‚æ•°çš„æ›´æ–°
    def iput(self, vt):
        ''' Call by main thread. Nonblocking.'''
        assert isinstance(vt, vTask)
        self.put_queue.add(vt)
        self.the_last_put = vt.idx

    def get(self):
        ''' Call by main thread. Blocking. Return vt.idx. '''
        return self.get_queue.remove()
    
    # ç­‰å¾…æœ€åä¸€ä¸ªæ”¾è¿›put_queueä¸­çš„ä»»åŠ¡ä»get_queueä¸­æ‹¿å‡ºæ¥ï¼Œå³æ‰§è¡Œå®Œæˆ
    def synchronize(self): 
        ''' Call by main thread. Blocking. Wait for all tasks in put_queue to complete. '''
        # depends on Assumption #0; wait for the last put idx 
        if self.the_last_put is None:
            return
        # print("[UpdateInBkgd] rank{} synchronize until task{}".format(self.rank,self.the_last_put))
        while True:
            vt_idx = self.get_queue.remove()
            if vt_idx == self.the_last_put:
                break
        # print("[UpdateInBkgd] rank{} has got task{}".format(self.rank,self.the_last_put))


############################ my version 3 #######################################
# ä¸»è¦æ˜¯æ·»åŠ æ–°çš„å±æ€§ local_modelï¼Œç”¨äºåœ¨UDPæ—¶ç­‰å¾…å¯¹åº”å±‚çš„å¸è½½å’Œåˆ é™¤å®Œæˆ
# 3ç‰ˆæ–°ç‰¹æ€§ï¼š
#  ä¸åŸç‰ˆå’Œç¬¬äºŒç‰ˆä¸åŒï¼Œä¸€æ¬¡å¤„ç†ä¸€ä¸ªlayerï¼Œç”¨äºå°†å½“å‰å±‚çš„æ›´æ–°å’Œå‰ä¸€å±‚çš„BWD overlap
class UpdateInBkgd_3(object):
    """ Handles CPU update model in background thread for runtime.py 
        Assumption:
            0) simliar to FIFO queue. put each task, and get updated task. 
            1) no sync_pinned_model(), which should be moved to next FWD/BWD's SwapIn
        NOTE: move vt.medium check back to runtime by reducing granularity to vLayer?
    """
    def __init__(self, swapout_stream, shared_optimizer, local_model, lr_scheduler, rank, nvprof=False):
        self.swapout_stream = swapout_stream # å®é™…ä¸ºé»˜è®¤è®¡ç®—æµ
        self.shared_optimizer = shared_optimizer
        self.lr_scheduler = lr_scheduler
        self.rank = rank
        self.nvprof = nvprof
        # initialize
        # å®ä¾‹åŒ–ä¸€ä¸ªçº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—ï¼Œç”¨äºput
        self.put_queue = threadsafe_data_struct.Queue() # [vtask1, vtask2, ...] # between main and update thread
        # å®ä¾‹åŒ–ä¸€ä¸ªçº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—ï¼Œç”¨äºget
        self.get_queue = threadsafe_data_struct.Queue() # [vtask1.idx, vtask2.idx, ...] # between update and main thread
        # åˆ›å»ºä¸€ä¸ªupdateçº¿ç¨‹
        self.update_thread = threading.Thread(target=self._thread_func)
        self.update_thread.daemon = True
        # å¼€å¯updateçº¿ç¨‹
        self.update_thread.start()
        # print("[UpdateInBkgd] rank{} started update_thread".format(self.rank))
        # 
        self.the_last_put = None

        self.local_model = local_model

    # ä¸æ–­å°è¯•ä»put_queueé˜Ÿåˆ—ä¸­æ‹¿å–ä»»åŠ¡ï¼Œå¯¹æ¯ä¸ªä»»åŠ¡æ‰§è¡Œï¼š
    # 1.ç­‰å¾…å½“å‰streamä¸­çš„æ‰€æœ‰æ“ä½œå…¨éƒ¨å®Œæˆï¼Œç„¶åæ‰ä¼šç»§ç»­æ‰§è¡Œåç»­çš„ä»£ç ã€‚å³ç­‰å¾…dW,B'è¢«swapåˆ°pinned memoryä¸­
    # 2.å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†cpuä¸Šshared_model.pinned_bufä¸­çš„æ•°æ®å¤åˆ¶åˆ°shared_modelå…±äº«å†…å­˜çš„vlayerçš„ buffer ä¸­ï¼Œ
    #   å³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
    # 3.æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
    # 4.å°†å®Œæˆçš„ä»»åŠ¡çš„idxåŠ å…¥åˆ°get_queueé˜Ÿåˆ—ä¸­
    def _thread_func(self):
        """ This method is to be executed from a daemon thread. """
        while True: # for each incoming task 
            # æ‹¿åˆ°put_queueä¸­çš„ç¬¬ä¸€ä¸ªvtask
            # è‹¥é˜Ÿåˆ—ä¸­æ²¡æœ‰ä»»åŠ¡ï¼Œä¼šä¸€ç›´ç­‰å¾…ï¼Œç›´åˆ°å‡ºç°ä»»åŠ¡æ­¤å¤„æ‰ä¼šç»§ç»­è¿›è¡Œ
            vt, layer_id = self.put_queue.remove() # blocking
            if self.nvprof: nvtx_range_push("__task{}({}) UPD(W)".format(vt.idx, vt.show_layers())) 
            # å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†cpu pinned memoryä¸­çš„bufferæ•°æ®å¤åˆ¶åˆ°
            # ä½äºå…±äº«å†…å­˜çš„ layer è‡ªèº«çš„ buffer ä¸­ï¼Œå³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
            self._update_buf(vt, layer_id) # if using local pinned model for B'
            # æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
            self._step(vt, layer_id)
            # ä»»åŠ¡çš„idxåŠ å…¥åˆ°get_queueé˜Ÿåˆ—ä¸­
            self.get_queue.add(vt.idx)
            if self.nvprof: nvtx_range_pop() 

    # åœ¨é»˜è®¤æµä¸Šé˜»å¡ï¼Œç›´åˆ°å…¶ä¸­æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚å®é™…æƒ…å†µæ˜¯è¯¥çº¿ç¨‹åœ¨swapout dW Båå·¥ä½œï¼Œå…¶å®å°±æ˜¯åœ¨ç­‰é»˜è®¤æµä¸Šçš„swap outå®Œæˆ
    def _wait_swapout(self, vt, layer_id):
        """ Wait swap out (dW,B') to complete (and reside in pinned memory) """
        if self.nvprof: nvtx_range_push("__task{}(L{}) UPD(W): waiting swap and delete finish".format(vt.idx, layer_id)) 
        _layer_waiting_futs(self.local_model[layer_id].model, layer_id)
        if self.nvprof: nvtx_range_pop() 

    # å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†pinned memoryä¸­çš„bufferæ•°æ®å¤åˆ¶åˆ°shared_modelå…±äº«å†…å­˜çš„vlayerçš„ buffer ä¸­ï¼Œ
    # å³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
    @torch.no_grad()
    def _update_buf(self, vt, layer_id):
        """ update B of this pack """  
        print(f"rank:{self.rank}, å¼€å§‹ç­‰å¾…layer{layer_id}çš„å¸è½½å®Œæˆ")
        self._wait_swapout(vt, layer_id)
        # å°†pinned memory (shared_model.pinned_buf) ä¸­ä¿å­˜çš„buffer tensorå¤åˆ¶åˆ°ä½äºå…±äº«å†…å­˜çš„
        # æ¨¡å‹(å°±æ˜¯ä¸€å±‚)çš„ buffer ä¸­ï¼Œå³shared_model.named_buffers() 
        self.shared_optimizer[layer_id].update_buf()
    
    # æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
    @torch.no_grad()
    def _step(self, vt, layer_id):
        """ update W,K of this pack """  
        assert vt.In['dW'][layer_id].medium == "LOC"
        assert vt.In['W'][layer_id].medium == "SHM"  
        assert vt.In['K'][layer_id].medium == "SHM"
        assert vt.Out['W'][layer_id].medium == "SHM"
        assert vt.Out['K'][layer_id].medium == "SHM" 

        # ä½¿ç”¨å…±äº«ä¼˜åŒ–å™¨æ›´æ–°å‚æ•°
        self.shared_optimizer[layer_id].step() # Update shared model and optim using swap-out'ed local .grad
        # å¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œåˆ™è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
        if self.lr_scheduler != []: # "gpt2_huggingface"
            if self.lr_scheduler[layer_id] is not None:
                assert self.shared_optimizer[layer_id].shared_optimizer is not None
                self.lr_scheduler[layer_id].step() 
            else:
                assert self.shared_optimizer[layer_id].shared_optimizer is None
        # print("[UpdateInBkgd] rank{} updated task{}({})".format(self.rank, vt.idx, vt.show_layers()))

    # å°†ç»™å®šçš„vtæ”¾å…¥åˆ°put_queueé˜Ÿåˆ—ä¸­ï¼ŒåŒæ—¶å°†self.the_last_put è®¾ç½®ä¸º vt.idxã€‚
    # ğŸ“Œè¿™æ„å‘³ç€UpdateInBkgdå®ä¾‹çš„çº¿ç¨‹ä¼šå¼€å§‹æ‰§è¡Œvtä¸Šçš„layerçš„bufferä»å›ºå®šå†…å­˜åˆ°å…±äº«å†…å­˜çš„å¤åˆ¶ï¼Œä»¥åŠåœ¨shared_memoryä¸Šè¿›è¡Œå‚æ•°çš„æ›´æ–°
    def iput(self, vt, layer_id):
        ''' Call by main thread. Nonblocking.'''
        assert isinstance(vt, vTask)
        self.put_queue.add(vt, layer_id)
        self.the_last_put = vt.idx

    def get(self):
        ''' Call by main thread. Blocking. Return vt.idx. '''
        return self.get_queue.remove()
    
    # ç­‰å¾…æœ€åä¸€ä¸ªæ”¾è¿›put_queueä¸­çš„ä»»åŠ¡ä»get_queueä¸­æ‹¿å‡ºæ¥ï¼Œå³æ‰§è¡Œå®Œæˆ
    def synchronize(self): 
        ''' Call by main thread. Blocking. Wait for all tasks in put_queue to complete. '''
        # depends on Assumption #0; wait for the last put idx 
        if self.the_last_put is None:
            return
        # print("[UpdateInBkgd] rank{} synchronize until task{}".format(self.rank,self.the_last_put))
        while True:
            vt_idx = self.get_queue.remove()
            if vt_idx == self.the_last_put:
                break
        # print("[UpdateInBkgd] rank{} has got task{}".format(self.rank,self.the_last_put))

# work5æœ€åˆçš„ç‰ˆæœ¬ï¼ŒåµŒå¥—çº¿ç¨‹ï¼Œå³å¸è½½åˆ°nvmeä¸¢ç»™swap_to_nvme_handleræ‰§è¡Œ
# æ·»åŠ åŠŸèƒ½ï¼š
# 1.åœ¨CPUä¸Šæ›´æ–°å®Œæˆåï¼Œå°†è¯¥vtæ‰€æœ‰layerå¸è½½åˆ°nvme
class UpdateInBkgd_for_worker5(object):
    """ Handles CPU update model in background thread for runtime.py 
        Assumption:
            0) simliar to FIFO queue. put each task, and get updated task. 
            1) no sync_pinned_model(), which should be moved to next FWD/BWD's SwapIn
        NOTE: move vt.medium check back to runtime by reducing granularity to vLayer?
    """
    def __init__(self, swapout_stream, shared_optimizer, swap_to_nvme_handler, lr_scheduler, rank, nvprof=False):
        self.swapout_stream = swapout_stream # å®é™…ä¸ºé»˜è®¤è®¡ç®—æµ
        self.shared_optimizer = shared_optimizer
        self.lr_scheduler = lr_scheduler
        self.rank = rank
        self.nvprof = nvprof
        # initialize
        # å®ä¾‹åŒ–ä¸€ä¸ªçº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—ï¼Œç”¨äºput
        self.put_queue = threadsafe_data_struct.Queue() # [vtask1, vtask2, ...] # between main and update thread
        # å®ä¾‹åŒ–ä¸€ä¸ªçº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—ï¼Œç”¨äºget
        self.get_queue = threadsafe_data_struct.Queue() # [vtask1.idx, vtask2.idx, ...] # between update and main thread
        # åˆ›å»ºä¸€ä¸ªupdateçº¿ç¨‹
        self.update_thread = threading.Thread(target=self._thread_func)
        self.update_thread.daemon = True
        # å¼€å¯updateçº¿ç¨‹
        self.update_thread.start()
        # print("[UpdateInBkgd] rank{} started update_thread".format(self.rank))
        # 
        self.the_last_put = None

        # ğŸ“
        self.swap_to_nvme_handle: SwapToNVMeInBkgd = swap_to_nvme_handler

    # ä¸æ–­å°è¯•ä»put_queueé˜Ÿåˆ—ä¸­æ‹¿å–ä»»åŠ¡ï¼Œå¯¹æ¯ä¸ªä»»åŠ¡æ‰§è¡Œï¼š
    # 1.ç­‰å¾…å½“å‰streamä¸­çš„æ‰€æœ‰æ“ä½œå…¨éƒ¨å®Œæˆï¼Œç„¶åæ‰ä¼šç»§ç»­æ‰§è¡Œåç»­çš„ä»£ç ã€‚å³ç­‰å¾…dW,B'è¢«swapåˆ°pinned memoryä¸­
    # 2.å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†cpuä¸Šshared_model.pinned_bufä¸­çš„æ•°æ®å¤åˆ¶åˆ°shared_modelå…±äº«å†…å­˜çš„vlayerçš„ buffer ä¸­ï¼Œ
    #   å³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
    # 3.æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
    # 4.å°†å®Œæˆçš„ä»»åŠ¡çš„idxåŠ å…¥åˆ°get_queueé˜Ÿåˆ—ä¸­
    def _thread_func(self):
        """ This method is to be executed from a daemon thread. """
        while True: # for each incoming task 
            # æ‹¿åˆ°put_queueä¸­çš„ç¬¬ä¸€ä¸ªvtask
            # è‹¥é˜Ÿåˆ—ä¸­æ²¡æœ‰ä»»åŠ¡ï¼Œä¼šä¸€ç›´ç­‰å¾…ï¼Œç›´åˆ°å‡ºç°ä»»åŠ¡æ­¤å¤„æ‰ä¼šç»§ç»­è¿›è¡Œ
            vt = self.put_queue.remove() # blocking
            if self.nvprof: nvtx_range_push("__task{}({}) UPD(W)".format(vt.idx, vt.show_layers())) 
            # åœ¨é»˜è®¤æµä¸Šé˜»å¡ï¼Œç›´åˆ°å…¶ä¸­æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚å®é™…æƒ…å†µæ˜¯è¯¥çº¿ç¨‹åœ¨swapout dW Båå·¥ä½œï¼Œå…¶å®å°±æ˜¯åœ¨ç­‰é»˜è®¤æµä¸Šçš„swap outå®Œæˆ
            self._wait_swapout()
            # å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†cpu pinned memoryä¸­çš„bufferæ•°æ®å¤åˆ¶åˆ°
            # ä½äºå…±äº«å†…å­˜çš„ layer è‡ªèº«çš„ buffer ä¸­ï¼Œå³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
            self._update_buf(vt) # if using local pinned model for B'
            # æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
            self._step(vt)

            # ğŸ“ç›®å‰æ˜¯é¡ºåºå¸è½½
            self.swap_to_nvme_handle.iput(vt)

            vt_idx = self.swap_to_nvme_handle.get()
            print(f"rank:{self.rank}, vt[{vt.layers}]å·²ä»swap_to_nvme get_queueä¸­æ‹¿åˆ°")
            assert vt_idx == vt.idx

            # ä»»åŠ¡çš„idxåŠ å…¥åˆ°get_queueé˜Ÿåˆ—ä¸­
            self.get_queue.add(vt.idx)
            if self.nvprof: nvtx_range_pop() 

    # åœ¨é»˜è®¤æµä¸Šé˜»å¡ï¼Œç›´åˆ°å…¶ä¸­æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚å®é™…æƒ…å†µæ˜¯è¯¥çº¿ç¨‹åœ¨swapout dW Båå·¥ä½œï¼Œå…¶å®å°±æ˜¯åœ¨ç­‰é»˜è®¤æµä¸Šçš„swap outå®Œæˆ
    def _wait_swapout(self):
        """ Wait swap out (dW,B') to complete (and reside in pinned memory) """
        self.swapout_stream.synchronize() # Wait for all the kernels in this stream to complete. # (maybe use cuda event in future)

    # å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†pinned memoryä¸­çš„bufferæ•°æ®å¤åˆ¶åˆ°shared_modelå…±äº«å†…å­˜çš„vlayerçš„ buffer ä¸­ï¼Œ
    # å³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
    @torch.no_grad()
    def _update_buf(self, vt):
        """ update B of this pack """  
        # è°ƒç”¨vtä¸­çš„æ‰€æœ‰çš„layerçš„
        for l in vt.layers:
            # å°†pinned memory (shared_model.pinned_buf) ä¸­ä¿å­˜çš„buffer tensorå¤åˆ¶åˆ°ä½äºå…±äº«å†…å­˜çš„
            # æ¨¡å‹(å°±æ˜¯ä¸€å±‚)çš„ buffer ä¸­ï¼Œå³shared_model.named_buffers() 
            self.shared_optimizer[l].update_buf()
    
    # æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
    @torch.no_grad()
    def _step(self, vt):
        """ update W,K of this pack """  
        for l in vt.layers:
            assert vt.In['dW'][l].medium == "LOC"
            assert vt.In['W'][l].medium == "SHM"  
            assert vt.In['K'][l].medium == "SHM"
            assert vt.Out['W'][l].medium == "SHM"
            assert vt.Out['K'][l].medium == "SHM" 
            # ä½¿ç”¨å…±äº«ä¼˜åŒ–å™¨æ›´æ–°å‚æ•°
            self.shared_optimizer[l].step() # Update shared model and optim using swap-out'ed local .grad
            # å¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œåˆ™è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
            if self.lr_scheduler != []: # "gpt2_huggingface"
                if self.lr_scheduler[l] is not None:
                    assert self.shared_optimizer[l].shared_optimizer is not None
                    self.lr_scheduler[l].step() 
                else:
                    assert self.shared_optimizer[l].shared_optimizer is None
        # print("[UpdateInBkgd] rank{} updated task{}({})".format(self.rank, vt.idx, vt.show_layers()))

    # å°†ç»™å®šçš„vtæ”¾å…¥åˆ°put_queueé˜Ÿåˆ—ä¸­ï¼ŒåŒæ—¶å°†self.the_last_put è®¾ç½®ä¸º vt.idxã€‚
    # ğŸ“Œè¿™æ„å‘³ç€UpdateInBkgdå®ä¾‹çš„çº¿ç¨‹ä¼šå¼€å§‹æ‰§è¡Œvtä¸Šçš„layerçš„bufferä»å›ºå®šå†…å­˜åˆ°å…±äº«å†…å­˜çš„å¤åˆ¶ï¼Œä»¥åŠåœ¨shared_memoryä¸Šè¿›è¡Œå‚æ•°çš„æ›´æ–°
    def iput(self, vt):
        ''' Call by main thread. Nonblocking.'''
        assert isinstance(vt, vTask)
        self.put_queue.add(vt)
        self.the_last_put = vt.idx

    def get(self):
        ''' Call by main thread. Blocking. Return vt.idx. '''
        return self.get_queue.remove()
    
    # 
    def synchronize(self): 
        ''' Call by main thread. Blocking. Wait for all tasks in put_queue to complete. '''
        # depends on Assumption #0; wait for the last put idx 
        if self.the_last_put is None:
            return
        # print("[UpdateInBkgd] rank{} synchronize until task{}".format(self.rank,self.the_last_put))
        while True:
            vt_idx = self.get_queue.remove()
            if vt_idx == self.the_last_put:
                break
        # print("[UpdateInBkgd] rank{} has got task{}".format(self.rank,self.the_last_put))

    # è¯¥ç±»æ–°æ·»åŠ çš„å‡½æ•°ï¼Œä¸“é—¨ç”¨æ¥åœ¨æ›´æ–°åå¸è½½å‚æ•°åˆ°NVMe
    # ç›´è§‰ä¸Šåº”è¯¥æŠŠè¯¥vtç»™å¦ä¸€ä¸ªçº¿ç¨‹,åå°è¿›è¡Œåˆ°nvmeçš„å¸è½½
    # def swap_out

# ä¸Šä¸€ä¸ªç±»æŠŠå¸è½½åˆ°nvmeçš„ä»»åŠ¡ä¸¢ç»™å¼‚æ­¥çº¿ç¨‹æ‰§è¡Œï¼Œè¯¥ç±»ä¸²è¡Œæ‰§è¡Œï¼Œä¸åµŒå¥—çº¿ç¨‹
class UpdateInBkgd_for_worker5_param_sync_version(object):
    """ Handles CPU update model in background thread for runtime.py 
        Assumption:
            0) simliar to FIFO queue. put each task, and get updated task. 
            1) no sync_pinned_model(), which should be moved to next FWD/BWD's SwapIn
        NOTE: move vt.medium check back to runtime by reducing granularity to vLayer?
    """
    def __init__(self, swapout_stream, shared_optimizer, lr_scheduler, layer_id_to_layer_idx, shared_model_nvme, layer_num, cpu_layer_id, rank, nvprof=False):
        self.swapout_stream = swapout_stream # å®é™…ä¸ºé»˜è®¤è®¡ç®—æµ
        self.shared_optimizer = shared_optimizer
        self.lr_scheduler = lr_scheduler
        self.layer_id_to_layer_idx = layer_id_to_layer_idx
        self.shared_model_nvme: SharedModelNVMe = shared_model_nvme
        self.rank = rank
        self.nvprof = nvprof
        # initialize
        # å®ä¾‹åŒ–ä¸€ä¸ªçº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—ï¼Œç”¨äºput
        self.put_queue = threadsafe_data_struct.Queue() # [vtask1, vtask2, ...] # between main and update thread
        # å®ä¾‹åŒ–ä¸€ä¸ªçº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—ï¼Œç”¨äºget
        self.get_queue = threadsafe_data_struct.Queue() # [vtask1.idx, vtask2.idx, ...] # between update and main thread
        # åˆ›å»ºä¸€ä¸ªupdateçº¿ç¨‹
        self.update_thread = threading.Thread(target=self._thread_func)
        self.update_thread.daemon = True
        # å¼€å¯updateçº¿ç¨‹
        self.update_thread.start()
        # print("[UpdateInBkgd] rank{} started update_thread".format(self.rank))
        # 
        self.the_last_put = None

        # ğŸ“
        self.layer_num = layer_num
        self.cpu_layer_id = cpu_layer_id

    # ä¸æ–­å°è¯•ä»put_queueé˜Ÿåˆ—ä¸­æ‹¿å–ä»»åŠ¡ï¼Œå¯¹æ¯ä¸ªä»»åŠ¡æ‰§è¡Œï¼š
    # 1.ç­‰å¾…å½“å‰streamä¸­çš„æ‰€æœ‰æ“ä½œå…¨éƒ¨å®Œæˆï¼Œç„¶åæ‰ä¼šç»§ç»­æ‰§è¡Œåç»­çš„ä»£ç ã€‚å³ç­‰å¾…dW,B'è¢«swapåˆ°pinned memoryä¸­
    # 2.å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†cpuä¸Šshared_model.pinned_bufä¸­çš„æ•°æ®å¤åˆ¶åˆ°shared_modelå…±äº«å†…å­˜çš„vlayerçš„ buffer ä¸­ï¼Œ
    #   å³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
    # 3.æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
    # 4.å°†å®Œæˆçš„ä»»åŠ¡çš„idxåŠ å…¥åˆ°get_queueé˜Ÿåˆ—ä¸­
    def _thread_func(self):
        """ This method is to be executed from a daemon thread. """
        while True: # for each incoming task 
            # æ‹¿åˆ°put_queueä¸­çš„ç¬¬ä¸€ä¸ªvtask
            # è‹¥é˜Ÿåˆ—ä¸­æ²¡æœ‰ä»»åŠ¡ï¼Œä¼šä¸€ç›´ç­‰å¾…ï¼Œç›´åˆ°å‡ºç°ä»»åŠ¡æ­¤å¤„æ‰ä¼šç»§ç»­è¿›è¡Œ
            vt = self.put_queue.remove() # blocking
            if self.nvprof: nvtx_range_push("__task{}({}) UPD(W)".format(vt.idx, vt.show_layers())) 
            # åœ¨é»˜è®¤æµä¸Šé˜»å¡ï¼Œç›´åˆ°å…¶ä¸­æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚å®é™…æƒ…å†µæ˜¯è¯¥çº¿ç¨‹åœ¨swapout dW Båå·¥ä½œï¼Œå…¶å®å°±æ˜¯åœ¨ç­‰é»˜è®¤æµä¸Šçš„swap outå®Œæˆ
            self._wait_swapout()
            # å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†cpu pinned memoryä¸­çš„bufferæ•°æ®å¤åˆ¶åˆ°
            # ä½äºå…±äº«å†…å­˜çš„ layer è‡ªèº«çš„ buffer ä¸­ï¼Œå³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
            self._update_buf(vt) # if using local pinned model for B'
            # æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
            self._step(vt)

            # ğŸ“ç›®å‰æ˜¯é¡ºåºå¸è½½
            self._swap_out_from_pinned_buffer(vt)

            # å°†shared_modelçš„dataå’Œgradç½®ä¸ºç©º
            self.shared_model_nvme.delete_vts_shared_model_param_grad_buf(vt)

            # ä»»åŠ¡çš„idxåŠ å…¥åˆ°get_queueé˜Ÿåˆ—ä¸­
            self.get_queue.add(vt.idx)
            if self.nvprof: nvtx_range_pop() 

    # åœ¨é»˜è®¤æµä¸Šé˜»å¡ï¼Œç›´åˆ°å…¶ä¸­æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚å®é™…æƒ…å†µæ˜¯è¯¥çº¿ç¨‹åœ¨swapout dW Båå·¥ä½œï¼Œå…¶å®å°±æ˜¯åœ¨ç­‰é»˜è®¤æµä¸Šçš„swap outå®Œæˆ
    def _wait_swapout(self):
        """ Wait swap out (dW,B') to complete (and reside in pinned memory) """
        self.swapout_stream.synchronize() # Wait for all the kernels in this stream to complete. # (maybe use cuda event in future)

    # å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†pinned memoryä¸­çš„bufferæ•°æ®å¤åˆ¶åˆ°shared_modelå…±äº«å†…å­˜çš„vlayerçš„ buffer ä¸­ï¼Œ
    # å³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
    @torch.no_grad()
    def _update_buf(self, vt):
        """ update B of this pack """  
        # è°ƒç”¨vtä¸­çš„æ‰€æœ‰çš„layerçš„
        for l in vt.layers:
            # å°†pinned memory (shared_model.pinned_buf) ä¸­ä¿å­˜çš„buffer tensorå¤åˆ¶åˆ°ä½äºå…±äº«å†…å­˜çš„
            # æ¨¡å‹(å°±æ˜¯ä¸€å±‚)çš„ buffer ä¸­ï¼Œå³shared_model.named_buffers() 
            self.shared_optimizer[l].update_buf()
    
    # æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
    @torch.no_grad()
    def _step(self, vt):
        """ update W,K of this pack """  
        for l in vt.layers:
            assert vt.In['dW'][l].medium == "LOC"
            assert vt.In['W'][l].medium == "SHM"  
            assert vt.In['K'][l].medium == "SHM"
            assert vt.Out['W'][l].medium == "SHM"
            assert vt.Out['K'][l].medium == "SHM" 
            # ä½¿ç”¨å…±äº«ä¼˜åŒ–å™¨æ›´æ–°å‚æ•°
            self.shared_optimizer[l].step() # Update shared model and optim using swap-out'ed local .grad
            # å¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œåˆ™è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
            if self.lr_scheduler != []: # "gpt2_huggingface"
                if self.lr_scheduler[l] is not None:
                    assert self.shared_optimizer[l].shared_optimizer is not None
                    self.lr_scheduler[l].step() 
                else:
                    assert self.shared_optimizer[l].shared_optimizer is None
        # print("[UpdateInBkgd] rank{} updated task{}({})".format(self.rank, vt.idx, vt.show_layers()))

    # å°†ç»™å®šçš„vtæ”¾å…¥åˆ°put_queueé˜Ÿåˆ—ä¸­ï¼ŒåŒæ—¶å°†self.the_last_put è®¾ç½®ä¸º vt.idxã€‚
    # ğŸ“Œè¿™æ„å‘³ç€UpdateInBkgdå®ä¾‹çš„çº¿ç¨‹ä¼šå¼€å§‹æ‰§è¡Œvtä¸Šçš„layerçš„bufferä»å›ºå®šå†…å­˜åˆ°å…±äº«å†…å­˜çš„å¤åˆ¶ï¼Œä»¥åŠåœ¨shared_memoryä¸Šè¿›è¡Œå‚æ•°çš„æ›´æ–°
    def iput(self, vt):
        ''' Call by main thread. Nonblocking.'''
        assert isinstance(vt, vTask)
        self.put_queue.add(vt)
        self.the_last_put = vt.idx

    def get(self):
        ''' Call by main thread. Blocking. Return vt.idx. '''
        return self.get_queue.remove()
    
    # 
    def synchronize(self): 
        ''' Call by main thread. Blocking. Wait for all tasks in put_queue to complete. '''
        # depends on Assumption #0; wait for the last put idx 
        if self.the_last_put is None:
            return
        # print("[UpdateInBkgd] rank{} synchronize until task{}".format(self.rank,self.the_last_put))
        while True:
            vt_idx = self.get_queue.remove()
            if vt_idx == self.the_last_put:
                break
        # print("[UpdateInBkgd] rank{} has got task{}".format(self.rank,self.the_last_put))

    # è¯¥ç±»æ–°æ·»åŠ çš„å‡½æ•°ï¼Œä¸“é—¨ç”¨æ¥åœ¨æ›´æ–°åå¸è½½å‚æ•°åˆ°NVMe
    def _swap_out_from_pinned_buffer(self, vt):
        for layer_id in vt.layers:
            # if vt.has_data and layer_id == vt.layers[0]:
            #     continue
            # if layer_id == self.layer_num-2:
            #     continue
            # if layer_id == self.layer_num-3:
            #     continue
            # # æœ€åä¸€å±‚åŒç†
            # if vt.has_criterion and layer_id == vt.layers[-1]:
            #     continue
            if layer_id in self.cpu_layer_id:
                continue

            # print(f"rank:{self.rank}, å‡†å¤‡è¦å¸è½½çš„vtçš„idxä¸º:{vt.idx}, ç±»å‹ä¸º{vt.type}")
            layer_idx = self.layer_id_to_layer_idx[vt.idx][layer_id]
            # print(f"rank:{self.rank}, layer{layer_id}å–åˆ°çš„layer_idxä¸º{layer_idx}")
            print(f"rank:{self.rank}, {layer_id}å‡†å¤‡ä»pinned bufferå¸è½½", flush=True)
            self.shared_model_nvme.swap_out_from_pinned_buffer_sync_2(layer_id, layer_idx)
            print(f"rank:{self.rank}, {layer_id}ä»pinned bufferå¸è½½å®Œæˆ", flush=True)

# UpdateInBkgd_for_worker5ç±»æŠŠå¸è½½åˆ°nvmeçš„ä»»åŠ¡ä¸¢ç»™å¼‚æ­¥çº¿ç¨‹æ‰§è¡Œï¼Œè¯¥ç±»ä¸²è¡Œæ‰§è¡Œï¼Œä¸åµŒå¥—çº¿ç¨‹
class UpdateInBkgd_for_worker5_2(object):
    """ Handles CPU update model in background thread for runtime.py 
        Assumption:
            0) simliar to FIFO queue. put each task, and get updated task. 
            1) no sync_pinned_model(), which should be moved to next FWD/BWD's SwapIn
        NOTE: move vt.medium check back to runtime by reducing granularity to vLayer?
    """
    def __init__(self, swapout_stream, shared_optimizer, lr_scheduler, layer_id_to_layer_idx, shared_model_nvme, layer_num, cpu_layer_id, rank, nvprof=False):
        self.swapout_stream = swapout_stream # å®é™…ä¸ºé»˜è®¤è®¡ç®—æµ
        self.shared_optimizer = shared_optimizer
        self.lr_scheduler = lr_scheduler
        self.layer_id_to_layer_idx = layer_id_to_layer_idx
        self.shared_model_nvme: SharedModelNVMe_2 = shared_model_nvme
        self.rank = rank
        self.nvprof = nvprof
        # initialize
        # å®ä¾‹åŒ–ä¸€ä¸ªçº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—ï¼Œç”¨äºput
        self.put_queue = threadsafe_data_struct.Queue() # [vtask1, vtask2, ...] # between main and update thread
        # å®ä¾‹åŒ–ä¸€ä¸ªçº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—ï¼Œç”¨äºget
        self.get_queue = threadsafe_data_struct.Queue() # [vtask1.idx, vtask2.idx, ...] # between update and main thread
        # åˆ›å»ºä¸€ä¸ªupdateçº¿ç¨‹
        self.update_thread = threading.Thread(target=self._thread_func)
        self.update_thread.daemon = True
        # å¼€å¯updateçº¿ç¨‹
        self.update_thread.start()
        # print("[UpdateInBkgd] rank{} started update_thread".format(self.rank))
        # 
        self.the_last_put = None

        # ğŸ“
        self.layer_num = layer_num
        self.cpu_layer_id = cpu_layer_id

    # ä¸æ–­å°è¯•ä»put_queueé˜Ÿåˆ—ä¸­æ‹¿å–ä»»åŠ¡ï¼Œå¯¹æ¯ä¸ªä»»åŠ¡æ‰§è¡Œï¼š
    # 1.ç­‰å¾…å½“å‰streamä¸­çš„æ‰€æœ‰æ“ä½œå…¨éƒ¨å®Œæˆï¼Œç„¶åæ‰ä¼šç»§ç»­æ‰§è¡Œåç»­çš„ä»£ç ã€‚å³ç­‰å¾…dW,B'è¢«swapåˆ°pinned memoryä¸­
    # 2.å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†cpuä¸Šshared_model.pinned_bufä¸­çš„æ•°æ®å¤åˆ¶åˆ°shared_modelå…±äº«å†…å­˜çš„vlayerçš„ buffer ä¸­ï¼Œ
    #   å³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
    # 3.æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
    # 4.å°†å®Œæˆçš„ä»»åŠ¡çš„idxåŠ å…¥åˆ°get_queueé˜Ÿåˆ—ä¸­
    def _thread_func(self):
        """ This method is to be executed from a daemon thread. """
        while True: # for each incoming task 
            # æ‹¿åˆ°put_queueä¸­çš„ç¬¬ä¸€ä¸ªvtask
            # è‹¥é˜Ÿåˆ—ä¸­æ²¡æœ‰ä»»åŠ¡ï¼Œä¼šä¸€ç›´ç­‰å¾…ï¼Œç›´åˆ°å‡ºç°ä»»åŠ¡æ­¤å¤„æ‰ä¼šç»§ç»­è¿›è¡Œ
            vt = self.put_queue.remove() # blocking
            if self.nvprof: nvtx_range_push("__task{}({}) UPD(W)".format(vt.idx, vt.show_layers())) 
            # åœ¨é»˜è®¤æµä¸Šé˜»å¡ï¼Œç›´åˆ°å…¶ä¸­æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚å®é™…æƒ…å†µæ˜¯è¯¥çº¿ç¨‹åœ¨swapout dW Båå·¥ä½œï¼Œå…¶å®å°±æ˜¯åœ¨ç­‰é»˜è®¤æµä¸Šçš„swap outå®Œæˆ
            self._wait_swapout()
            # å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†cpu pinned memoryä¸­çš„bufferæ•°æ®å¤åˆ¶åˆ°
            # ä½äºå…±äº«å†…å­˜çš„ layer è‡ªèº«çš„ buffer ä¸­ï¼Œå³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
            self._update_buf(vt) # if using local pinned model for B'
            # æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
            start_time = time.time()
            self._step(vt)
            end_time = time.time()
            step_time = end_time - start_time
            print(f"rank:{self.rank}, {vt.layers}æ›´æ–°å®Œæˆ, è€—æ—¶{step_time:.6f}ç§’", flush=True)

            # ğŸ“ç›®å‰æ˜¯é¡ºåºå¸è½½
            start_time = time.time()
            self._swap_out_from_pinned_buffer(vt)
            end_time = time.time()
            swap_out_time = end_time - start_time
            print(f"rank:{self.rank}, {vt.layers}ä»pinned bufferå¸è½½å®Œæˆ, è€—æ—¶{swap_out_time:.6f}ç§’", flush=True)

            # å°†shared_modelçš„dataå’Œgradç½®ä¸ºç©º
            self.shared_model_nvme.delete_vts_shared_model_param_grad_buf(vt)

            # ä»»åŠ¡çš„idxåŠ å…¥åˆ°get_queueé˜Ÿåˆ—ä¸­
            self.get_queue.add((vt.idx, step_time, swap_out_time))
            if self.nvprof: nvtx_range_pop() 

    # åœ¨é»˜è®¤æµä¸Šé˜»å¡ï¼Œç›´åˆ°å…¶ä¸­æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚å®é™…æƒ…å†µæ˜¯è¯¥çº¿ç¨‹åœ¨swapout dW Båå·¥ä½œï¼Œå…¶å®å°±æ˜¯åœ¨ç­‰é»˜è®¤æµä¸Šçš„swap outå®Œæˆ
    def _wait_swapout(self):
        """ Wait swap out (dW,B') to complete (and reside in pinned memory) """
        self.swapout_stream.synchronize() # Wait for all the kernels in this stream to complete. # (maybe use cuda event in future)

    # å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†pinned memoryä¸­çš„bufferæ•°æ®å¤åˆ¶åˆ°shared_modelå…±äº«å†…å­˜çš„vlayerçš„ buffer ä¸­ï¼Œ
    # å³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
    @torch.no_grad()
    def _update_buf(self, vt):
        """ update B of this pack """  
        # è°ƒç”¨vtä¸­çš„æ‰€æœ‰çš„layerçš„
        for l in vt.layers:
            # å°†pinned memory (shared_model.pinned_buf) ä¸­ä¿å­˜çš„buffer tensorå¤åˆ¶åˆ°ä½äºå…±äº«å†…å­˜çš„
            # æ¨¡å‹(å°±æ˜¯ä¸€å±‚)çš„ buffer ä¸­ï¼Œå³shared_model.named_buffers() 
            self.shared_optimizer[l].update_buf()
    
    # æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
    @torch.no_grad()
    def _step(self, vt):
        """ update W,K of this pack """  
        for l in vt.layers:
            assert vt.In['dW'][l].medium == "LOC"
            assert vt.In['W'][l].medium == "SHM"  
            assert vt.In['K'][l].medium == "SHM"
            assert vt.Out['W'][l].medium == "SHM"
            assert vt.Out['K'][l].medium == "SHM" 
            # ä½¿ç”¨å…±äº«ä¼˜åŒ–å™¨æ›´æ–°å‚æ•°
            self.shared_optimizer[l].step() # Update shared model and optim using swap-out'ed local .grad
            # å¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œåˆ™è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
            if self.lr_scheduler != []: # "gpt2_huggingface"
                if self.lr_scheduler[l] is not None:
                    assert self.shared_optimizer[l].shared_optimizer is not None
                    self.lr_scheduler[l].step() 
                else:
                    assert self.shared_optimizer[l].shared_optimizer is None
        # print("[UpdateInBkgd] rank{} updated task{}({})".format(self.rank, vt.idx, vt.show_layers()))

    # å°†ç»™å®šçš„vtæ”¾å…¥åˆ°put_queueé˜Ÿåˆ—ä¸­ï¼ŒåŒæ—¶å°†self.the_last_put è®¾ç½®ä¸º vt.idxã€‚
    # ğŸ“Œè¿™æ„å‘³ç€UpdateInBkgdå®ä¾‹çš„çº¿ç¨‹ä¼šå¼€å§‹æ‰§è¡Œvtä¸Šçš„layerçš„bufferä»å›ºå®šå†…å­˜åˆ°å…±äº«å†…å­˜çš„å¤åˆ¶ï¼Œä»¥åŠåœ¨shared_memoryä¸Šè¿›è¡Œå‚æ•°çš„æ›´æ–°
    def iput(self, vt):
        ''' Call by main thread. Nonblocking.'''
        assert isinstance(vt, vTask)
        self.put_queue.add(vt)
        self.the_last_put = vt.idx

    def get(self):
        ''' Call by main thread. Blocking. Return vt.idx. '''
        return self.get_queue.remove()
    
    # 
    def synchronize(self): 
        ''' Call by main thread. Blocking. Wait for all tasks in put_queue to complete. '''
        # depends on Assumption #0; wait for the last put idx 
        if self.the_last_put is None:
            return
        # print("[UpdateInBkgd] rank{} synchronize until task{}".format(self.rank,self.the_last_put))
        while True:
            vt_idx, _, _ = self.get_queue.remove()
            if vt_idx == self.the_last_put:
                break
        # print("[UpdateInBkgd] rank{} has got task{}".format(self.rank,self.the_last_put))

    # è¯¥ç±»æ–°æ·»åŠ çš„å‡½æ•°ï¼Œä¸“é—¨ç”¨æ¥åœ¨æ›´æ–°åå¸è½½å‚æ•°åˆ°NVMe
    def _swap_out_from_pinned_buffer(self, vt):
        for layer_id in vt.layers:
            # if vt.has_data and layer_id == vt.layers[0]:
            #     continue
            # if layer_id == self.layer_num-2:
            #     continue
            # if layer_id == self.layer_num-3:
            #     continue
            # # æœ€åä¸€å±‚åŒç†
            # if vt.has_criterion and layer_id == vt.layers[-1]:
            #     continue
            if layer_id in self.cpu_layer_id:
                continue

            # print(f"rank:{self.rank}, å‡†å¤‡è¦å¸è½½çš„vtçš„idxä¸º:{vt.idx}, ç±»å‹ä¸º{vt.type}")
            layer_idx = self.layer_id_to_layer_idx[vt.idx][layer_id]
            # print(f"rank:{self.rank}, layer{layer_id}å–åˆ°çš„layer_idxä¸º{layer_idx}")
            print(f"rank:{self.rank}, {layer_id}å‡†å¤‡ä»pinned bufferå¸è½½", flush=True)
            self.shared_model_nvme.swap_out_from_pinned_buffer_sync(layer_id, layer_idx)
            print(f"rank:{self.rank}, {layer_id}ä»pinned bufferå¸è½½å®Œæˆ", flush=True)

# 25/1/9æ·»åŠ 
# ä¸ä¸Šä¸€ä¸ªçš„åŒºåˆ«ï¼šé’ˆå¯¹new cpu layerè¿›è¡Œé’ˆå¯¹å¤„ç†
class UpdateInBkgd_for_worker5_2_new_cpu_layer(object):
    """ Handles CPU update model in background thread for runtime.py 
        Assumption:
            0) simliar to FIFO queue. put each task, and get updated task. 
            1) no sync_pinned_model(), which should be moved to next FWD/BWD's SwapIn
        NOTE: move vt.medium check back to runtime by reducing granularity to vLayer?
    """
    def __init__(self, swapout_stream, shared_optimizer, lr_scheduler, layer_id_to_layer_idx, shared_model_nvme, layer_num, cpu_layer_id, new_cpu_layer_id, rank, nvprof=False):
        self.swapout_stream = swapout_stream # å®é™…ä¸ºé»˜è®¤è®¡ç®—æµ
        self.shared_optimizer = shared_optimizer
        self.lr_scheduler = lr_scheduler
        self.layer_id_to_layer_idx = layer_id_to_layer_idx
        self.shared_model_nvme: SharedModelNVMe_2 = shared_model_nvme
        self.rank = rank
        self.nvprof = nvprof
        # initialize
        # å®ä¾‹åŒ–ä¸€ä¸ªçº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—ï¼Œç”¨äºput
        self.put_queue = threadsafe_data_struct.Queue() # [vtask1, vtask2, ...] # between main and update thread
        # å®ä¾‹åŒ–ä¸€ä¸ªçº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—ï¼Œç”¨äºget
        self.get_queue = threadsafe_data_struct.Queue() # [vtask1.idx, vtask2.idx, ...] # between update and main thread
        # åˆ›å»ºä¸€ä¸ªupdateçº¿ç¨‹
        self.update_thread = threading.Thread(target=self._thread_func)
        self.update_thread.daemon = True
        # å¼€å¯updateçº¿ç¨‹
        self.update_thread.start()
        # print("[UpdateInBkgd] rank{} started update_thread".format(self.rank))
        # 
        self.the_last_put = None

        # ğŸ“
        self.layer_num = layer_num
        self.cpu_layer_id = cpu_layer_id
        self.new_cpu_layer_id = new_cpu_layer_id

    # ä¸æ–­å°è¯•ä»put_queueé˜Ÿåˆ—ä¸­æ‹¿å–ä»»åŠ¡ï¼Œå¯¹æ¯ä¸ªä»»åŠ¡æ‰§è¡Œï¼š
    # 1.ç­‰å¾…å½“å‰streamä¸­çš„æ‰€æœ‰æ“ä½œå…¨éƒ¨å®Œæˆï¼Œç„¶åæ‰ä¼šç»§ç»­æ‰§è¡Œåç»­çš„ä»£ç ã€‚å³ç­‰å¾…dW,B'è¢«swapåˆ°pinned memoryä¸­
    # 2.å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†cpuä¸Šshared_model.pinned_bufä¸­çš„æ•°æ®å¤åˆ¶åˆ°shared_modelå…±äº«å†…å­˜çš„vlayerçš„ buffer ä¸­ï¼Œ
    #   å³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
    # 3.æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
    # 4.å°†å®Œæˆçš„ä»»åŠ¡çš„idxåŠ å…¥åˆ°get_queueé˜Ÿåˆ—ä¸­
    def _thread_func(self):
        """ This method is to be executed from a daemon thread. """
        while True: # for each incoming task 
            # æ‹¿åˆ°put_queueä¸­çš„ç¬¬ä¸€ä¸ªvtask
            # è‹¥é˜Ÿåˆ—ä¸­æ²¡æœ‰ä»»åŠ¡ï¼Œä¼šä¸€ç›´ç­‰å¾…ï¼Œç›´åˆ°å‡ºç°ä»»åŠ¡æ­¤å¤„æ‰ä¼šç»§ç»­è¿›è¡Œ
            vt = self.put_queue.remove() # blocking
            if self.nvprof: nvtx_range_push("__task{}({}) UPD(W)".format(vt.idx, vt.show_layers())) 
            # åœ¨é»˜è®¤æµä¸Šé˜»å¡ï¼Œç›´åˆ°å…¶ä¸­æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚å®é™…æƒ…å†µæ˜¯è¯¥çº¿ç¨‹åœ¨swapout dW Båå·¥ä½œï¼Œå…¶å®å°±æ˜¯åœ¨ç­‰é»˜è®¤æµä¸Šçš„swap outå®Œæˆ
            self._wait_swapout()
            # å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†cpu pinned memoryä¸­çš„bufferæ•°æ®å¤åˆ¶åˆ°
            # ä½äºå…±äº«å†…å­˜çš„ layer è‡ªèº«çš„ buffer ä¸­ï¼Œå³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
            self._update_buf(vt) # if using local pinned model for B'
            # æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
            self._step(vt)

            # ğŸ“ç›®å‰æ˜¯é¡ºåºå¸è½½
            self._swap_out_from_pinned_buffer(vt)

            # å°†shared_modelçš„dataå’Œgradç½®ä¸ºç©º
            self.shared_model_nvme.delete_vts_shared_model_param_grad_buf_for_new_cpu_layer(vt, self.new_cpu_layer_id)

            # ä»»åŠ¡çš„idxåŠ å…¥åˆ°get_queueé˜Ÿåˆ—ä¸­
            self.get_queue.add(vt.idx)
            if self.nvprof: nvtx_range_pop() 

    # åœ¨é»˜è®¤æµä¸Šé˜»å¡ï¼Œç›´åˆ°å…¶ä¸­æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚å®é™…æƒ…å†µæ˜¯è¯¥çº¿ç¨‹åœ¨swapout dW Båå·¥ä½œï¼Œå…¶å®å°±æ˜¯åœ¨ç­‰é»˜è®¤æµä¸Šçš„swap outå®Œæˆ
    def _wait_swapout(self):
        """ Wait swap out (dW,B') to complete (and reside in pinned memory) """
        self.swapout_stream.synchronize() # Wait for all the kernels in this stream to complete. # (maybe use cuda event in future)

    # å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†pinned memoryä¸­çš„bufferæ•°æ®å¤åˆ¶åˆ°shared_modelå…±äº«å†…å­˜çš„vlayerçš„ buffer ä¸­ï¼Œ
    # å³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
    @torch.no_grad()
    def _update_buf(self, vt):
        """ update B of this pack """  
        # è°ƒç”¨vtä¸­çš„æ‰€æœ‰çš„layerçš„
        for l in vt.layers:
            # å°†pinned memory (shared_model.pinned_buf) ä¸­ä¿å­˜çš„buffer tensorå¤åˆ¶åˆ°ä½äºå…±äº«å†…å­˜çš„
            # æ¨¡å‹(å°±æ˜¯ä¸€å±‚)çš„ buffer ä¸­ï¼Œå³shared_model.named_buffers() 
            self.shared_optimizer[l].update_buf()
    
    # æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
    @torch.no_grad()
    def _step(self, vt):
        """ update W,K of this pack """  
        for l in vt.layers:
            assert vt.In['dW'][l].medium == "LOC"
            assert vt.In['W'][l].medium == "SHM"  
            assert vt.In['K'][l].medium == "SHM"
            assert vt.Out['W'][l].medium == "SHM"
            assert vt.Out['K'][l].medium == "SHM" 
            # ä½¿ç”¨å…±äº«ä¼˜åŒ–å™¨æ›´æ–°å‚æ•°
            self.shared_optimizer[l].step() # Update shared model and optim using swap-out'ed local .grad
            # å¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œåˆ™è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
            if self.lr_scheduler != []: # "gpt2_huggingface"
                if self.lr_scheduler[l] is not None:
                    assert self.shared_optimizer[l].shared_optimizer is not None
                    self.lr_scheduler[l].step() 
                else:
                    assert self.shared_optimizer[l].shared_optimizer is None
        # print("[UpdateInBkgd] rank{} updated task{}({})".format(self.rank, vt.idx, vt.show_layers()))

    # å°†ç»™å®šçš„vtæ”¾å…¥åˆ°put_queueé˜Ÿåˆ—ä¸­ï¼ŒåŒæ—¶å°†self.the_last_put è®¾ç½®ä¸º vt.idxã€‚
    # ğŸ“Œè¿™æ„å‘³ç€UpdateInBkgdå®ä¾‹çš„çº¿ç¨‹ä¼šå¼€å§‹æ‰§è¡Œvtä¸Šçš„layerçš„bufferä»å›ºå®šå†…å­˜åˆ°å…±äº«å†…å­˜çš„å¤åˆ¶ï¼Œä»¥åŠåœ¨shared_memoryä¸Šè¿›è¡Œå‚æ•°çš„æ›´æ–°
    def iput(self, vt):
        ''' Call by main thread. Nonblocking.'''
        assert isinstance(vt, vTask)
        self.put_queue.add(vt)
        self.the_last_put = vt.idx

    def get(self):
        ''' Call by main thread. Blocking. Return vt.idx. '''
        return self.get_queue.remove()
    
    # 
    def synchronize(self): 
        ''' Call by main thread. Blocking. Wait for all tasks in put_queue to complete. '''
        # depends on Assumption #0; wait for the last put idx 
        if self.the_last_put is None:
            return
        # print("[UpdateInBkgd] rank{} synchronize until task{}".format(self.rank,self.the_last_put))
        while True:
            vt_idx = self.get_queue.remove()
            if vt_idx == self.the_last_put:
                break
        # print("[UpdateInBkgd] rank{} has got task{}".format(self.rank,self.the_last_put))

    # è¯¥ç±»æ–°æ·»åŠ çš„å‡½æ•°ï¼Œä¸“é—¨ç”¨æ¥åœ¨æ›´æ–°åå¸è½½å‚æ•°åˆ°NVMe
    def _swap_out_from_pinned_buffer(self, vt):
        for layer_id in vt.layers:
            if layer_id in self.cpu_layer_id or layer_id in self.new_cpu_layer_id:
                continue

            # print(f"rank:{self.rank}, å‡†å¤‡è¦å¸è½½çš„vtçš„idxä¸º:{vt.idx}, ç±»å‹ä¸º{vt.type}")
            layer_idx = self.layer_id_to_layer_idx[vt.idx][layer_id]
            # print(f"rank:{self.rank}, layer{layer_id}å–åˆ°çš„layer_idxä¸º{layer_idx}")
            print(f"rank:{self.rank}, {layer_id}å‡†å¤‡ä»pinned bufferå¸è½½", flush=True)
            self.shared_model_nvme.swap_out_from_pinned_buffer_sync(layer_id, layer_idx)
            print(f"rank:{self.rank}, {layer_id}ä»pinned bufferå¸è½½å®Œæˆ", flush=True)


# ç‰ˆæœ¬3ï¼šåŒbufferç‰ˆæœ¬
class UpdateInBkgd_for_worker5_double_buffer(object):
    """ Handles CPU update model in background thread for runtime.py 
        Assumption:
            0) simliar to FIFO queue. put each task, and get updated task. 
            1) no sync_pinned_model(), which should be moved to next FWD/BWD's SwapIn
        NOTE: move vt.medium check back to runtime by reducing granularity to vLayer?
    """
    def __init__(self, swapout_stream, shared_optimizer, lr_scheduler, layer_id_to_layer_idx, shared_model_nvme, layer_num, cpu_layer_id, rank, nvprof=False):
        self.swapout_stream = swapout_stream # å®é™…ä¸ºé»˜è®¤è®¡ç®—æµ
        self.shared_optimizer = shared_optimizer
        self.lr_scheduler = lr_scheduler
        self.layer_id_to_layer_idx = layer_id_to_layer_idx
        self.shared_model_nvme: SharedModelNVMe_double_buffer = shared_model_nvme
        self.rank = rank
        self.nvprof = nvprof
        # initialize
        # å®ä¾‹åŒ–ä¸€ä¸ªçº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—ï¼Œç”¨äºput
        self.put_queue = threadsafe_data_struct.Queue() # [vtask1, vtask2, ...] # between main and update thread
        # å®ä¾‹åŒ–ä¸€ä¸ªçº¿ç¨‹å®‰å…¨çš„é˜Ÿåˆ—ï¼Œç”¨äºget
        self.get_queue = threadsafe_data_struct.Queue() # [vtask1.idx, vtask2.idx, ...] # between update and main thread
        # åˆ›å»ºä¸€ä¸ªupdateçº¿ç¨‹
        self.update_thread = threading.Thread(target=self._thread_func)
        self.update_thread.daemon = True
        # å¼€å¯updateçº¿ç¨‹
        self.update_thread.start()
        # print("[UpdateInBkgd] rank{} started update_thread".format(self.rank))
        # 
        self.the_last_put = None

        # ğŸ“
        self.layer_num = layer_num
        self.cpu_layer_id = cpu_layer_id

    # ä¸æ–­å°è¯•ä»put_queueé˜Ÿåˆ—ä¸­æ‹¿å–ä»»åŠ¡ï¼Œå¯¹æ¯ä¸ªä»»åŠ¡æ‰§è¡Œï¼š
    # 1.ç­‰å¾…å½“å‰streamä¸­çš„æ‰€æœ‰æ“ä½œå…¨éƒ¨å®Œæˆï¼Œç„¶åæ‰ä¼šç»§ç»­æ‰§è¡Œåç»­çš„ä»£ç ã€‚å³ç­‰å¾…dW,B'è¢«swapåˆ°pinned memoryä¸­
    # 2.å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†cpuä¸Šshared_model.pinned_bufä¸­çš„æ•°æ®å¤åˆ¶åˆ°shared_modelå…±äº«å†…å­˜çš„vlayerçš„ buffer ä¸­ï¼Œ
    #   å³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
    # 3.æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
    # 4.å°†å®Œæˆçš„ä»»åŠ¡çš„idxåŠ å…¥åˆ°get_queueé˜Ÿåˆ—ä¸­
    def _thread_func(self):
        """ This method is to be executed from a daemon thread. """
        while True: # for each incoming task 
            # æ‹¿åˆ°put_queueä¸­çš„ç¬¬ä¸€ä¸ªvtask
            # è‹¥é˜Ÿåˆ—ä¸­æ²¡æœ‰ä»»åŠ¡ï¼Œä¼šä¸€ç›´ç­‰å¾…ï¼Œç›´åˆ°å‡ºç°ä»»åŠ¡æ­¤å¤„æ‰ä¼šç»§ç»­è¿›è¡Œ
            vt = self.put_queue.remove() # blocking
            if self.nvprof: nvtx_range_push("__task{}({}) UPD(W)".format(vt.idx, vt.show_layers())) 
            # åœ¨é»˜è®¤æµä¸Šé˜»å¡ï¼Œç›´åˆ°å…¶ä¸­æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚å®é™…æƒ…å†µæ˜¯è¯¥çº¿ç¨‹åœ¨swapout dW Båå·¥ä½œï¼Œå…¶å®å°±æ˜¯åœ¨ç­‰é»˜è®¤æµä¸Šçš„swap outå®Œæˆ
            self._wait_swapout()
            # å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†cpu pinned memoryä¸­çš„bufferæ•°æ®å¤åˆ¶åˆ°
            # ä½äºå…±äº«å†…å­˜çš„ layer è‡ªèº«çš„ buffer ä¸­ï¼Œå³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
            self._update_buf(vt) # if using local pinned model for B'
            # æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
            self._step(vt)

            # è·å–buffer_idï¼Œç°åœ¨æ˜¯UPDä»»åŠ¡ï¼Œbufferå·²åœ¨BWDä»»åŠ¡æ—¶è·å–
            buffer_id = self.shared_model_nvme.get_buffer_id(vt)

            # ğŸ“ç›®å‰æ˜¯é¡ºåºå¸è½½
            self._swap_out_from_pinned_buffer(buffer_id, vt)

            # TODO:
            # 1.é‡Šæ”¾buffer_id
            # 2.å°†shared_modelçš„dataå’Œgradç½®ä¸ºç©º

            # 1.é‡Šæ”¾buffer_id
            self.shared_model_nvme.release_buffer(buffer_id)
            # 2.å°†shared_modelçš„dataå’Œgradç½®ä¸ºç©º
            self.shared_model_nvme.delete_vts_shared_model_param_grad_buf(vt)

            # ä»»åŠ¡çš„idxåŠ å…¥åˆ°get_queueé˜Ÿåˆ—ä¸­
            self.get_queue.add(vt.idx)
            if self.nvprof: nvtx_range_pop() 

    # åœ¨é»˜è®¤æµä¸Šé˜»å¡ï¼Œç›´åˆ°å…¶ä¸­æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚å®é™…æƒ…å†µæ˜¯è¯¥çº¿ç¨‹åœ¨swapout dW Båå·¥ä½œï¼Œå…¶å®å°±æ˜¯åœ¨ç­‰é»˜è®¤æµä¸Šçš„swap outå®Œæˆ
    def _wait_swapout(self):
        """ Wait swap out (dW,B') to complete (and reside in pinned memory) """
        self.swapout_stream.synchronize() # Wait for all the kernels in this stream to complete. # (maybe use cuda event in future)

    # å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†pinned memoryä¸­çš„bufferæ•°æ®å¤åˆ¶åˆ°shared_modelå…±äº«å†…å­˜çš„vlayerçš„ buffer ä¸­ï¼Œ
    # å³shared_modelè‡ªèº«ä¸Šï¼ˆshared_model.named_buffers())
    @torch.no_grad()
    def _update_buf(self, vt):
        """ update B of this pack """  
        # è°ƒç”¨vtä¸­çš„æ‰€æœ‰çš„layerçš„
        for l in vt.layers:
            # å°†pinned memory (shared_model.pinned_buf) ä¸­ä¿å­˜çš„buffer tensorå¤åˆ¶åˆ°ä½äºå…±äº«å†…å­˜çš„
            # æ¨¡å‹(å°±æ˜¯ä¸€å±‚)çš„ buffer ä¸­ï¼Œå³shared_model.named_buffers() 
            self.shared_optimizer[l].update_buf()
    
    # æ›´æ–°vtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
    @torch.no_grad()
    def _step(self, vt):
        """ update W,K of this pack """  
        for l in vt.layers:
            assert vt.In['dW'][l].medium == "LOC"
            assert vt.In['W'][l].medium == "SHM"  
            assert vt.In['K'][l].medium == "SHM"
            assert vt.Out['W'][l].medium == "SHM"
            assert vt.Out['K'][l].medium == "SHM" 
            # ä½¿ç”¨å…±äº«ä¼˜åŒ–å™¨æ›´æ–°å‚æ•°
            self.shared_optimizer[l].step() # Update shared model and optim using swap-out'ed local .grad
            # å¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œåˆ™è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
            if self.lr_scheduler != []: # "gpt2_huggingface"
                if self.lr_scheduler[l] is not None:
                    assert self.shared_optimizer[l].shared_optimizer is not None
                    self.lr_scheduler[l].step() 
                else:
                    assert self.shared_optimizer[l].shared_optimizer is None
        # print("[UpdateInBkgd] rank{} updated task{}({})".format(self.rank, vt.idx, vt.show_layers()))

    # å°†ç»™å®šçš„vtæ”¾å…¥åˆ°put_queueé˜Ÿåˆ—ä¸­ï¼ŒåŒæ—¶å°†self.the_last_put è®¾ç½®ä¸º vt.idxã€‚
    # ğŸ“Œè¿™æ„å‘³ç€UpdateInBkgdå®ä¾‹çš„çº¿ç¨‹ä¼šå¼€å§‹æ‰§è¡Œvtä¸Šçš„layerçš„bufferä»å›ºå®šå†…å­˜åˆ°å…±äº«å†…å­˜çš„å¤åˆ¶ï¼Œä»¥åŠåœ¨shared_memoryä¸Šè¿›è¡Œå‚æ•°çš„æ›´æ–°
    def iput(self, vt):
        ''' Call by main thread. Nonblocking.'''
        assert isinstance(vt, vTask)
        self.put_queue.add(vt)
        self.the_last_put = vt.idx

    def get(self):
        ''' Call by main thread. Blocking. Return vt.idx. '''
        return self.get_queue.remove()
    
    # 
    def synchronize(self): 
        ''' Call by main thread. Blocking. Wait for all tasks in put_queue to complete. '''
        # depends on Assumption #0; wait for the last put idx 
        if self.the_last_put is None:
            return
        # print("[UpdateInBkgd] rank{} synchronize until task{}".format(self.rank,self.the_last_put))
        while True:
            vt_idx = self.get_queue.remove()
            if vt_idx == self.the_last_put:
                break
        # print("[UpdateInBkgd] rank{} has got task{}".format(self.rank,self.the_last_put))

    # è¯¥ç±»æ–°æ·»åŠ çš„å‡½æ•°ï¼Œä¸“é—¨ç”¨æ¥åœ¨æ›´æ–°åå¸è½½å‚æ•°åˆ°NVMe
    def _swap_out_from_pinned_buffer(self, buffer_id, vt):
        for layer_id in vt.layers:
            # if vt.has_data and layer_id == vt.layers[0]:
            #     continue
            # if layer_id == self.layer_num-2:
            #     continue
            # if layer_id == self.layer_num-3:
            #     continue
            # # æœ€åä¸€å±‚åŒç†
            # if vt.has_criterion and layer_id == vt.layers[-1]:
            #     continue
            # å¦‚æœè¯¥layeråœ¨cpu_layer_idä¸­ï¼Œåˆ™è·³è¿‡
            if layer_id in self.cpu_layer_id:
                continue

            # print(f"rank:{self.rank}, å‡†å¤‡è¦å¸è½½çš„vtçš„idxä¸º:{vt.idx}, ç±»å‹ä¸º{vt.type}")
            layer_idx = self.layer_id_to_layer_idx[vt.idx][layer_id]
            # print(f"rank:{self.rank}, layer{layer_id}å–åˆ°çš„layer_idxä¸º{layer_idx}")
            self.shared_model_nvme.swap_out_from_pinned_buffer(buffer_id, layer_id, layer_idx)
            print(f"rank:{self.rank}, {layer_id}ä»pinned bufferå¸è½½å®Œæˆ", flush=True)


def delete_param_grad_buf_for_shared_model(top_module, manual_gc=False):
    @torch.no_grad()
    def fn(m): # m = each module
        for key, param in m._parameters.items(): # OrderedDict([('weight', Parameter), ('bias', Parameter)])
            if param is not None:
                # delete param
                # åˆ é™¤å‚æ•°ï¼šåˆ›å»ºäº†ä¸€ä¸ªå½¢çŠ¶ä¸ºç©ºçš„å¼ é‡ï¼Œå¹¶å°†å…¶æ”¾ç½®åœ¨ CPU ä¸Šã€‚è¿™ä¸ªå¼ é‡æ²¡æœ‰ä»»ä½•å…ƒç´ ï¼Œå› ä¸ºå®ƒçš„å½¢çŠ¶æ˜¯ (0,)
                param.data = torch.empty(0, device="cpu")
                # delete grad
                # åˆ™å°†æ¢¯åº¦ç½®ä¸º Noneï¼Œç›¸å½“äºåˆ é™¤æ¢¯åº¦
                if param.grad is not None:
                    param.grad = None
                # å°†å‚æ•°ä»è®¡ç®—å›¾ä¸­åˆ†ç¦»ï¼Œä½¿å…¶æˆä¸ºå¶å­èŠ‚ç‚¹ï¼Œä»¥é˜²æ­¢æ¢¯åº¦ä¼ æ’­
                # ğŸ“è¿™å—ä¸ç”¨detach_()ï¼Œä½¿paramçš„required_gradä¸€ç›´ä¸ºtrue
                # param.detach_() # in-place detaches self Tensor from the graph that created it, making it a leaf.
                # assert not param.requires_grad
        # å¯¹äºæ¯ä¸ªæ¨¡å—çš„ç¼“å†²åŒºï¼Œé€šè¿‡ for key, buf in m._buffers.items() éå†æ¨¡å—çš„ç¼“å†²åŒºå­—å…¸ã€‚å¦‚æœç¼“å†²åŒºä¸ä¸º Noneï¼Œ
        # åˆ™å°†å…¶æ›¿æ¢ä¸ºä¸€ä¸ªç©ºçš„é›¶å¼ é‡ï¼Œç›¸å½“äºåˆ é™¤ç¼“å†²åŒºæ•°æ®
        for key, buf in m._buffers.items(): # OrderedDict([('running_mean', tensor), ('running_var', tensor), ('num_batches_tracked', tensor)])
            if buf is not None:
                m._buffers[key] = torch.empty(0, device="cpu")
    # applyï¼šç”¨äºé€’å½’åœ°åº”ç”¨ä¸€ä¸ªå‡½æ•°åˆ°æ¨¡å—çš„æ¯ä¸ªå­æ¨¡å—ä¸Š
    top_module.apply(fn) # Applies ``fn`` recursively to every submodule (as returned by ``.children()`` as well as self.
    #
    if manual_gc:
        gc.collect(); torch.cuda.empty_cache() # can block all cudaStreams

# ä¸åˆ é™¤grad
def delete_param_buf_for_shared_model(top_module, manual_gc=False):
    @torch.no_grad()
    def fn(m): # m = each module
        for key, param in m._parameters.items(): # OrderedDict([('weight', Parameter), ('bias', Parameter)])
            if param is not None:
                # delete param
                # åˆ é™¤å‚æ•°ï¼šåˆ›å»ºäº†ä¸€ä¸ªå½¢çŠ¶ä¸ºç©ºçš„å¼ é‡ï¼Œå¹¶å°†å…¶æ”¾ç½®åœ¨ CPU ä¸Šã€‚è¿™ä¸ªå¼ é‡æ²¡æœ‰ä»»ä½•å…ƒç´ ï¼Œå› ä¸ºå®ƒçš„å½¢çŠ¶æ˜¯ (0,)
                param.data = torch.empty(0, device="cpu")
                # delete grad
                # åˆ™å°†æ¢¯åº¦ç½®ä¸º Noneï¼Œç›¸å½“äºåˆ é™¤æ¢¯åº¦
                # if param.grad is not None:
                #     param.grad = None
                # å°†å‚æ•°ä»è®¡ç®—å›¾ä¸­åˆ†ç¦»ï¼Œä½¿å…¶æˆä¸ºå¶å­èŠ‚ç‚¹ï¼Œä»¥é˜²æ­¢æ¢¯åº¦ä¼ æ’­
                # ğŸ“è¿™å—ä¸ç”¨detach_()ï¼Œä½¿paramçš„required_gradä¸€ç›´ä¸ºtrue
                # param.detach_() # in-place detaches self Tensor from the graph that created it, making it a leaf.
                # assert not param.requires_grad
        # å¯¹äºæ¯ä¸ªæ¨¡å—çš„ç¼“å†²åŒºï¼Œé€šè¿‡ for key, buf in m._buffers.items() éå†æ¨¡å—çš„ç¼“å†²åŒºå­—å…¸ã€‚å¦‚æœç¼“å†²åŒºä¸ä¸º Noneï¼Œ
        # åˆ™å°†å…¶æ›¿æ¢ä¸ºä¸€ä¸ªç©ºçš„é›¶å¼ é‡ï¼Œç›¸å½“äºåˆ é™¤ç¼“å†²åŒºæ•°æ®
        for key, buf in m._buffers.items(): # OrderedDict([('running_mean', tensor), ('running_var', tensor), ('num_batches_tracked', tensor)])
            if buf is not None:
                m._buffers[key] = torch.empty(0, device="cpu")
    # applyï¼šç”¨äºé€’å½’åœ°åº”ç”¨ä¸€ä¸ªå‡½æ•°åˆ°æ¨¡å—çš„æ¯ä¸ªå­æ¨¡å—ä¸Š
    top_module.apply(fn) # Applies ``fn`` recursively to every submodule (as returned by ``.children()`` as well as self.
    #
    if manual_gc:
        gc.collect(); torch.cuda.empty_cache() # can block all cudaStreams

from deepspeed.runtime.swap_tensor.partitioned_param_swapper_2 import AsyncPartitionedParameterSwapper

# ä¸“é—¨æä¾›å¯¹VLayerç±»(å°±æ˜¯æ¨¡å‹çš„ä¸€å±‚)çš„NVMeçš„äº¤äº’ï¼Œå³å¯¹é‡Œé¢çš„å‚æ•°è°ƒç”¨param_swapperçš„æ–¹æ³•
# ä»¥transformerçš„å­å±‚ä¸ºç²’åº¦è¿›è¡Œé€šä¿¡
class SharedModelNVMe(object):
    # empty modelå°±æ˜¯å‚æ•°ã€æ¢¯åº¦ã€ç¼“å†²åŒºå…¨ä¸ºç©ºçš„layeråˆ—è¡¨ï¼Œæ–¹ä¾¿æˆ‘ä»¬è¿›è¡Œpinned modelçš„åˆ›å»ºï¼ˆå› ä¸ºä¸ç”¨å¤åˆ¶æ•°æ®ï¼‰
    def __init__(self, shared_model, empty_model, param_swapper, layer_count, transformer_layer_idx_to_shape, cpu_layer_id, rank):
        self.shared_model = shared_model
        self.param_swapper: AsyncPartitionedParameterSwapper = param_swapper
        self.layer_count = layer_count
        self.transformer_layer_idx_to_shape = transformer_layer_idx_to_shape
        self.rank = rank
        
        # ğŸ“Œä¸€ä¸ªpinned bufferå°±æ˜¯ä¸€ä¸ªtransformerå±‚
        self.pinned_buffer = []
        self.empty_model = empty_model

        # æ³¨å†Œä¸€ä¸ªæˆå‘˜, ç”¨äºæ ‡è®°æ— éœ€å¸è½½åˆ°nvmeçš„å±‚
        self.cpu_layer_id = cpu_layer_id

        # åˆ›å»ºpinned buffer
        for layer_idx in range(self.layer_count):
            self.initial_pinned_buffer(layer_idx)

    # 
    def initial_pinned_buffer(self, layer_idx):
        pinned_buffer = copy.deepcopy(self.empty_model[1]) # ç¬¬0å±‚æ˜¯embedding
        global_param_idx = 0
        for m in pinned_buffer.modules():
            for param_idx,(key, param) in enumerate(m._parameters.items()):
                compute_buffer, swap_buffer = self.param_swapper._allocate_and_return_buffers_for_swap_in_2(layer_idx, global_param_idx)
                param.data = compute_buffer.data
                global_param_idx+=1

            for key, buf in m._buffers.items():
                compute_buffer, swap_buffer = self.param_swapper._allocate_and_return_buffers_for_swap_in_2(layer_idx, global_param_idx)
                buf.data = compute_buffer.data
                global_param_idx += 1

        self.pinned_buffer.append(pinned_buffer)

    def get_pinned_buffer(self, layer_idx):
        return self.pinned_buffer[layer_idx]

    # æŒ‰ç…§å­å±‚çš„ç²’åº¦å¸è½½layer
    def swap_out_from_pinned_buffer(self, layer_id, layer_idx):
        pinned_buffer = self.get_pinned_buffer(layer_idx)
        global_param_idx = 0

        for pinned_m in pinned_buffer.modules():
            for key, param in pinned_m._parameters.items():
                if param is not None:
                    # pinned_m._parameters[key].data.copy_(param.data, non_blocking=False)
                    self.param_swapper.swap_out_2(param, layer_id, global_param_idx)
                    global_param_idx += 1

            for key, buf in pinned_m._buffers.items(): # OrderedDict([('running_mean', tensor), ('running_var', tensor), ('num_batches_tracked', tensor)])
                if buf is not None:
                    self.param_swapper.swap_out_2(buf, layer_id, global_param_idx)
                    global_param_idx += 1

    def swap_out_from_pinned_buffer_sync(self, layer_id, layer_idx):
        pinned_buffer = self.get_pinned_buffer(layer_idx)
        global_param_idx = 0
        for pinned_m in pinned_buffer.modules():
            for key, param in pinned_m._parameters.items():
                if param is not None:
                    self.param_swapper.swap_out_2_sync(param, layer_id, global_param_idx)
                    global_param_idx += 1

            for key, buf in pinned_m._buffers.items(): # OrderedDict([('running_mean', tensor), ('running_var', tensor), ('num_batches_tracked', tensor)])
                if buf is not None:
                    self.param_swapper.swap_out_2_sync(buf, layer_id, global_param_idx)
                    global_param_idx += 1

    # çœŸæ­£çš„åŒæ­¥ï¼Œåº•å±‚C++åº“ä¸ä¼šæ”¾åˆ°çº¿ç¨‹ä¸­ï¼Œè€Œæ˜¯ç›´æ¥æ‰§è¡Œ
    def swap_out_from_pinned_buffer_sync_2(self, layer_id, layer_idx):
        pinned_buffer = self.get_pinned_buffer(layer_idx)
        global_param_idx = 0
        for pinned_m in pinned_buffer.modules():
            for key, param in pinned_m._parameters.items():
                if param is not None:
                    self.param_swapper.swap_out_2_sync_2(param, layer_id, global_param_idx)
                    global_param_idx += 1

            for key, buf in pinned_m._buffers.items(): # OrderedDict([('running_mean', tensor), ('running_var', tensor), ('num_batches_tracked', tensor)])
                if buf is not None:
                    self.param_swapper.swap_out_2_sync_2(buf, layer_id, global_param_idx)
                    global_param_idx += 1

    # æ— éœ€å…ˆæ”¾åˆ°pinned bufferä¸Šï¼Œç›´æ¥ä»shared memoryä¸­å¸è½½åˆ°nvme
    def swap_out_from_shared_memory_and_release(self, layer_id):
        global_param_idx = 0
        print(f"rank:{self.rank}, æ­£åœ¨å¸è½½layer{layer_id}",flush=True)
        for cpu_m in self.shared_model[layer_id][0].modules(): # iterator over all modules in the network
            # print("{} <- {}".format(gpu_m, cpu_m))
            for key, param in cpu_m._parameters.items(): # OrderedDict([('weight', Parameter), ('bias', Parameter)])
                if param is not None:
                    # one_dim_param = param.view(-1)
                    # ğŸ“å†…éƒ¨ä¼šç­‰å¾…å¼‚æ­¥å¸è½½çš„å®Œæˆï¼Œå› æ­¤è¯¥å‡½æ•°æ‰§è¡Œå®Œå¸è½½å°±ä¸€å®šå®Œæˆäº†
                    # print(f"rank:{self.rank}, åˆå§‹åŒ–å¸è½½æ—¶ï¼Œlayer{layer_id}param:{param}, å½¢çŠ¶ä¸º:{param.shape}")
                    self.param_swapper.swap_out_2_sync_2(param, layer_id, global_param_idx)
                    global_param_idx += 1

            for key, buf in cpu_m._buffers.items(): # OrderedDict([('running_mean', tensor), ('running_var', tensor), ('num_batches_tracked', tensor)])
                if buf is not None:
                    # one_dim_param = buf.view(-1)
                    # print(f"rank:{self.rank}, åˆå§‹åŒ–å¸è½½æ—¶ï¼Œlayer{layer_id}buffer:{buf}, å½¢çŠ¶ä¸º:{param.shape}")
                    self.param_swapper.swap_out_2_sync_2(buf, layer_id, global_param_idx)
                    global_param_idx += 1

        # å¸è½½å®Œæˆåï¼Œåˆ é™¤cpuä¸Šshared modelçš„å‚æ•°ã€æ¢¯åº¦ã€ç¼“å†²åŒº
        self._delete_param_grad_buf(self.shared_model[layer_id][0])

    def _delete_param_grad_buf(self, model, manual_gc=False):
        delete_param_grad_buf_for_shared_model(model, manual_gc=manual_gc)
        
    # ä»nvmeå‘pinned bufferå¤åˆ¶
    def swap_in(self, layer_id, layer_idx):
        # 
        pinned_buffer = self.get_pinned_buffer(layer_idx)
        global_param_idx = 0
        # for pinned_m, cpu_m in zip(pinned_model.modules(), self.shared_model[layer_idx].modules()):
        #     for key, param in cpu_m._parameters.items(): # OrderedDict([('weight', Parameter), ('bias', Parameter)])
        #         if param is not None:
        #             # pinned_m._parameters[key].data.copy_(param.data, non_blocking=False)
        #             self.param_swapper.swap_in_2(layer_id, layer_idx, global_param_idx)
        #             global_param_idx += 1

        #     for key, buf in cpu_m._buffers.items(): # OrderedDict([('running_mean', tensor), ('running_var', tensor), ('num_batches_tracked', tensor)])
        #         if buf is not None:
        #             self.param_swapper.swap_in_2(layer_id, layer_idx, global_param_idx)

        for pinned_m in pinned_buffer.modules():
            # print(f"rank:{self.rank},xxxxxx: {pinned_m}")
            for key, param in pinned_m._parameters.items():
                
                if param is not None:
                    print(f"rank:{self.rank}, æ­£åœ¨è¯»å–{layer_id}-{global_param_idx}", flush=True)
                    # pinned_m._parameters[key].data.copy_(param.data, non_blocking=False)
                    self.param_swapper.swap_in_2(layer_id, layer_idx, global_param_idx, async_op=False)
                    # print(f"rank:{self.rank}, åˆšåˆšæ¥æ”¶çš„layer{layer_id}:{param}, å½¢çŠ¶ä¸º:{param.shape}")
                    global_param_idx += 1

            for key, buf in pinned_m._buffers.items(): # OrderedDict([('running_mean', tensor), ('running_var', tensor), ('num_batches_tracked', tensor)])
                if buf is not None:
                    print(f"rank:{self.rank}, æ­£åœ¨è¯»å–{layer_id}-{global_param_idx}", flush=True)
                    self.param_swapper.swap_in_2(layer_id, layer_idx, global_param_idx, async_op=False)
                    global_param_idx += 1

    def swap_in_sync(self, layer_id, layer_idx):
        pinned_buffer = self.get_pinned_buffer(layer_idx)
        global_param_idx = 0

        for pinned_m in pinned_buffer.modules():
            # print(f"rank:{self.rank},xxxxxx: {pinned_m}")
            for key, param in pinned_m._parameters.items():
                
                if param is not None:
                    print(f"rank:{self.rank}, æ­£åœ¨è¯»å–{layer_id}-{global_param_idx}", flush=True)
                    # pinned_m._parameters[key].data.copy_(param.data, non_blocking=False)
                    self.param_swapper.swap_in_2_sync(layer_id, layer_idx, global_param_idx)
                    # print(f"rank:{self.rank}, åˆšåˆšæ¥æ”¶çš„layer{layer_id}:{param}, å½¢çŠ¶ä¸º:{param.shape}")
                    global_param_idx += 1

            for key, buf in pinned_m._buffers.items(): # OrderedDict([('running_mean', tensor), ('running_var', tensor), ('num_batches_tracked', tensor)])
                if buf is not None:
                    print(f"rank:{self.rank}, æ­£åœ¨è¯»å–{layer_id}-{global_param_idx}", flush=True)
                    self.param_swapper.swap_in_2_sync(layer_id, layer_idx, global_param_idx)
                    global_param_idx += 1

    # çœŸæ­£çš„åŒæ­¥ï¼Œåº•å±‚C++åº“ä¸ä¼šæ”¾åˆ°çº¿ç¨‹ä¸­ï¼Œè€Œæ˜¯ç›´æ¥æ‰§è¡Œ
    def swap_in_sync_2(self, layer_id, layer_idx):
        pinned_buffer = self.get_pinned_buffer(layer_idx)
        global_param_idx = 0
        for pinned_m in pinned_buffer.modules():
            for key, param in pinned_m._parameters.items():
                if param is not None:
                    self.param_swapper.swap_in_2_sync_2(layer_id, layer_idx, global_param_idx)
                    global_param_idx += 1

            for key, buf in pinned_m._buffers.items(): # OrderedDict([('running_mean', tensor), ('running_var', tensor), ('num_batches_tracked', tensor)])
                if buf is not None:
                    self.param_swapper.swap_in_2_sync_2(layer_id, layer_idx, global_param_idx)
                    global_param_idx += 1

    def delete_vts_shared_model_param_grad_buf(self, vt):
        for layer_id in vt.layers:
            if layer_id in self.cpu_layer_id:
                continue
            self._delete_param_grad_buf(self.shared_model[layer_id][0])

    # å°†shared modelçš„å‚æ•°çš„dataæŒ‡å‘pinned modelï¼ˆpinned bufferï¼‰çš„data
    def make_shared_model_point_to_pinned(self, layer_id, layer_idx):
        print(f"rank:{self.rank}, æ­£åœ¨è¿›è¡Œ layer{layer_id} çš„shared model dataæŒ‡å‘pinned buffer")
        pinned_buffer = self.get_pinned_buffer(layer_idx)

        global_param_idx = 0
        for cpu_m, pinned_m in zip(self.shared_model[layer_id][0].modules(), pinned_buffer.modules()):
            for key, param in pinned_m._parameters.items(): # OrderedDict([('weight', Parameter), ('bias', Parameter)])
                if param is not None:
                    cpu_m._parameters[key].data = param.view(self.transformer_layer_idx_to_shape[global_param_idx]).data
                    global_param_idx+=1
            for key, buf in pinned_m._buffers.items(): # OrderedDict([('running_mean', tensor), ('running_var', tensor), ('num_batches_tracked', tensor)])
                if buf is not None:
                    cpu_m._buffers[key] = buf.view(self.transformer_layer_idx_to_shape[global_param_idx]).data
                    global_param_idx += 1

# ä¸ä¸Šä¸€ä¸ªçš„åŒºåˆ«ï¼šä»¥å±‚ä¸ºç²’åº¦è¿›è¡Œcpu-nvmeé€šä¿¡
class SharedModelNVMe_2(object):
    # empty modelå°±æ˜¯å‚æ•°ã€æ¢¯åº¦ã€ç¼“å†²åŒºå…¨ä¸ºç©ºçš„layeråˆ—è¡¨ï¼Œæ–¹ä¾¿æˆ‘ä»¬è¿›è¡Œpinned modelçš„åˆ›å»ºï¼ˆå› ä¸ºä¸ç”¨å¤åˆ¶æ•°æ®ï¼‰
    def __init__(self, shared_model, empty_model, param_swapper, pinned_buffer_information, layer_count, transformer_layer_idx_to_shape, layer_id_to_layer_idx, layer_num, cpu_layer_id, rank):
        self.shared_model = shared_model
        self.param_swapper: AsyncPartitionedParameterSwapper = param_swapper
        self.pinned_buffer_information: PinnedBufferInformation_2 = pinned_buffer_information
        self.layer_count = layer_count
        self.transformer_layer_idx_to_shape = transformer_layer_idx_to_shape
        self.rank = rank
        
        # ğŸ“Œä¸€ä¸ªpinned bufferå°±æ˜¯ä¸€ä¸ªtransformerå±‚
        self.pinned_buffer = []
        self.empty_model = empty_model


        # åˆ›å»ºpinned buffer
        for layer_idx in range(self.layer_count):
            self.initial_pinned_buffer(layer_idx)

        self.layer_id_to_layer_idx = layer_id_to_layer_idx
        self.layer_num = layer_num
        self.cpu_layer_id = cpu_layer_id

    # ä¸ä¸Šä¸€ä¸ªçš„åŒºåˆ«ï¼Œä¸è¿”å›æ¯ä¸ªparamçš„è¡¥é½éƒ¨åˆ†ï¼Œå› ä¸ºæ ¹æœ¬ä¸éœ€è¦ï¼Œå› ä¸ºä¸æ˜¯ä»¥paramç²’åº¦å¸è½½çš„
    def initial_pinned_buffer(self, layer_idx):
        pinned_buffer = copy.deepcopy(self.empty_model[1]) # ç¬¬0å±‚æ˜¯embedding
        global_param_idx = 0
        for m in pinned_buffer.modules():
            for param_idx,(key, param) in enumerate(m._parameters.items()):
                compute_buffer = self.param_swapper._allocate_and_return_buffers_for_param(layer_idx, global_param_idx)
                param.data = compute_buffer.data
                global_param_idx+=1

            for key, buf in m._buffers.items():
                compute_buffer = self.param_swapper._allocate_and_return_buffers_for_param(layer_idx, global_param_idx)
                buf.data = compute_buffer.data
                global_param_idx += 1

        self.pinned_buffer.append(pinned_buffer)

    def get_pinned_buffer(self, layer_idx):
        return self.pinned_buffer[layer_idx]

    # ç›´æ¥å¸è½½æ•´ä¸ªlayer
    def swap_out_from_pinned_buffer(self, layer_id, layer_idx):
        # start_time = time.perf_counter()
        self.param_swapper.swap_out_transformer_layer(layer_id, layer_idx)
        # end_time = time.perf_counter()
        # print(f"rank:{self.rank}ï¼Œswap_out_from_pinned_bufferæ‰§è¡Œæ—¶é—´: {(end_time - start_time):.4f} ç§’", flush=True)

    def swap_out_from_pinned_buffer_sync(self, layer_id, layer_idx):
        self.param_swapper.swap_out_transformer_layer_sync(layer_id, layer_idx)

    def _delete_param_grad_buf(self, model, manual_gc=False):
        delete_param_grad_buf_for_shared_model(model, manual_gc=manual_gc)

    def copy_shared_model_to_pinned_buffer(self, layer_id, layer_idx):
        pinned_buffer = self.get_pinned_buffer(layer_idx)
        global_param_idx = 0
        for cpu_m, pin_m in zip(self.shared_model[layer_id][0].modules(), pinned_buffer.modules()): # iterator over all modules in the network
            # print("{} <- {}".format(gpu_m, cpu_m))
            for key, param in cpu_m._parameters.items(): # OrderedDict([('weight', Parameter), ('bias', Parameter)])
                if param is not None:
                    # one_dim_param = param.view(-1)
                    # ğŸ“å†…éƒ¨ä¼šç­‰å¾…å¼‚æ­¥å¸è½½çš„å®Œæˆï¼Œå› æ­¤è¯¥å‡½æ•°æ‰§è¡Œå®Œå¸è½½å°±ä¸€å®šå®Œæˆäº†
                    # print(f"rank:{self.rank}, åˆå§‹åŒ–å¸è½½æ—¶ï¼Œlayer{layer_id}param:{param}, å½¢çŠ¶ä¸º:{param.shape}")
                    pin_m._parameters[key].data.copy_(param.data.view(-1), non_blocking=MEMCPY_NONBLK)

            for key, buf in cpu_m._buffers.items(): # OrderedDict([('running_mean', tensor), ('running_var', tensor), ('num_batches_tracked', tensor)])
                if buf is not None:
                    pin_m._buffers[key].data.copy_(buf.data.view(-1), non_blocking=MEMCPY_NONBLK)

    def swap_out_from_shared_memory_through_pinned_buffer(self, bwd_vts):
        for vt in bwd_vts:
            for layer_id in vt.layers:
                if layer_id in self.cpu_layer_id:
                    continue
                layer_idx = self.layer_id_to_layer_idx[vt.idx][layer_id]
                self.copy_shared_model_to_pinned_buffer(layer_id, layer_idx)
                self.swap_out_from_pinned_buffer(layer_id, layer_idx)
                # print(f"rank:{self.rank}, å¸è½½layer{layer_id}ä¹‹å‰")
                # for param in self.shared_model[layer_id][0].parameters():
                #     print(f"\t\trank:{self.rank} is shared?{param.is_shared()}")
                self._delete_param_grad_buf(self.shared_model[layer_id][0])
                # print(f"rank:{self.rank}, å¸è½½layer{layer_id}å®Œæˆ")
                # for param in self.shared_model[layer_id][0].parameters():
                #     print(f"\t\trank:{self.rank} is shared?{param.is_shared()}")


    # åºŸå¼ƒï¼Œè¿˜éœ€è¦æ ¹æ®bwd vtæ¥é€‰æ‹©éœ€è¦è¯»å–çš„layerï¼Œå¤ªéº»çƒ¦
    def swap_in_from_nvme_to_shared_memory_through_pinned_buffer(self, bwd_vts_need_reload):
        for bwd_vt in bwd_vts_need_reload:
            for layer_id in bwd_vt.layers:
                if layer_id not in self.cpu_layer_id and layer_id in self.new_cpu_layer_id:
                    continue
                layer_idx = self.layer_id_to_layer_idx[bwd_vt.idx][layer_id]
                self.swap_in_sync(layer_id, layer_idx)
                self.alloc_shared_model_param_buf_and_reload_from_pinned_buffer(layer_id, layer_idx)

    # ç›´æ¥æ ¹æ®ä¼ å…¥
    def swap_in_from_nvme_to_shared_memory_through_pinned_buffer_without_bwdvt(self, new_cpu_layer_id):
        for i in range(0, len(new_cpu_layer_id), self.layer_count):
            # è·å–å½“å‰æ‰¹æ¬¡çš„layer ids
            # batch_layer_ids = new_cpu_layer_id[i:i+self.layer_count]
            batch_layer_ids = new_cpu_layer_id[i:min(i + self.layer_count, len(new_cpu_layer_id))]
            print(f"rank:{self.rank}, ä»NVMeè¯»å–ç¬¬{i//self.layer_count + 1}æ‰¹layers: {batch_layer_ids}")
            
            # å¯¹å½“å‰æ‰¹æ¬¡çš„æ¯ä¸ªlayerè¿›è¡Œå¤„ç†
            layer_idx = 0
            for layer_id in batch_layer_ids:
                # ä½¿ç”¨0ä½œä¸ºlayer_idxï¼Œå› ä¸ºæˆ‘ä»¬ç›´æ¥è¯»å–æ•´ä¸ªlayer
                # ä»NVMeè¯»å–æ•°æ®åˆ°pinned buffer
                self.swap_in_sync(layer_id, layer_idx)
                # åˆ†é…shared modelçš„ç©ºé—´å¹¶ä»pinned bufferåŠ è½½æ•°æ®
                self.alloc_shared_model_param_buf_and_reload_from_pinned_buffer(layer_id, layer_idx)
                layer_idx += 1

    # ä¸€æ¬¡æ€§ç›´æ¥è¯»ä¸€å±‚transformeræ¨¡å‹
    def swap_in(self, layer_id, layer_idx): # reload_from_nvme_to_pinned_buffer
        self.param_swapper.swap_in_transformer_layer(layer_id, layer_idx)

    def swap_in_sync(self, layer_id, layer_idx):
        self.param_swapper.swap_in_transformer_layer_sync(layer_id, layer_idx)

    # å°†shared modelçš„å‚æ•°çš„dataæŒ‡å‘pinned modelï¼ˆpinned bufferï¼‰çš„data
    def make_shared_model_point_to_pinned(self, layer_id, layer_idx):
        # print(f"rank:{self.rank}, æ­£åœ¨è¿›è¡Œ layer{layer_id} çš„shared model dataæŒ‡å‘pinned buffer")
        pinned_buffer = self.get_pinned_buffer(layer_idx)

        global_param_idx = 0
        for cpu_m, pinned_m in zip(self.shared_model[layer_id][0].modules(), pinned_buffer.modules()):
            for key, param in pinned_m._parameters.items(): # OrderedDict([('weight', Parameter), ('bias', Parameter)])
                if param is not None:
                    cpu_m._parameters[key].data = param.view(self.transformer_layer_idx_to_shape[global_param_idx]).data
                    global_param_idx+=1
            for key, buf in pinned_m._buffers.items(): # OrderedDict([('running_mean', tensor), ('running_var', tensor), ('num_batches_tracked', tensor)])
                if buf is not None:
                    cpu_m._buffers[key].data = buf.view(self.transformer_layer_idx_to_shape[global_param_idx]).data
                    global_param_idx += 1

    def delete_vts_shared_model_param_grad_buf(self, vt):
        for layer_id in vt.layers:
            if layer_id in self.cpu_layer_id:
                continue
            self._delete_param_grad_buf(self.shared_model[layer_id][0])


    def delete_other_shared_model(self, other_layers):
        for layer_id in other_layers:
            if layer_id in self.cpu_layer_id:
                    continue
            self._delete_param_grad_buf(self.shared_model[layer_id][0])

    def delete_vts_shared_model_param_grad_buf_for_new_cpu_layer(self, vt, new_cpu_layer_id):
        for layer_id in vt.layers:
            if layer_id in self.cpu_layer_id or layer_id in new_cpu_layer_id:
                continue
            self._delete_param_grad_buf(self.shared_model[layer_id][0])

    # åºŸå¼ƒï¼Œæ ¹æœ¬æ²¡æ³•æ¢å¤ï¼Œlayerçš„shared modelç‰ˆæœ¬åœ¨é¦–æ¬¡å¸è½½åˆ°nvmeæ—¶è¢«åˆ æ‰äº†ï¼Œä¸€åˆ æ‰å°±å¤±å»äº†å…±äº«ç‰¹æ€§
    # å› ä¸ºdataè¢«ç”¨â€œ=â€èµ‹å€¼äº†
    # æ¢å¤æŒ‡å®š layer_id çš„shared memoryç‰ˆæœ¬çš„å‚æ•°å’Œ bufferã€‚
    @torch.no_grad()
    def alloc_shared_model_param_buf_and_reload_from_pinned_buffer(self, layer_id, layer_idx):
        """
        ä» pined buffer ä¸­æ¢å¤ shared_model ä¸­æŒ‡å®š layer_id çš„å‚æ•°å’Œ bufferã€‚
        
        å‚æ•°ï¼š
            layer_id (int): è¦æ¢å¤çš„ transformer å±‚çš„ç¼–å·ã€‚
        """
        # è·å–å¯¹åº”å±‚çš„ pinned buffer ä¿¡æ¯
        pinned_buffer_info = self.pinned_buffer_information
        
        # è·å– pinned buffer çš„æ•°æ®
        pinned_buffer = self.get_pinned_buffer(layer_idx)
        
        shared_layer = self.shared_model[layer_id][0]  # è·å– shared_model ä¸­çš„å¯¹åº”å±‚

        print(f"rank:{self.rank}, æ­£åœ¨æ¢å¤{layer_id}")
        if layer_id == 5:
            for param in shared_layer.parameters():
                print(f"\t\trank:{self.rank} is shared?{param.is_shared()}")
        global_param_idx = 0
        for shared_m, pinned_m in zip(shared_layer.modules(), pinned_buffer.modules()):
            # å¤åˆ¶å‚æ•°
            for key, param in pinned_m._parameters.items():
                if param is not None:
                    # åˆ›å»ºå…±äº«å†…å­˜å¼ é‡å¹¶å¤åˆ¶æ•°æ®
                    shared_param_data = torch.empty(
                        self.transformer_layer_idx_to_shape[global_param_idx],
                        device='cpu'
                    ).share_memory_()
                    shared_param_data.copy_(param.view(self.transformer_layer_idx_to_shape[global_param_idx]).data, non_blocking=MEMCPY_NONBLK)
                    
                    # å°†å…±äº«å†…å­˜å¼ é‡èµ‹å€¼ç»™ shared_layer çš„å‚æ•°
                    shared_m._parameters[key].data = shared_param_data
                    if layer_id == 5:
                        print(f"\trank:{self.rank}, layer{layer_id}, shared_param.shape:{shared_m._parameters[key].shape}")
                    global_param_idx += 1

            # å¤åˆ¶ç¼“å†²åŒº
            for key, buf in pinned_m._buffers.items():
                if buf is not None:
                    # åˆ›å»ºå…±äº«å†…å­˜å¼ é‡å¹¶å¤åˆ¶æ•°æ®
                    shared_buf_data = torch.empty(
                        self.transformer_layer_idx_to_shape[global_param_idx],
                        device='cpu'
                    ).share_memory_()
                    shared_buf_data.copy_(buf.view(self.transformer_layer_idx_to_shape[global_param_idx]).data, non_blocking=MEMCPY_NONBLK)
                    
                    # å°†å…±äº«å†…å­˜å¼ é‡èµ‹å€¼ç»™ shared_layer çš„ç¼“å†²åŒº
                    shared_m._buffers[key].data = shared_buf_data
                    global_param_idx += 1

        # for m in shared_layer.modules():
        #     for key, param in m._parameters.items():
        #         if param is not None:
        #             # è·å–å‚æ•°å¯¹åº”çš„å½¢çŠ¶
        #             param_shape = transformer_layer_shape[global_param_idx]
        #             param_numel = pinned_buffer_info.param_idx_in_layer_to_numel[global_param_idx]
        #             param_start_pos = pinned_buffer_info.param_idx_to_start_pos[global_param_idx]
                    
        #             # é‡æ–°åˆ†é…å‚æ•°å¼ é‡
        #             new_param_data = torch.empty(param_shape, device='cpu').share_memory_()
                    
        #             # ä» pinned buffer ä¸­å¤åˆ¶æ•°æ®
        #             pinned_data = pinned_buffer.data[param_start_pos:param_start_pos + param_numel]
        #             new_param_data.copy_(pinned_data.view(param_shape))
                    
        #             # èµ‹å€¼ç»™ shared_model çš„å‚æ•°
        #             shared_layer._parameters[key].data = new_param_data
                    
        #             global_param_idx += 1

        #     for key, buf in m._buffers.items():
        #         if buf is not None:
        #             # è·å–ç¼“å†²åŒºå¯¹åº”çš„å½¢çŠ¶
        #             buf_shape = transformer_layer_shape[global_param_idx]
        #             buf_numel = pinned_buffer_info.param_idx_in_layer_to_numel[global_param_idx]
        #             buf_start_pos = pinned_buffer_info.param_idx_to_start_pos[global_param_idx]
                    
        #             # é‡æ–°åˆ†é…ç¼“å†²åŒºå¼ é‡
        #             new_buf_data = torch.empty(buf_shape, device='cpu').share_memory_()
                    
        #             # ä» pinned buffer ä¸­å¤åˆ¶æ•°æ®
        #             pinned_buf_data = pinned_buffer.data[buf_start_pos:buf_start_pos + buf_numel]
        #             new_buf_data.copy_(pinned_buf_data.view(buf_shape))
                    
        #             # èµ‹å€¼ç»™ shared_model çš„ç¼“å†²åŒº
        #             shared_layer._buffers[key].data = new_buf_data
                    
        #             global_param_idx += 1

        print(f"rank{self.rank}: æˆåŠŸä» pinned buffer ä¸­æ¢å¤ layer {layer_id} çš„å‚æ•°å’Œç¼“å†²åŒºã€‚")
        if layer_id == 5:
            for param in shared_layer.parameters():
                print(f"\t\trank:{self.rank} is shared?{param.is_shared()}")

# ç‰ˆæœ¬3ï¼šåŒbufferç‰ˆæœ¬
# ä¸ä¸Šä¸€ä¸ªçš„åŒºåˆ«ï¼Œæ„å»ºå¤šä¸ªbuffer, ä¸€ä¸ªbufferå¸è½½æ—¶ï¼Œå¦ä¸€ä¸ªbufferå¯ä»¥è¯»å–
class SharedModelNVMe_double_buffer(object):
    def __init__(self, shared_model, empty_model, param_swapper, layer_count, transformer_layer_idx_to_shape, layer_id_to_layer_idx, layer_num, cpu_layer_id, rank, num_buffers=2):
        self.shared_model = shared_model
        self.param_swapper: AsyncPartitionedParameterSwapper = param_swapper
        self.layer_count = layer_count
        self.transformer_layer_idx_to_shape = transformer_layer_idx_to_shape
        self.rank = rank
        self.num_buffers = num_buffers
        
        # åˆ›å»ºå¤šä¸ªpinned buffer
        self.pinned_buffers = []
        self.empty_model = empty_model

        self.buffer_lock = threading.Lock()
        self.available_buffers = queue.Queue()

        # åˆ›å»ºå¤šä¸ªpinned bufferå¹¶åŠ å…¥å¯ç”¨é˜Ÿåˆ—
        for buffer_id in range(num_buffers):
            buffer_list = []
            for layer_idx in range(self.layer_count):
                buffer_list.append(self.initial_pinned_buffer(buffer_id, layer_idx))
            self.pinned_buffers.append(buffer_list)
            self.available_buffers.put(buffer_id)

        self.layer_id_to_layer_idx = layer_id_to_layer_idx
        self.layer_num = layer_num
        self.cpu_layer_id = cpu_layer_id

        # è®°å½•æ¯ä¸ªbufferçš„ä½¿ç”¨çŠ¶æ€
        self.buffer_status = {i: {'in_use': False, 'layers': set()} for i in range(num_buffers)}

    def initial_pinned_buffer(self, buffer_id, layer_idx):
        pinned_buffer = copy.deepcopy(self.empty_model[1]) # ç¬¬0å±‚æ˜¯embedding
        global_param_idx = 0
        for m in pinned_buffer.modules():
            for param_idx,(key, param) in enumerate(m._parameters.items()):
                compute_buffer = self.param_swapper._allocate_and_return_buffers_for_param_double_buffer(buffer_id, layer_idx, global_param_idx)
                param.data = compute_buffer.data
                global_param_idx+=1

            for key, buf in m._buffers.items():
                compute_buffer = self.param_swapper._allocate_and_return_buffers_for_param_double_buffer(buffer_id, layer_idx, global_param_idx)
                buf.data = compute_buffer.data
                global_param_idx += 1

        return pinned_buffer

    def get_available_buffer(self, vt):
        """è·å–ä¸€ä¸ªå¯ç”¨çš„buffer id"""
        try:
            buffer_id = self.available_buffers.get_nowait()
            with self.buffer_lock:
                self.buffer_status[buffer_id]['in_use'] = True
                self.buffer_status[buffer_id]['layers'] = vt.layers
            return buffer_id
        except queue.Empty:
            return None

    # åœ¨ä¹‹å‰å·²ç»è·å¾—bufferçš„æƒ…å†µä¸‹ï¼Œè·å–buffer_id
    def get_buffer_id(self, vt):
        with self.buffer_lock:
            for buffer_id, status in self.buffer_status.items():
                if status['in_use'] and status['layers'] == vt.layers:
                    return buffer_id
        return None

    def release_buffer(self, buffer_id):
        """é‡Šæ”¾ä¸€ä¸ªbuffer"""
        with self.buffer_lock:
            self.buffer_status[buffer_id]['in_use'] = False
            self.buffer_status[buffer_id]['layers'] = []
        self.available_buffers.put(buffer_id)

    def get_pinned_buffer(self, buffer_id, layer_idx):
        """è·å–æŒ‡å®šbufferä¸­çš„æŒ‡å®šå±‚"""
        return self.pinned_buffers[buffer_id][layer_idx]

    def swap_out_from_pinned_buffer(self, buffer_idx, layer_id, layer_idx):
        """ä»æŒ‡å®šçš„bufferä¸­å¸è½½æ•°æ®åˆ°NVMe"""
        self.param_swapper.swap_out_transformer_layer_double_buffer_sync(buffer_idx, layer_id, layer_idx)
        # æ›´æ–°bufferçŠ¶æ€
        # with self.buffer_lock:
        #     self.buffer_status[buffer_idx]['layers'].add(layer_id)

    def _delete_param_grad_buf(self, model, manual_gc=False):
        delete_param_grad_buf_for_shared_model(model, manual_gc=manual_gc)

    def copy_shared_model_to_pinned_buffer(self, buffer_id, layer_id, layer_idx):
        pinned_buffer = self.get_pinned_buffer(buffer_id, layer_idx)
        global_param_idx = 0
        for cpu_m, pin_m in zip(self.shared_model[layer_id][0].modules(), pinned_buffer.modules()): # iterator over all modules in the network
            # print("{} <- {}".format(gpu_m, cpu_m))
            for key, param in cpu_m._parameters.items(): # OrderedDict([('weight', Parameter), ('bias', Parameter)])
                if param is not None:
                    # one_dim_param = param.view(-1)
                    # ğŸ“å†…éƒ¨ä¼šç­‰å¾…å¼‚æ­¥å¸è½½çš„å®Œæˆï¼Œå› æ­¤è¯¥å‡½æ•°æ‰§è¡Œå®Œå¸è½½å°±ä¸€å®šå®Œæˆäº†
                    # print(f"rank:{self.rank}, åˆå§‹åŒ–å¸è½½æ—¶ï¼Œlayer{layer_id}param:{param}, å½¢çŠ¶ä¸º:{param.shape}")
                    pin_m._parameters[key].data.copy_(param.data.view(-1), non_blocking=MEMCPY_NONBLK)

            for key, buf in cpu_m._buffers.items(): # OrderedDict([('running_mean', tensor), ('running_var', tensor), ('num_batches_tracked', tensor)])
                if buf is not None:
                    pin_m._buffers[key].data.copy_(buf.data.view(-1), non_blocking=MEMCPY_NONBLK)

    def swap_out_from_shared_memory_through_pinned_buffer(self, bwd_vts):
        for vt in bwd_vts:
            buffer_idx = self.get_available_buffer(vt)
            assert buffer_idx is not None, f"rank:{self.rank}, æ²¡æœ‰å¯ç”¨çš„buffer..."

            for layer_id in vt.layers:
                if layer_id in self.cpu_layer_id:
                    continue
                layer_idx = self.layer_id_to_layer_idx[vt.idx][layer_id]
                self.copy_shared_model_to_pinned_buffer(buffer_idx, layer_id, layer_idx)
                self.swap_out_from_pinned_buffer(buffer_idx, layer_id, layer_idx)
                self._delete_param_grad_buf(self.shared_model[layer_id][0])

            self.release_buffer(buffer_idx)
        return True

    def swap_in(self, buffer_id, layer_id, layer_idx):
        """ä»NVMeé€šè¿‡pinned bufferåŠ è½½åˆ°GPU"""
        self.param_swapper.swap_in_transformer_layer_double_buffer_sync(buffer_id, layer_id, layer_idx)


    def make_shared_model_point_to_pinned(self, buffer_id, layer_id, layer_idx):
        """è®©shared modelæŒ‡å‘æŒ‡å®šbufferä¸­çš„æ•°æ®"""
        pinned_buffer = self.get_pinned_buffer(buffer_id, layer_idx)
        # ... åŸæœ‰çš„æŒ‡é’ˆé‡å®šå‘é€»è¾‘ ...
        global_param_idx = 0
        for cpu_m, pinned_m in zip(self.shared_model[layer_id][0].modules(), pinned_buffer.modules()):
            for key, param in pinned_m._parameters.items(): # OrderedDict([('weight', Parameter), ('bias', Parameter)])
                if param is not None:
                    cpu_m._parameters[key].data = param.view(self.transformer_layer_idx_to_shape[global_param_idx]).data
                    global_param_idx+=1
            for key, buf in pinned_m._buffers.items(): # OrderedDict([('running_mean', tensor), ('running_var', tensor), ('num_batches_tracked', tensor)])
                if buf is not None:
                    cpu_m._buffers[key].data = buf.view(self.transformer_layer_idx_to_shape[global_param_idx]).data
                    global_param_idx += 1

    def delete_vts_shared_model_param_grad_buf(self, vt):
        for layer_id in vt.layers:
            if layer_id in self.cpu_layer_id:
                continue
            self._delete_param_grad_buf(self.shared_model[layer_id][0])


class SwapToNVMeInBkgd(object):
    def __init__(self, shared_model_nvme, layer_id_to_layer_idx, bwd_vts, layer_num, rank, nvprof=False):
        self.rank = rank
        self.shared_model_nvme: SharedModelNVMe = shared_model_nvme
        # self.param_swapper: AsyncPartitionedParameterSwapper = param_swapper
        self.the_last_put = None
        self.layer_num = layer_num
        self.nvprof = nvprof

        self.layer_id_to_layer_idx = layer_id_to_layer_idx

        print(f"rank:{self.rank}, å‡†å¤‡è¿›è¡Œåˆå§‹åŒ–å¸è½½",flush=True)
        self.swap_to_nvme_at_start(bwd_vts)
        gc.collect()

        self.put_queue = threadsafe_data_struct.Queue() # [vtask1, vtask2, ...] # between main and sync thread
        self.get_queue = threadsafe_data_struct.Queue()
        self.sync_thread = threading.Thread(target=self._thread_func)
        self.sync_thread.daemon = True
        self.sync_thread.start()

    # å°†ç»™å®švtï¼ˆé™¤äº†é¦–å±‚å’Œæœ€åä¸€å±‚ï¼‰å¸è½½åˆ°nvmeä¸Š
    def swap_to_nvme_at_start(self, vts):
        for vt in vts:
            self._swap_out_from_shared(vt)


    def _thread_func(self):
        """ This method is to be executed from a daemon thread. """
        while True: # for each incoming task 
            # æ‹¿åˆ°put_queueä¸­çš„ç¬¬ä¸€ä¸ªvtask
            # è‹¥é˜Ÿåˆ—ä¸­æ²¡æœ‰ä»»åŠ¡ï¼Œä¼šä¸€ç›´ç­‰å¾…ï¼Œç›´åˆ°å‡ºç°ä»»åŠ¡æ­¤å¤„æ‰ä¼šç»§ç»­è¿›è¡Œ
            vt = self.put_queue.remove() # blocking
            if self.nvprof: nvtx_range_push("__task{}({}) CPU->NVMe(Wã€B)".format(vt.idx, vt.show_layers())) 
            self._swap_out_from_pinned_buffer(vt)
            print(f"rank:{self.rank}, vt.[{vt.layers}]ä»pinned bufferå¸è½½å®Œæˆ", flush=True)
            self.get_queue.add(vt.idx)
            if self.nvprof: nvtx_range_pop() 

    def _swap_out_from_pinned_buffer(self, vt):
        for layer_id in vt.layers:
            if vt.has_data and layer_id == vt.layers[0]:
                continue
            if layer_id == self.layer_num-2:
                continue
            if layer_id == self.layer_num-3:
                continue
            # æœ€åä¸€å±‚åŒç†
            if vt.has_criterion and layer_id == vt.layers[-1]:
                continue

            # print(f"rank:{self.rank}, å‡†å¤‡è¦å¸è½½çš„vtçš„idxä¸º:{vt.idx}, ç±»å‹ä¸º{vt.type}")
            layer_idx = self.layer_id_to_layer_idx[vt.idx][layer_id]
            # print(f"rank:{self.rank}, layer{layer_id}å–åˆ°çš„layer_idxä¸º{layer_idx}")
            self.shared_model_nvme.swap_out_from_pinned_buffer_sync_2(layer_id, layer_idx)
            print(f"rank:{self.rank}, {layer_id}ä»pinned bufferå¸è½½å®Œæˆ", flush=True)

    def _swap_out_from_shared(self, vt):
        """ update W,K of this pack """  
        for layer_id in vt.layers:
            if vt.has_data and layer_id == vt.layers[0]:
                continue
            if layer_id == self.layer_num-2:
                continue
            if layer_id == self.layer_num-3:
                continue
            # æœ€åä¸€å±‚åŒç†
            if vt.has_criterion and layer_id == vt.layers[-1]:
                continue

            self.shared_model_nvme.swap_out_from_shared_memory_and_release(layer_id) # Update shared model and optim using swap-out'ed local .grad

    def iput(self, vt):
        ''' Call by upstream thread. Nonblocking.'''
        assert isinstance(vt, vTask)
        self.put_queue.add(vt)

    def get(self):
        ''' Call by prefetech thread. Blocking. Return vt.idx. '''
        return self.get_queue.remove()


class SwapInCpuInBkgd(object):
    def __init__(self, syncpin_handler, shared_model_nvme, layer_id_to_layer_idx, layer_num, rank, nvprof=False):
        self.rank = rank
        self.nvprof = nvprof
        self.shared_model_nvme: SharedModelNVMe = shared_model_nvme
        self.syncpin_handler = syncpin_handler
        self.layer_num = layer_num

        # self.param_swapper: AsyncPartitionedParameterSwapper = param_swapper
        self.the_last_put = None

        self.layer_id_to_layer_idx = layer_id_to_layer_idx

        self.put_queue = threadsafe_data_struct.Queue() # [vtask1, vtask2, ...] # between main and sync thread
        self.get_queue = threadsafe_data_struct.Queue()
        self.sync_thread = threading.Thread(target=self._thread_func)
        self.sync_thread.daemon = True
        self.sync_thread.start()
    
    def _thread_func(self):
        """ This method is to be executed from a daemon thread. """
        while True: # for each incoming task 
            # æ‹¿åˆ°put_queueä¸­çš„ç¬¬ä¸€ä¸ªvtask
            # è‹¥é˜Ÿåˆ—ä¸­æ²¡æœ‰ä»»åŠ¡ï¼Œä¼šä¸€ç›´ç­‰å¾…ï¼Œç›´åˆ°å‡ºç°ä»»åŠ¡æ­¤å¤„æ‰ä¼šç»§ç»­è¿›è¡Œ
            vt = self.put_queue.remove() # blocking
            if self.nvprof: nvtx_range_push("__task{}({}) NVMe->CPU(Wã€B)".format(vt.idx, vt.show_layers())) 
            print(f"rank:{self.rank}, å¼€å§‹swap in cpu {vt.layers}")
            self._swap_in(vt)
            self.get_queue.add(vt.idx)
            if self.nvprof: nvtx_range_pop() 

    def _swap_in(self, vt):
        """ update W,K of this pack """  
        for layer_id in vt.layers:
            print(f"rank:{self.rank}, æ­£åœ¨swap in layer{layer_id}")
            # æ•´ä¸ªæ¨¡å‹çš„é¦–å±‚æ°¸è¿œå­˜åœ¨pinned modelï¼Œè€Œä¸æ˜¯pinned bufferï¼Œä¸ä¼šå¸è½½åˆ°nvme
            if vt.has_data and layer_id == vt.layers[0]:
                self.syncpin_handler.input_one_layer(layer_id, vt)
                continue
            if layer_id == self.layer_num-3:
                self.syncpin_handler.input_one_layer(layer_id, vt)
                continue
            if layer_id == self.layer_num-2:
                self.syncpin_handler.input_one_layer(layer_id, vt)
                continue
            if layer_id == self.layer_num-1:
                self.syncpin_handler.input_one_layer(layer_id, vt)
                continue
            # if vt.has_criterion and layer_id == vt.layers[-2]:
            #     self.syncpin_handler.input_one_layer(layer_id, vt)
            
            layer_idx = self.layer_id_to_layer_idx[vt.idx][layer_id]
            self.shared_model_nvme.swap_in_sync_2(layer_id, layer_idx) # Update shared model and optim using swap-out'ed local .grad
            print(f"rank:{self.rank},layer{layer_id} SWAP INå®Œæˆ", flush=True)
            self.shared_model_nvme.make_shared_model_point_to_pinned(layer_id, layer_idx)
            print(f"rank:{self.rank},layer{layer_id}çš„sharedmodelå·²æŒ‡å‘pinned buffer", flush=True)
    # def sync_to_shared_model(self):


    def iput(self, vt):
        ''' Call by upstream thread. Nonblocking.'''
        assert isinstance(vt, vTask)
        self.put_queue.add(vt)

    def get(self):
        ''' Call by prefetech thread. Blocking. Return vt.idx. '''
        return self.get_queue.remove()

# 
class SyncPinModelInBkgd(object):
    """ Handles synchronization to local pinned model in background thread.
        Assumption:
            0) always in FIFO ordering. put each task, and get synced task. 
        TODO: skip sync_pinned_model() if already done (FWD -> BWD)
        NOTE: move vt.medium check back to runtime by reducing granularity to vLayer?
    """
    def __init__(self, shared_optimizer, rank, nvprof=False):
        self.shared_optimizer = shared_optimizer
        self.rank = rank
        self.nvprof = nvprof
        # initialize
        # put_queue ç›¸å½“äºä¸€ä¸ªå¯åŠ¨æ¡ä»¶ï¼Œå³æ¥æ´»äº†ï¼Œå…¶ä¸­çš„å…ƒç´ æ˜¯å…¶ä»–çº¿ç¨‹æˆ–è‡ªå·±æ·»åŠ è¿›å»çš„ï¼Œè¿™ä¸ªé‡Œé¢å¾—æœ‰ä¸œè¥¿ï¼Œ
        # è‡ªèº«è¿™ä¸ªçº¿ç¨‹æ‰èƒ½å–å‡ºä¸œè¥¿ï¼Œå¹¶æ‰§è¡Œåé¢çš„æ­¥éª¤ï¼Œä¸ç„¶ä¼šä¸€ç›´é˜»å¡
        self.put_queue = threadsafe_data_struct.Queue() # [vtask1, vtask2, ...] # between main and sync thread
        # get_queue ä»£è¡¨é€»è¾‘ä¸Šæˆ‘è¿™ä¸ªæ´»å¹²å®Œäº†ï¼Œç”¨äºé€šçŸ¥å…¶ä»–çº¿ç¨‹æˆ‘çš„æ´»å¹²å®Œäº†ï¼Œä¸€èˆ¬æ˜¯ä¸Šçº§çº¿ç¨‹è°ƒç”¨å‡½æ•°æ‹¿å–è¿™é‡Œé¢çš„å€¼
        self.get_queue = threadsafe_data_struct.Queue() # [vtask1.idx, vtask2.idx, ...] # between sync and prefetch thread
        self.sync_thread = threading.Thread(target=self._thread_func)
        self.sync_thread.daemon = True
        self.sync_thread.start()
        # print("[SyncPinModelInBkgd] rank{} started sync_thread".format(self.rank))

    # ä¸æ–­å°è¯•ä»put_queueä¸­æ‹¿å–ä»»åŠ¡ï¼ˆvtï¼‰ï¼Œå¯¹æ‹¿åˆ°çš„vtæ‰§è¡Œï¼š
    # 1.è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
    #   --è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
    # 2.å°†åŒæ­¥å®Œæˆçš„vtçš„idxåŠ å…¥get_queueé˜Ÿåˆ—
    def _thread_func(self):
        """ This method is to be executed from a daemon thread. """
        while True: # for each incoming task 
            vt = self.put_queue.remove() # blocking
            if self.nvprof: nvtx_range_push("__task{}({}) SyncPin(W,B)".format(vt.idx, vt.show_layers())) 
            # ä¸¤ç§æƒ…å†µï¼š
            # 1.è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
            # 2.è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
            self._sync_pinned_model(vt)
            # å°†åŒæ­¥å®Œæˆçš„vtçš„idxåŠ å…¥get_queueé˜Ÿåˆ—
            self.get_queue.add(vt.idx)
            if self.nvprof: nvtx_range_pop() 

    # ä¸¤ç§æƒ…å†µï¼š
    # 1.è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
    # 2.è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
    @torch.no_grad()
    def _sync_pinned_model(self, vt):
        """ sync W,B to local pinned model for this pack """  
        for l in vt.layers:
            # è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
            if vt.In['W'][l].medium=='SHM' and vt.In['B'][l].medium=='SHM':
                self.shared_optimizer[l].sync_pinned_model()
            # è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
            elif vt.In['W'][l].medium=='PIN' and vt.In['B'][l].medium=='PIN':
                pass
            else: # P2P
                raise ValueError("Underdevelopment")
    
    # self.put_queue.add(vt)
    def iput(self, vt):
        ''' Call by main thread. Nonblocking.'''
        assert isinstance(vt, vTask)
        self.put_queue.add(vt)

    # è¿”å›get_queueçš„é¦–ä¸ªå…ƒç´ ï¼ˆä»»åŠ¡çš„idxï¼‰ï¼Œå¹¶æŠŠå…¶ä»é˜Ÿåˆ—ä¸­åˆ é™¤ã€‚å³è¿”å›å·²ç»å®Œæˆä»å…±äº«æ¨¡å‹åˆ°å›ºå®šå†…å­˜æ¨¡å‹å¤åˆ¶W,Bçš„ä»»åŠ¡ï¼ˆå³åŒæ­¥ï¼‰
    def get(self):
        ''' Call by prefetech thread. Blocking. Return vt.idx. '''
        return self.get_queue.remove()

# ================ my version =========================
class SyncPinModelInBkgd_2(object):
    """ Handles synchronization to local pinned model in background thread.
        Assumption:
            0) always in FIFO ordering. put each task, and get synced task. 
        TODO: skip sync_pinned_model() if already done (FWD -> BWD)
        NOTE: move vt.medium check back to runtime by reducing granularity to vLayer?
    """
    def __init__(self, shared_optimizer, rank, nvprof=False):
        self.shared_optimizer = shared_optimizer
        self.rank = rank
        self.nvprof = nvprof
        # initialize
        # put_queue ç›¸å½“äºä¸€ä¸ªå¯åŠ¨æ¡ä»¶ï¼Œå³æ¥æ´»äº†ï¼Œå…¶ä¸­çš„å…ƒç´ æ˜¯å…¶ä»–çº¿ç¨‹æˆ–è‡ªå·±æ·»åŠ è¿›å»çš„ï¼Œè¿™ä¸ªé‡Œé¢å¾—æœ‰ä¸œè¥¿ï¼Œ
        # è‡ªèº«è¿™ä¸ªçº¿ç¨‹æ‰èƒ½å–å‡ºä¸œè¥¿ï¼Œå¹¶æ‰§è¡Œåé¢çš„æ­¥éª¤ï¼Œä¸ç„¶ä¼šä¸€ç›´é˜»å¡
        self.put_queue = threadsafe_data_struct.Queue() # [vtask1, vtask2, ...] # between main and sync thread
        # get_queue ä»£è¡¨é€»è¾‘ä¸Šæˆ‘è¿™ä¸ªæ´»å¹²å®Œäº†ï¼Œç”¨äºé€šçŸ¥å…¶ä»–çº¿ç¨‹æˆ‘çš„æ´»å¹²å®Œäº†ï¼Œä¸€èˆ¬æ˜¯ä¸Šçº§çº¿ç¨‹è°ƒç”¨å‡½æ•°æ‹¿å–è¿™é‡Œé¢çš„å€¼
        self.get_queue = threadsafe_data_struct.Queue() # [vtask1.idx, vtask2.idx, ...] # between sync and prefetch thread
        self.sync_thread = threading.Thread(target=self._thread_func)
        self.sync_thread.daemon = True
        self.sync_thread.start()
        # print("[SyncPinModelInBkgd] rank{} started sync_thread".format(self.rank))

    # ä¸æ–­å°è¯•ä»put_queueä¸­æ‹¿å–ä»»åŠ¡ï¼ˆvtï¼‰ï¼Œå¯¹æ‹¿åˆ°çš„vtæ‰§è¡Œï¼š
    # 1.è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
    #   --è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
    # 2.å°†åŒæ­¥å®Œæˆçš„vtçš„idxåŠ å…¥get_queueé˜Ÿåˆ—
    def _thread_func(self):
        """ This method is to be executed from a daemon thread. """
        while True: # for each incoming task 
            layer_id, vt = self.put_queue.remove() # blocking
            if self.nvprof: nvtx_range_push("__task{}({}) SyncPin(W,B)".format(vt.idx, vt.show_layers())) 
            # ä¸¤ç§æƒ…å†µï¼š
            # 1.è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
            # 2.è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
            self._sync_pinned_model(layer_id)
            # å°†åŒæ­¥å®Œæˆçš„vtçš„idxåŠ å…¥get_queueé˜Ÿåˆ—
            self.get_queue.add(layer_id)
            if self.nvprof: nvtx_range_pop() 

    # ä¸¤ç§æƒ…å†µï¼š
    # 1.è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
    # 2.è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
    @torch.no_grad()
    def _sync_pinned_model(self, layer_id):
        """ sync W,B to local pinned model for this layer """  
        # è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
        # if vt.In['W'][l].medium=='SHM' and vt.In['B'][l].medium=='SHM':
        #     self.shared_optimizer[l].sync_pinned_model()
        # # è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
        # elif vt.In['W'][l].medium=='PIN' and vt.In['B'][l].medium=='PIN':
        #     pass
        # else: # P2P
        #     raise ValueError("Underdevelopment")
        self.shared_optimizer[layer_id].sync_pinned_model()
    
    # self.put_queue.add(vt)
    def iput(self, vt):
        ''' Call by main thread. Nonblocking.'''
        assert isinstance(vt, vTask)
        self.put_queue.add(vt)

    def input_one_layer(self, layer_id, vt):
        self.put_queue.add((layer_id, vt))

    # è¿”å›get_queueçš„é¦–ä¸ªå…ƒç´ ï¼ˆä»»åŠ¡çš„idxï¼‰ï¼Œå¹¶æŠŠå…¶ä»é˜Ÿåˆ—ä¸­åˆ é™¤ã€‚å³è¿”å›å·²ç»å®Œæˆä»å…±äº«æ¨¡å‹åˆ°å›ºå®šå†…å­˜æ¨¡å‹å¤åˆ¶W,Bçš„ä»»åŠ¡ï¼ˆå³åŒæ­¥ï¼‰
    def get(self):
        ''' Call by prefetech thread. Blocking. Return vt.idx. '''
        return self.get_queue.remove()
    

# ================ my version =========================

# ä»¥paramä¸ºç²’åº¦ä¸nvmeé€šä¿¡
# ä¸ºè§£å†³åµŒå¥—é—®é¢˜å†™çš„ï¼Œå¯åŒæ—¶å¤„ç†nvme->pinnedå’Œshared memory->pinned
class SyncPinModelInBkgd_for_worker5_param_sync_version(object):
    """ Handles synchronization to local pinned model in background thread.
        Assumption:
            0) always in FIFO ordering. put each task, and get synced task. 
        TODO: skip sync_pinned_model() if already done (FWD -> BWD)
        NOTE: move vt.medium check back to runtime by reducing granularity to vLayer?
    """
    def __init__(self, shared_optimizer, shared_model_nvme, layer_num, layer_id_to_layer_idx, cpu_layer_id, rank, nvprof=False):
        self.shared_optimizer = shared_optimizer
        self.rank = rank
        self.nvprof = nvprof
        # initialize
        # put_queue ç›¸å½“äºä¸€ä¸ªå¯åŠ¨æ¡ä»¶ï¼Œå³æ¥æ´»äº†ï¼Œå…¶ä¸­çš„å…ƒç´ æ˜¯å…¶ä»–çº¿ç¨‹æˆ–è‡ªå·±æ·»åŠ è¿›å»çš„ï¼Œè¿™ä¸ªé‡Œé¢å¾—æœ‰ä¸œè¥¿ï¼Œ
        # è‡ªèº«è¿™ä¸ªçº¿ç¨‹æ‰èƒ½å–å‡ºä¸œè¥¿ï¼Œå¹¶æ‰§è¡Œåé¢çš„æ­¥éª¤ï¼Œä¸ç„¶ä¼šä¸€ç›´é˜»å¡
        self.put_queue = threadsafe_data_struct.Queue() # [vtask1, vtask2, ...] # between main and sync thread
        # get_queue ä»£è¡¨é€»è¾‘ä¸Šæˆ‘è¿™ä¸ªæ´»å¹²å®Œäº†ï¼Œç”¨äºé€šçŸ¥å…¶ä»–çº¿ç¨‹æˆ‘çš„æ´»å¹²å®Œäº†ï¼Œä¸€èˆ¬æ˜¯ä¸Šçº§çº¿ç¨‹è°ƒç”¨å‡½æ•°æ‹¿å–è¿™é‡Œé¢çš„å€¼
        self.get_queue = threadsafe_data_struct.Queue() # [vtask1.idx, vtask2.idx, ...] # between sync and prefetch thread
        self.sync_thread = threading.Thread(target=self._thread_func)
        self.sync_thread.daemon = True
        self.sync_thread.start()
        # print("[SyncPinModelInBkgd] rank{} started sync_thread".format(self.rank))

        # ğŸ“
        self.shared_model_nvme: SharedModelNVMe = shared_model_nvme
        self.layer_num = layer_num
        self.layer_id_to_layer_idx = layer_id_to_layer_idx
        self.cpu_layer_id = cpu_layer_id

    # ä¸æ–­å°è¯•ä»put_queueä¸­æ‹¿å–ä»»åŠ¡ï¼ˆvtï¼‰ï¼Œå¯¹æ‹¿åˆ°çš„vtæ‰§è¡Œï¼š
    # 1.è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
    #   --è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
    # 2.å°†åŒæ­¥å®Œæˆçš„vtçš„idxåŠ å…¥get_queueé˜Ÿåˆ—
    def _thread_func(self):
        """ This method is to be executed from a daemon thread. """
        while True: # for each incoming task 
            vt = self.put_queue.remove() # blocking
            if self.nvprof: nvtx_range_push("__task{}({}) SyncPin(W,B)".format(vt.idx, vt.show_layers())) 
            # ä¸¤ç§æƒ…å†µï¼š
            # 1.è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
            # 2.è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
            self._sync_pinned_model(vt)
            # å°†åŒæ­¥å®Œæˆçš„vtçš„idxåŠ å…¥get_queueé˜Ÿåˆ—
            self.get_queue.add(vt.idx)
            if self.nvprof: nvtx_range_pop() 

    # ä¸¤ç§æƒ…å†µï¼š
    # 1.è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
    # 2.è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
    @torch.no_grad()
    def _sync_pinned_model(self, vt):
        """ sync W,B to local pinned model for this pack """  
        for l in vt.layers:
            # è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
            if vt.In['W'][l].medium=='SHM' and vt.In['B'][l].medium=='SHM':
                if l in self.cpu_layer_id:
                    self.shared_optimizer[l].sync_pinned_model()
                else:
                    layer_idx = self.layer_id_to_layer_idx[vt.idx][l]
                    self.shared_model_nvme.swap_in_sync_2(l, layer_idx)
                    print(f"rank:{self.rank},layer{l} SWAP INå®Œæˆ", flush=True)
                    # è‹¥vtæ˜¯BWDä»»åŠ¡ï¼Œè¿˜éœ€å°†å…±äº«æ¨¡å‹æŒ‡å‘å›ºå®šå†…å­˜æ¨¡å‹ï¼Œå› ä¸ºè¦åœ¨cpuä¸Šè¿›è¡Œå‚æ•°æ›´æ–°
                    if vt.type == 'BWD':
                        self.shared_model_nvme.make_shared_model_point_to_pinned(l, layer_idx)
                        print(f"rank:{self.rank},layer{l}çš„sharedmodelå·²æŒ‡å‘pinned buffer", flush=True)
            # è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
            elif vt.In['W'][l].medium=='PIN' and vt.In['B'][l].medium=='PIN':
                if vt.type == 'BWD':
                    layer_idx = self.layer_id_to_layer_idx[vt.idx][l]
                    self.shared_model_nvme.make_shared_model_point_to_pinned(l, layer_idx)
            else: # P2P
                raise ValueError("Underdevelopment")
    
    # self.put_queue.add(vt)
    def iput(self, vt):
        ''' Call by main thread. Nonblocking.'''
        assert isinstance(vt, vTask)
        self.put_queue.add(vt)

    # è¿”å›get_queueçš„é¦–ä¸ªå…ƒç´ ï¼ˆä»»åŠ¡çš„idxï¼‰ï¼Œå¹¶æŠŠå…¶ä»é˜Ÿåˆ—ä¸­åˆ é™¤ã€‚å³è¿”å›å·²ç»å®Œæˆä»å…±äº«æ¨¡å‹åˆ°å›ºå®šå†…å­˜æ¨¡å‹å¤åˆ¶W,Bçš„ä»»åŠ¡ï¼ˆå³åŒæ­¥ï¼‰
    def get(self):
        ''' Call by prefetech thread. Blocking. Return vt.idx. '''
        return self.get_queue.remove()


# ä¸ºè§£å†³çº¿ç¨‹åµŒå¥—é—®é¢˜å†™çš„ï¼Œsyncçº¿ç¨‹åŸæœ¬çš„ä»shared_model->pinned_modelçš„åŒæ­¥ï¼Œç°åœ¨ä¸nvme->pinned_modelçš„åŒæ­¥
# ä¸²è¡Œæ‰§è¡Œ
class SyncPinModelInBkgd_for_worker5(object):
    """ Handles synchronization to local pinned model in background thread.
        Assumption:
            0) always in FIFO ordering. put each task, and get synced task. 
        TODO: skip sync_pinned_model() if already done (FWD -> BWD)
        NOTE: move vt.medium check back to runtime by reducing granularity to vLayer?
    """
    def __init__(self, shared_optimizer, shared_model_nvme, layer_num, layer_id_to_layer_idx, cpu_layer_id, rank, nvprof=False):
        self.shared_optimizer = shared_optimizer
        self.rank = rank
        self.nvprof = nvprof
        # initialize
        # put_queue ç›¸å½“äºä¸€ä¸ªå¯åŠ¨æ¡ä»¶ï¼Œå³æ¥æ´»äº†ï¼Œå…¶ä¸­çš„å…ƒç´ æ˜¯å…¶ä»–çº¿ç¨‹æˆ–è‡ªå·±æ·»åŠ è¿›å»çš„ï¼Œè¿™ä¸ªé‡Œé¢å¾—æœ‰ä¸œè¥¿ï¼Œ
        # è‡ªèº«è¿™ä¸ªçº¿ç¨‹æ‰èƒ½å–å‡ºä¸œè¥¿ï¼Œå¹¶æ‰§è¡Œåé¢çš„æ­¥éª¤ï¼Œä¸ç„¶ä¼šä¸€ç›´é˜»å¡
        self.put_queue = threadsafe_data_struct.Queue() # [vtask1, vtask2, ...] # between main and sync thread
        # get_queue ä»£è¡¨é€»è¾‘ä¸Šæˆ‘è¿™ä¸ªæ´»å¹²å®Œäº†ï¼Œç”¨äºé€šçŸ¥å…¶ä»–çº¿ç¨‹æˆ‘çš„æ´»å¹²å®Œäº†ï¼Œä¸€èˆ¬æ˜¯ä¸Šçº§çº¿ç¨‹è°ƒç”¨å‡½æ•°æ‹¿å–è¿™é‡Œé¢çš„å€¼
        self.get_queue = threadsafe_data_struct.Queue() # [vtask1.idx, vtask2.idx, ...] # between sync and prefetch thread
        self.sync_thread = threading.Thread(target=self._thread_func)
        self.sync_thread.daemon = True
        self.sync_thread.start()
        # print("[SyncPinModelInBkgd] rank{} started sync_thread".format(self.rank))

        # ğŸ“
        self.shared_model_nvme: SharedModelNVMe_2 = shared_model_nvme
        self.layer_num = layer_num
        self.layer_id_to_layer_idx = layer_id_to_layer_idx
        self.cpu_layer_id = cpu_layer_id

    # ä¸æ–­å°è¯•ä»put_queueä¸­æ‹¿å–ä»»åŠ¡ï¼ˆvtï¼‰ï¼Œå¯¹æ‹¿åˆ°çš„vtæ‰§è¡Œï¼š
    # 1.è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
    #   --è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
    # 2.å°†åŒæ­¥å®Œæˆçš„vtçš„idxåŠ å…¥get_queueé˜Ÿåˆ—
    def _thread_func(self):
        """ This method is to be executed from a daemon thread. """
        while True: # for each incoming task 
            vt = self.put_queue.remove() # blocking
            if self.nvprof: nvtx_range_push("__task{}({}) SyncPin(W,B)".format(vt.idx, vt.show_layers())) 
            # ä¸¤ç§æƒ…å†µï¼š
            # 1.è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
            # 2.è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
            self._sync_pinned_model(vt)
            # å°†åŒæ­¥å®Œæˆçš„vtçš„idxåŠ å…¥get_queueé˜Ÿåˆ—
            self.get_queue.add(vt.idx)
            if self.nvprof: nvtx_range_pop() 

    # ä¸¤ç§æƒ…å†µï¼š
    # 1.è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
    # 2.è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
    @torch.no_grad()
    def _sync_pinned_model(self, vt):
        """ sync W,B to local pinned model for this pack """  
        for l in vt.layers:
            # è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
            if vt.In['W'][l].medium=='SHM' and vt.In['B'][l].medium=='SHM':
                if l in self.cpu_layer_id:
                    self.shared_optimizer[l].sync_pinned_model()
                else:
                    layer_idx = self.layer_id_to_layer_idx[vt.idx][l]
                    self.shared_model_nvme.swap_in_sync(l, layer_idx)
                    print(f"rank:{self.rank},layer{l} SWAP INå®Œæˆ", flush=True)
                    # è‹¥vtæ˜¯BWDä»»åŠ¡ï¼Œè¿˜éœ€å°†å…±äº«æ¨¡å‹æŒ‡å‘å›ºå®šå†…å­˜æ¨¡å‹ï¼Œå› ä¸ºè¦åœ¨cpuä¸Šè¿›è¡Œå‚æ•°æ›´æ–°
                    if vt.type == 'BWD':
                        self.shared_model_nvme.make_shared_model_point_to_pinned(l, layer_idx)
                        print(f"rank:{self.rank},layer{l}çš„sharedmodelå·²æŒ‡å‘pinned buffer", flush=True)
            # è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
            elif vt.In['W'][l].medium=='PIN' and vt.In['B'][l].medium=='PIN':
                if l in self.cpu_layer_id:
                    pass
                else:
                    if vt.type == 'BWD':
                        layer_idx = self.layer_id_to_layer_idx[vt.idx][l]
                        self.shared_model_nvme.make_shared_model_point_to_pinned(l, layer_idx)
            else: # P2P
                raise ValueError("Underdevelopment")
    
    # self.put_queue.add(vt)
    def iput(self, vt):
        ''' Call by main thread. Nonblocking.'''
        assert isinstance(vt, vTask)
        self.put_queue.add(vt)

    # è¿”å›get_queueçš„é¦–ä¸ªå…ƒç´ ï¼ˆä»»åŠ¡çš„idxï¼‰ï¼Œå¹¶æŠŠå…¶ä»é˜Ÿåˆ—ä¸­åˆ é™¤ã€‚å³è¿”å›å·²ç»å®Œæˆä»å…±äº«æ¨¡å‹åˆ°å›ºå®šå†…å­˜æ¨¡å‹å¤åˆ¶W,Bçš„ä»»åŠ¡ï¼ˆå³åŒæ­¥ï¼‰
    def get(self):
        ''' Call by prefetech thread. Blocking. Return vt.idx. '''
        return self.get_queue.remove()
    
# 25/1/9æ·»åŠ 
# layerç²’åº¦ + new cpu layerå¤„ç†
# ä¸ä¸Šä¸€ä¸ªçš„åŒºåˆ«ï¼šä¸»è¦æ˜¯å¯¹new cpu layerè¿›è¡Œåˆ°pinned bufferçš„å¤åˆ¶ï¼Œè¿™æ ·æ— éœ€å¯¹è¿™äº›layerå»ºç«‹pinned modelç‰ˆæœ¬
class SyncPinModelInBkgd_for_worker5_2(object):
    """ Handles synchronization to local pinned model in background thread.
        Assumption:
            0) always in FIFO ordering. put each task, and get synced task. 
        TODO: skip sync_pinned_model() if already done (FWD -> BWD)
        NOTE: move vt.medium check back to runtime by reducing granularity to vLayer?
    """
    def __init__(self, shared_optimizer, shared_model_nvme, layer_num, layer_id_to_layer_idx, cpu_layer_id, new_cpu_layer_id, rank, nvprof=False):
        self.shared_optimizer = shared_optimizer
        self.rank = rank
        self.nvprof = nvprof
        # initialize
        # put_queue ç›¸å½“äºä¸€ä¸ªå¯åŠ¨æ¡ä»¶ï¼Œå³æ¥æ´»äº†ï¼Œå…¶ä¸­çš„å…ƒç´ æ˜¯å…¶ä»–çº¿ç¨‹æˆ–è‡ªå·±æ·»åŠ è¿›å»çš„ï¼Œè¿™ä¸ªé‡Œé¢å¾—æœ‰ä¸œè¥¿ï¼Œ
        # è‡ªèº«è¿™ä¸ªçº¿ç¨‹æ‰èƒ½å–å‡ºä¸œè¥¿ï¼Œå¹¶æ‰§è¡Œåé¢çš„æ­¥éª¤ï¼Œä¸ç„¶ä¼šä¸€ç›´é˜»å¡
        self.put_queue = threadsafe_data_struct.Queue() # [vtask1, vtask2, ...] # between main and sync thread
        # get_queue ä»£è¡¨é€»è¾‘ä¸Šæˆ‘è¿™ä¸ªæ´»å¹²å®Œäº†ï¼Œç”¨äºé€šçŸ¥å…¶ä»–çº¿ç¨‹æˆ‘çš„æ´»å¹²å®Œäº†ï¼Œä¸€èˆ¬æ˜¯ä¸Šçº§çº¿ç¨‹è°ƒç”¨å‡½æ•°æ‹¿å–è¿™é‡Œé¢çš„å€¼
        self.get_queue = threadsafe_data_struct.Queue() # [vtask1.idx, vtask2.idx, ...] # between sync and prefetch thread
        self.sync_thread = threading.Thread(target=self._thread_func)
        self.sync_thread.daemon = True
        self.sync_thread.start()
        # print("[SyncPinModelInBkgd] rank{} started sync_thread".format(self.rank))

        # ğŸ“
        self.shared_model_nvme: SharedModelNVMe_2 = shared_model_nvme
        self.layer_num = layer_num
        self.layer_id_to_layer_idx = layer_id_to_layer_idx
        self.cpu_layer_id = cpu_layer_id
        self.new_cpu_layer_id = new_cpu_layer_id

    # ä¸æ–­å°è¯•ä»put_queueä¸­æ‹¿å–ä»»åŠ¡ï¼ˆvtï¼‰ï¼Œå¯¹æ‹¿åˆ°çš„vtæ‰§è¡Œï¼š
    # 1.è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
    #   --è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
    # 2.å°†åŒæ­¥å®Œæˆçš„vtçš„idxåŠ å…¥get_queueé˜Ÿåˆ—
    def _thread_func(self):
        """ This method is to be executed from a daemon thread. """
        while True: # for each incoming task 
            vt = self.put_queue.remove() # blocking
            if self.nvprof: nvtx_range_push("__task{}({}) SyncPin(W,B)".format(vt.idx, vt.show_layers())) 
            # ä¸¤ç§æƒ…å†µï¼š
            # 1.è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
            # 2.è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
            self._sync_pinned_model(vt)
            # å°†åŒæ­¥å®Œæˆçš„vtçš„idxåŠ å…¥get_queueé˜Ÿåˆ—
            self.get_queue.add(vt.idx)
            if self.nvprof: nvtx_range_pop() 

    # ä¸¤ç§æƒ…å†µï¼š
    # 1.è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
    # 2.è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
    @torch.no_grad()
    def _sync_pinned_model(self, vt):
        """ sync W,B to local pinned model for this pack """  
        for l in vt.layers:
            # è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
            if vt.In['W'][l].medium=='SHM' and vt.In['B'][l].medium=='SHM':
                if l in self.cpu_layer_id:
                    self.shared_optimizer[l].sync_pinned_model()
                elif l in self.new_cpu_layer_id:
                    print(f"rank:{self.rank}, layer{l} æ˜¯æ–°cpu layer ({vt.layers})", flush=True)
                    layer_idx = self.layer_id_to_layer_idx[vt.idx][l]
                    pinned_buffer = self.shared_model_nvme.get_pinned_buffer(layer_idx)
                    self.shared_optimizer[l].sync_pinned_buffer(pinned_buffer)
                else:
                    print(f"rank:{self.rank}, layer{l} æ˜¯nvme layer ({vt.layers})", flush=True)
                    layer_idx = self.layer_id_to_layer_idx[vt.idx][l]
                    self.shared_model_nvme.swap_in_sync(l, layer_idx)
                    print(f"rank:{self.rank},layer{l} SWAP INå®Œæˆ", flush=True)
                    # è‹¥vtæ˜¯BWDä»»åŠ¡ï¼Œè¿˜éœ€å°†å…±äº«æ¨¡å‹æŒ‡å‘å›ºå®šå†…å­˜æ¨¡å‹ï¼Œå› ä¸ºè¦åœ¨cpuä¸Šè¿›è¡Œå‚æ•°æ›´æ–°
                    if vt.type == 'BWD':
                        self.shared_model_nvme.make_shared_model_point_to_pinned(l, layer_idx)
                        print(f"rank:{self.rank},layer{l}çš„sharedmodelå·²æŒ‡å‘pinned buffer", flush=True)
            # è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
            elif vt.In['W'][l].medium=='PIN' and vt.In['B'][l].medium=='PIN':
                pass
            else: # P2P
                raise ValueError("Underdevelopment")
    
    # self.put_queue.add(vt)
    def iput(self, vt):
        ''' Call by main thread. Nonblocking.'''
        assert isinstance(vt, vTask)
        self.put_queue.add(vt)

    # è¿”å›get_queueçš„é¦–ä¸ªå…ƒç´ ï¼ˆä»»åŠ¡çš„idxï¼‰ï¼Œå¹¶æŠŠå…¶ä»é˜Ÿåˆ—ä¸­åˆ é™¤ã€‚å³è¿”å›å·²ç»å®Œæˆä»å…±äº«æ¨¡å‹åˆ°å›ºå®šå†…å­˜æ¨¡å‹å¤åˆ¶W,Bçš„ä»»åŠ¡ï¼ˆå³åŒæ­¥ï¼‰
    def get(self):
        ''' Call by prefetech thread. Blocking. Return vt.idx. '''
        return self.get_queue.remove()

# åŒbufferç‰ˆæœ¬
class SyncPinModelInBkgd_for_worker5_double_buffer(object):
    """ Handles synchronization to local pinned model in background thread.
        Assumption:
            0) always in FIFO ordering. put each task, and get synced task. 
        TODO: skip sync_pinned_model() if already done (FWD -> BWD)
        NOTE: move vt.medium check back to runtime by reducing granularity to vLayer?
    """
    def __init__(self, shared_optimizer, shared_model_nvme, layer_num, layer_id_to_layer_idx, cpu_layer_id, rank, nvprof=False):
        self.shared_optimizer = shared_optimizer
        self.rank = rank
        self.nvprof = nvprof
        # initialize
        # put_queue ç›¸å½“äºä¸€ä¸ªå¯åŠ¨æ¡ä»¶ï¼Œå³æ¥æ´»äº†ï¼Œå…¶ä¸­çš„å…ƒç´ æ˜¯å…¶ä»–çº¿ç¨‹æˆ–è‡ªå·±æ·»åŠ è¿›å»çš„ï¼Œè¿™ä¸ªé‡Œé¢å¾—æœ‰ä¸œè¥¿ï¼Œ
        # è‡ªèº«è¿™ä¸ªçº¿ç¨‹æ‰èƒ½å–å‡ºä¸œè¥¿ï¼Œå¹¶æ‰§è¡Œåé¢çš„æ­¥éª¤ï¼Œä¸ç„¶ä¼šä¸€ç›´é˜»å¡
        self.put_queue = threadsafe_data_struct.Queue() # [vtask1, vtask2, ...] # between main and sync thread
        # get_queue ä»£è¡¨é€»è¾‘ä¸Šæˆ‘è¿™ä¸ªæ´»å¹²å®Œäº†ï¼Œç”¨äºé€šçŸ¥å…¶ä»–çº¿ç¨‹æˆ‘çš„æ´»å¹²å®Œäº†ï¼Œä¸€èˆ¬æ˜¯ä¸Šçº§çº¿ç¨‹è°ƒç”¨å‡½æ•°æ‹¿å–è¿™é‡Œé¢çš„å€¼
        self.get_queue = threadsafe_data_struct.Queue() # [vtask1.idx, vtask2.idx, ...] # between sync and prefetch thread
        self.sync_thread = threading.Thread(target=self._thread_func)
        self.sync_thread.daemon = True
        self.sync_thread.start()
        # print("[SyncPinModelInBkgd] rank{} started sync_thread".format(self.rank))

        # ğŸ“
        self.shared_model_nvme: SharedModelNVMe_double_buffer = shared_model_nvme
        self.layer_num = layer_num
        self.layer_id_to_layer_idx = layer_id_to_layer_idx
        self.cpu_layer_id = cpu_layer_id

    # ä¸æ–­å°è¯•ä»put_queueä¸­æ‹¿å–ä»»åŠ¡ï¼ˆvtï¼‰ï¼Œå¯¹æ‹¿åˆ°çš„vtæ‰§è¡Œï¼š
    # 1.è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
    #   --è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
    # 2.å°†åŒæ­¥å®Œæˆçš„vtçš„idxåŠ å…¥get_queueé˜Ÿåˆ—
    def _thread_func(self):
        """ This method is to be executed from a daemon thread. """
        while True: # for each incoming task 
            vt = self.put_queue.remove() # blocking
            if self.nvprof: nvtx_range_push("__task{}({}) SyncPin(W,B)".format(vt.idx, vt.show_layers())) 
            
            buffer_id = self.reuse_buffer(vt)
            if buffer_id is None:
                buffer_id = self.get_available_buffer(vt)
                self._sync_pinned_model(vt, buffer_id)
            else:
                for l in vt.layers:
                    layer_idx = self.layer_id_to_layer_idx[vt.idx][l]
                    self.shared_model_nvme.make_shared_model_point_to_pinned(buffer_id, l, layer_idx)

            # å°†åŒæ­¥å®Œæˆçš„vtçš„idxåŠ å…¥get_queueé˜Ÿåˆ—
            self.get_queue.add((vt.idx, buffer_id))
            if self.nvprof: nvtx_range_pop() 

    def reuse_buffer(self, vt):
        # æ— è®ºæ˜¯FWDè¿˜æ˜¯BWDï¼ŒIn['W']å’ŒIn['B']éƒ½æ˜¯æœ‰å€¼çš„
        all_pin = all(vt.In['W'][l].medium=='PIN' and vt.In['B'][l].medium=='PIN' for l in vt.layers)
        if all_pin:
            # å¦‚æœæ˜¯PINåª’ä»‹ï¼Œè¿”å›å‰ä¸€ä¸ªä»»åŠ¡ä½¿ç”¨çš„buffer_id
            prev_buffer_id = self.shared_model_nvme.get_buffer_id(vt)
            assert prev_buffer_id is not None, "å‰ä¸€ä¸ªä»»åŠ¡ä½¿ç”¨çš„buffer_idä¸ºNone"
            print(f"rank:{self.rank}, ({vt.type}/{vt.layers})ä½¿ç”¨PINåª’ä»‹, ç»§ç»­ä½¿ç”¨buffer_id:{prev_buffer_id}")
            return prev_buffer_id

        return None

    def get_available_buffer(self, vt, max_retries=10):
        # åœ¨vtçº§åˆ«è·å–buffer
        retries = 0
        
        while True:
            buffer_id = self.shared_model_nvme.get_available_buffer(vt)
            if buffer_id is not None:
                print(f"rank:{self.rank}, ---------------------({vt.type}/{vt.layers})æˆåŠŸè·å–åˆ°buffer_id:{buffer_id}")
                return buffer_id

            # print(f"rank:{self.rank}, æ²¡æœ‰å¯ç”¨çš„buffer, ç­‰å¾…... (é‡è¯•æ¬¡æ•°: {retries + 1}/{max_retries})")
            time.sleep(0.001)
            retries += 1

        if buffer_id is None:
            error_msg = f"rank:{self.rank}, åœ¨{max_retries}æ¬¡å°è¯•åä»æœªè·å–åˆ°å¯ç”¨bufferï¼Œç¨‹åºç»ˆæ­¢"
            print(error_msg)
            raise RuntimeError(error_msg)

    # ä¸¤ç§æƒ…å†µï¼š
    # 1.è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
    # 2.è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
    @torch.no_grad()
    def _sync_pinned_model(self, vt, buffer_id):
        """ sync W,B to local pinned model for this pack """  
        for l in vt.layers:
            # è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
            if vt.In['W'][l].medium=='SHM' and vt.In['B'][l].medium=='SHM':
                if l in self.cpu_layer_id: # l == 0 or l == self.layer_num-3 or l == self.layer_num-2 or l == self.layer_num-1:
                    self.shared_optimizer[l].sync_pinned_model()
                else:
                    layer_idx = self.layer_id_to_layer_idx[vt.idx][l]
                    self.shared_model_nvme.swap_in(buffer_id, l, layer_idx)
                    print(f"rank:{self.rank},layer{l} SWAP INå®Œæˆ", flush=True)
                    # è‹¥vtæ˜¯BWDä»»åŠ¡ï¼Œè¿˜éœ€å°†å…±äº«æ¨¡å‹æŒ‡å‘å›ºå®šå†…å­˜æ¨¡å‹ï¼Œå› ä¸ºè¦åœ¨cpuä¸Šè¿›è¡Œå‚æ•°æ›´æ–°
                    if vt.type == 'BWD':
                        self.shared_model_nvme.make_shared_model_point_to_pinned(buffer_id, l, layer_idx)
                        print(f"rank:{self.rank},layer{l}çš„sharedmodelå·²æŒ‡å‘pinned buffer", flush=True)
            # è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
            elif vt.In['W'][l].medium=='PIN' and vt.In['B'][l].medium=='PIN':
                pass
            else: # P2P
                raise ValueError("Underdevelopment")
    
    # self.put_queue.add(vt)
    def iput(self, vt):
        ''' Call by main thread. Nonblocking.'''
        assert isinstance(vt, vTask)
        self.put_queue.add(vt)

    # è¿”å›get_queueçš„é¦–ä¸ªå…ƒç´ ï¼ˆä»»åŠ¡çš„idxï¼‰ï¼Œå¹¶æŠŠå…¶ä»é˜Ÿåˆ—ä¸­åˆ é™¤ã€‚å³è¿”å›å·²ç»å®Œæˆä»å…±äº«æ¨¡å‹åˆ°å›ºå®šå†…å­˜æ¨¡å‹å¤åˆ¶W,Bçš„ä»»åŠ¡ï¼ˆå³åŒæ­¥ï¼‰
    def get(self):
        ''' Call by prefetech thread. Blocking. Return vt.idx. '''
        return self.get_queue.remove()
