# Copyright (c) Microsoft Corporation.
# Licensed under the MIT license.

from __future__ import division, print_function
import argparse
import os
import sys
import json
import numpy as np
import gc
from collections import OrderedDict as ODict
from copy import deepcopy

import torch
from torch.autograd import Variable
from torch.utils.data import DataLoader, RandomSampler
import torch.distributed as dist

import torch.cuda.profiler as cuda_profiler 
from torch.cuda.nvtx import mark as nvtx_mark 
from torch.cuda.nvtx import range_push as nvtx_range_push 
from torch.cuda.nvtx import range_pop as nvtx_range_pop 
from viewer.probe_cuda_mem import ProbeCudaMem 
from time import perf_counter as pc

import seeding, checker

from profiler import realize_X, realize_dX, realize_T
from task_data_struct import Medium, vTask
import shared_optim_cpu, local_model_gpu, msg_stash_x, ubatchsize_converter, swp_x, p2p
from decompose import decompose_minibatch
from tensor_helper import * 
from utils import *

import datetime
import time

class Worker(object): # each rank process
    def __init__(self, args, real_dataset, shared_model, shared_optimizer, empty_model, get_lr_sched, compute_loss, save_model, XMETA, TMETA, rTASKS, CONFIGS, rank):
        self.args = args
        self.shared_model = shared_model
        self.shared_optimizer = shared_optimizer
        self.compute_loss = compute_loss
        self.save_model = save_model
        self.XMETA, self.TMETA = XMETA, TMETA
        self.rTASKS, self.CONFIGS = rTASKS, CONFIGS
        self.rank, self.world_size = rank, CONFIGS["N"]
        self.verbose, self.nvprof = args.verbose, args.nvprof

        # worker process must re-seed
        seeding.seed(args.seed, args.seed_cudnn) 
        self.rand_state_train = seeding.RandState()

        # per-rank configs
        if CONFIGS['mode'] == 'vPP':
            self.ubatchszs_fwd_local = CONFIGS['ubatchszs_fwd']
            print(f"ubatchszs_fwd_local:{CONFIGS['ubatchszs_fwd']}")
            self.ubatchszs_bwd_local = CONFIGS['ubatchszs_bwd']
            print(f"ubatchszs_bwd_local:{CONFIGS['ubatchszs_bwd']}")
            self.minibatchsize_local = CONFIGS['D']
            print(f"minibatchsize_local:{CONFIGS['D']}")
        elif CONFIGS['mode'] == 'vDP':
            self.ubatchszs_fwd_local = CONFIGS['ubatchszs_fwd'][self.rank]
            self.ubatchszs_bwd_local = CONFIGS['ubatchszs_bwd'][self.rank]
            self.minibatchsize_local = sum(self.ubatchszs_fwd_local)
            assert self.minibatchsize_local == sum(self.ubatchszs_bwd_local)
        else:
            raise ValueError
        # è‹¥å‰åå‘microbatchçš„listä¸ä¸€æ ·ï¼Œè¯¥é¡¹ä¸ºtrue
        print("CONFIGS[\"u_fwd\"]:", CONFIGS["u_fwd"])
        print("CONFIGS[\"u_bwd\"]:", CONFIGS["u_bwd"])
        self.is_convert_ubs = True if CONFIGS["u_fwd"] != CONFIGS["u_bwd"] else False
        
        # Initialize the Gloo world first
        # é»˜è®¤å€¼ä¸º "localhost"
        os.environ['MASTER_ADDR'] = args.master_addr
        # é»˜è®¤å€¼ä¸º 12345
        os.environ['MASTER_PORT'] = str(args.master_port)

        # 1.å»ºç«‹è¿›ç¨‹é—´çš„é€šä¿¡
        # backendï¼šé€šä¿¡åç«¯ï¼Œglooç”¨äºCPU
        # init_methodï¼šé»˜è®¤ä¸º env://ï¼Œè¡¨ç¤ºä½¿ç”¨è¯»å–ç¯å¢ƒå˜é‡çš„æ–¹å¼è¿›è¡Œåˆå§‹åŒ–ã€‚os.environ['MASTER_ADDR'] = 'localhost'å’Œ
        # os.environ['MASTER_PORT'] = '12345'ï¼Œå°±æ˜¯ç”¨æ¥ä¾›ç»™init_methodä½¿ç”¨çš„
        # ğŸ“Œä¸åŒè¿›ç¨‹è¿è¡Œåˆ°dist.init_process_group(backend,  init_method,  rank,  world_size)çš„æ—¶å€™ï¼Œä¼šé˜»å¡ï¼Œç›´åˆ°ç¡®å®šæ‰€
        # æœ‰è¿›ç¨‹éƒ½å¯ä»¥é€šä¿¡ä¸ºæ­¢
        dist.init_process_group(backend="gloo", rank=self.rank, world_size=self.world_size)      
        assert dist.get_rank() == self.rank and dist.get_world_size() == self.world_size
        print("rank%d (pid %d): initialized Gloo world. world_size %d" % (self.rank, os.getpid(), self.world_size))
        
        # Set up GPU
        torch.cuda.set_device(self.rank)
        
        # initialize dataset (must be local to be pinned)
        # è¯¥å‚æ•°é»˜è®¤ä¸ºfalseï¼Œæ‰§è¡Œelse
        if args.synthetic_data:
            self.data_loader = list(range(args.num_iters))
            self.data_ubatches, self.target_ubatches = synthesize_data(XMETA, TMETA, self.ubatchszs_fwd_local, self.ubatchszs_bwd_local, pin_memory=not args.no_pin_data)
        else:
            # self.bnamesï¼š{"is_data" = [True, False]ï¼Œ "name" = ["input0", "labels"]}
            self.data_loader, _, self.is_skip_minibatch, self.preprocess_minibatch, self.bnames, self.fdim, self.is_copy_minibatch = real_dataset(args, CONFIGS["D"], args.data_workers)
            self.data_ubatches, self.target_ubatches = None, None
        

        # å›ºå®šå†…å­˜ç»Ÿä¸€ç®¡ç†çš„é€»è¾‘ç°åœ¨è¿™å†™ä¸€ä¸‹
        # ï¼ˆ1ï¼‰è·å–å½“å‰rankä¸Šçš„æ‰€æœ‰å±‚
        from task_data_struct import filter_tasks_by_attr_val
        bwd_tasks = filter_tasks_by_attr_val(self.rTASKS[self.rank], attr='type', value='BWD')
        local_layers = [layer for vt in bwd_tasks for layer in vt.layers]
        # ï¼ˆ2ï¼‰ä¼ ç»™init_in_subprocæ–¹æ³•ã€‚åœ¨ä¸‹é¢çš„forå¾ªç¯ä¸­ï¼Œæ˜¯æœ‰idçš„ï¼Œä¸è¿‡æ²¡ç”¨ä¸Šã€‚ç°åœ¨æ­£å¥½èƒ½ç”¨ä¸Šäº†
        #      æŠŠidå’Œlocal_layersä¸€èµ·ä¼ ç»™è¿™ä¸ªæ–¹æ³•, idåªè¦åœ¨local_layersä¸­ï¼Œå°±æ·±æ‹·è´å½“å‰å±‚ä½œä¸ºpinned model
        print(f"rank:{self.rank}, å½“å‰rankä¸Šçš„å±‚ä¸º:{local_layers}")

        # initialize shared optimizer locally
        self.pcm = PrintCPUMem()
        self.pcm.print("rank%d: before initializing optimizer" % self.rank)
        lr_scheduler = []
        # 2.åˆ›å»ºæ¯ä¸€å±‚çš„pinned memoryç‰ˆæœ¬ï¼ˆå¯¹æ¯å±‚æ¥è¯´ï¼Œç›¸å½“äºå¤åˆ¶å‡ºä¸€ä¸ªæ–°çš„å±‚ï¼‰
        # éå†shared_optimizerï¼Œæ·±åº¦æ‹·è´å…¶ä¸­çš„shared_memoryå˜é‡ï¼ˆå³å…±äº«å†…å­˜ä¸­çš„layerï¼‰ï¼Œå¹¶å°†å¤åˆ¶åçš„æ¨¡å‹çš„å‚æ•°å’Œbuffer
        # ç§»åŠ¨åˆ°pinned memoryä¸­ï¼Œä½œä¸ºä¸€ä¸ªæ–°çš„æˆå‘˜å˜é‡ï¼Œpinned_model
        for id, optim in enumerate(shared_optimizer):
            # args.no_pin_modelï¼šé»˜è®¤ä¸ºfalse
            # args.no_pin_grad_bufï¼šé»˜è®¤ä¸ºfalse
            # åœ¨å½“å‰processä¸­åˆå§‹åŒ–ä¼˜åŒ–å™¨
            # 1.ä¿é™©æ“ä½œï¼Œç¡®ä¿é€»è¾‘æ­£ç¡®ï¼ˆç¡®ä¿å‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€éƒ½åœ¨shared memoryä¸Šï¼Œå¦å¤–ç¡®ä¿param_groups[0]ä¸­é™¤paramsè¿™ä¸ªkeyå¤–å…¶ä»–çš„keyçš„valueä¸æ˜¯tensorï¼‰
            # 2.æ·±åº¦æ‹·è´modelï¼Œå…¶å®å°±æ˜¯ä¸€å±‚ï¼ˆself.shared_modelï¼‰
            # 3.ğŸ“Œå°†å¤åˆ¶çš„å±‚çš„å‚æ•°å’Œbufferç§»åŠ¨åˆ°å›ºå®šå†…å­˜(ç¬¬2æ­¥æ‹·è´çš„model)ä¸­ï¼Œä»¥ä¾¿æ›´é«˜æ•ˆåœ°å°†å‚æ•°ä¼ è¾“åˆ° GPUï¼Œå› ä¸ºåœ¨ä¼ è¾“æ—¶æ— éœ€é‡æ–°åˆ†é…å†…å­˜
            optim.init_in_subproc(self.rank, no_pin_model=args.no_pin_model, no_pin_grad_buf=args.no_pin_grad_buf)
            # optim.init_in_subproc_2(id, local_layers, self.rank, no_pin_model=args.no_pin_model, no_pin_grad_buf=args.no_pin_grad_buf)
            if get_lr_sched is not None: # "gpt2_huggingface"      
                # è‹¥ä¼˜åŒ–å™¨å­˜åœ¨ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªå¸¦æœ‰ warm-up çš„çº¿æ€§å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œå¦åˆ™å¾€åˆ—è¡¨é‡Œæ·»åŠ ä¸€ä¸ªNone
                # æœ€åä¸€ä¸ªè®¡ç®—lossçš„å±‚æ˜¾ç„¶æ˜¯None
                lr_scheduler.append(None if optim.shared_optimizer is None else 
                                    get_lr_sched(args, optim.shared_optimizer))
        self.pcm.print("rank%d: optimizer initialized" % self.rank)

        # initialize local model GPU 
        #
        # 3.åˆ›å»ºæ¯ä¸€å±‚çš„GPUç‰ˆæœ¬ï¼Œå‚æ•°å’Œbufferéƒ½æ˜¯ç©ºçš„ï¼ˆè¢«æ›¿æ¢ä¸º0å¼ é‡ï¼‰
        # æ¯ä¸€ä¸ªlayeréƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œæœ‰è‡ªå·±çš„ä¼˜åŒ–å™¨ï¼Œå¯¹æ¯ä¸€å±‚æ‰§è¡Œï¼š
        # 3.1.åˆå§‹åŒ–ä¸€ä¸ªç±»ï¼Œè¿‡ç¨‹ä¸ºï¼šå°†å­˜æ”¾åœ¨è¿™ä¸€å±‚optimizerä¸­çš„pinned_modelï¼Œå°±æ˜¯ä¸€ä¸ªlayerï¼Œå³æ”¾åœ¨å›ºå®šå†…å­˜ä¸­çš„vlayerï¼Œ
        #   å¤åˆ¶åˆ°GPUä¸Šï¼Œç„¶åèµ‹ç»™empty modelå¯¹åº”çš„layerä¸Šã€‚æœ€ååˆ é™¤GPUä¸Šå½“å‰layerï¼ˆempty_vlayerï¼‰çš„æ‰€æœ‰å‚æ•°ã€æ¢¯åº¦å’Œç¼“å†²åŒº
        # 3.2.è°ƒç”¨ç±»ä¸­modelæˆå‘˜ï¼ˆempty_vlayerï¼‰çš„trainå‡½æ•°ï¼Œå³å¯ç”¨ batch normalization å’Œ dropout 
        # 3.3.å°†è¯¥ç±»åŠ å…¥åˆ°listä¸­
        # æœ€åï¼Œlocal_modelåŒ…å«äº†æ‰€æœ‰åŒ…å«GPUä¸Švlayerçš„ç±»
        self.local_model = []
        for vlayer_id, (optim, (_,X_names,Y_names), empty_vlayer) in enumerate(zip(shared_optimizer, shared_model, empty_model)):
            # 1.ä¿é™©æ“ä½œï¼šç¡®ä¿pinned_modelï¼ˆå°±æ˜¯ä¸€ä¸ªvlayerï¼‰çš„å‚æ•°å’Œbufferéƒ½åœ¨å›ºå®šå†…å­˜ä¸­
            # 2.å°†å­˜æ”¾åœ¨cpuå›ºå®šå†…å­˜çš„vlayerçš„å‚æ•°å’Œbufferçš„dataï¼Œä½¿ç”¨.cuda()æ–¹æ³•å¤åˆ¶åˆ°GPUä¸Šï¼Œå¹¶èµ‹ç»™empty_vlayer(empty_model å¯¹åº”çš„layer)çš„dataä¸Š
            #   å³ç°åœ¨empty_modelçš„è¯¥å±‚layerï¼ˆempty_vlayerï¼‰å­˜åœ¨äºGPUä¸Š
            # 3.åˆ é™¤GPUä¸Šå½“å‰layerï¼ˆempty_vlayerï¼‰çš„æ‰€æœ‰å‚æ•°ã€æ¢¯åº¦å’Œç¼“å†²åŒº
            local_vlayer = local_model_gpu.LocalModelGPU(optim.pinned_model, optim.shared_model, empty_vlayer, vlayer_id, X_names, Y_names, self.rank, self.world_size, no_pin_model=args.no_pin_model, no_pin_grad_buf=args.no_pin_grad_buf) 
            # local_vlayer = local_model_gpu.LocalModelGPU_2(optim.pinned_model, optim.shared_model, empty_vlayer, vlayer_id, X_names, Y_names, self.rank, self.world_size, no_pin_model=args.no_pin_model, no_pin_grad_buf=args.no_pin_grad_buf) 
            # è°ƒç”¨ç±»ä¸­modelæˆå‘˜ï¼ˆempty_vlayerï¼‰çš„trainå‡½æ•°ï¼Œå³å¯ç”¨ batch normalization å’Œ dropout 
            local_vlayer.train() # shared_model/pinned_train.train() not necessary
            # å°†è¯¥ç±»åŠ å…¥åˆ°listä¸­
            self.local_model.append(local_vlayer)
        self.pcm.print("rank%d: local model initialized" % self.rank)
        
        # initialize MSG stashing X on CPU
        # 4.åˆå§‹åŒ–MSGXçº¿ç¨‹å®ä¾‹
        layer_X_names = ODict()
        for vlayer_id, (_,X_names,_) in enumerate(shared_model):
            layer_X_names[vlayer_id] = X_names
        # pin_memoryï¼šargs.no_pin_xé»˜è®¤ä¸ºfalseï¼Œå³ä¸ä¼šä¸pin xï¼Œè€Œå‚æ•°åå­—çš„è¯­ä¹‰æœ¬èº«ä¸argä¸­çš„å‚æ•°ç›¸åï¼Œå› æ­¤å–åä¸ºtrueï¼Œå³pin x
        #
        # Handles gloo send/recv of stashing X between cpu processes. 
        # æå–MSGXçš„ä»»åŠ¡çš„ä¿¡æ¯ï¼Œä¸ºå½“å‰rankä¸Šå‘é€ã€æ¥æ”¶MSGXçš„çº¿ç¨‹æå‰å‡†å¤‡æ•°æ®ç»“æ„ï¼Œé‡ç‚¹ä¸ºåˆ›å»ºçº¿ç¨‹å®‰å…¨çš„å‘é€/æ¥æ”¶å­—å…¸ã€‚è€Œå
        # åˆ›å»ºå¹¶å¯åŠ¨çº¿ç¨‹ï¼šåˆ›å»ºä¸€ä¸ªå‘é€çº¿ç¨‹ï¼Œè¿˜è¦ä¸ºæ‰€æœ‰å‘å½“å‰rankå‘é€Xçš„src rankåˆ›å»ºæ¥æ”¶çº¿ç¨‹ï¼Œ
        msg_stashx = msg_stash_x.MSGStashX(self.rank, rTASKS, layer_X_names, XMETA, self.ubatchszs_bwd_local, 'pack-by-pack', pin_memory=not args.no_pin_x, nvprof=self.nvprof)
        
        # å°†layer_id å’Œ named_tensors åŠ å…¥åˆ°MSGStashXç±»çš„ send_dict å­—å…¸ä¸­ï¼ˆçº¿ç¨‹å®‰å…¨å­—å…¸ï¼‰
        swapout_stashx_output_fn = msg_stashx.isend

        # è‹¥å‰åå‘microbatchçš„listä¸ä¸€æ ·ï¼Œè¯¥é¡¹ä¸ºtrue
        if self.is_convert_ubs: # initialize Optional UBatchSize Converter on CPU
            # 
            # self.minibatchsize_localï¼šminibatch size
            # CONFIGS['u_fwd']ï¼šfwd micro batchçš„å¤§å°
            # self.ubatchszs_fwd_localï¼šfwd microbatchsizeçš„åˆ—è¡¨
            # CONFIGS['u_bwd']ï¼šbwd micro batchçš„å¤§å°
            # self.ubatchszs_bwd_localï¼šbwd microbatchsizeçš„åˆ—è¡¨
            # msg_stashx.isendï¼šä¸Šé¢é‚£ä¸ªæ–¹æ³•ï¼ˆMSGStashXç±»çš„ï¼‰
            # pack_ordering=False
            # pin_memory=not args.no_pin_xï¼ˆtrueï¼‰
            # 
            # å®é™…è°ƒç”¨çš„è¿˜æ˜¯MSGstashXçš„çº¿ç¨‹å‘é€tensorï¼Œå³è°ƒç”¨MSGstashXçš„isendæ–¹æ³•ï¼Œè¯¥ç±»åªç›¸å½“äºåœ¨æ­£å¸¸çš„ä¸­é—´ç¯èŠ‚ä¸­æ·»åŠ ä¸€ä¸ªé¢å¤–
            # çš„æ­¥éª¤ï¼Œç”¨äºå°†æ›´å¤§çš„FWDç”¨microbatchæ‹†åˆ†ä¸ºBWDç”¨microbatchã€‚
            # åˆ†æï¼šå‰å‘microbatch sizeé»˜è®¤æ˜¯ä¸èƒ½è¶…è¿‡bwd microbatchsizeçš„ï¼Œé“ç†å¾ˆç®€å•ã€‚è‹¥fwdå°äºbwdï¼Œè¯¥microbatchå‹æ ¹ä¸èƒ½ç”¨äºBWDçš„æµç¨‹
            # åªèƒ½è¢«å½“ä½œå‰©ä½™æ•°æ®ç­‰å¾…ä¸‹ä¸€ä¸ªiterationçš„æ–°æ•°æ®è¿›æ¥ï¼Œç»„åˆæˆä¸€ä¸ªè¶³å¤Ÿå¤§çš„tensorï¼Œåœ¨æ­¤ä¹‹å‰BWDæ— æ³•è¿›è¡Œï¼Œæ ¹æœ¬å°±æ— æ³•è¿›è¡Œæ­£å¸¸è®­ç»ƒ
            stashx_ubs_converter = ubatchsize_converter.UBatchSizeConverter(self.rank, self.minibatchsize_local, CONFIGS['u_fwd'], self.ubatchszs_fwd_local, CONFIGS['u_bwd'], self.ubatchszs_bwd_local, msg_stashx.isend, pack_ordering=False, pin_memory=not args.no_pin_x, nvprof=self.nvprof)
            # å°†layer_idå’Œinput2ï¼šcpu_named_tensorsåŠ å…¥åˆ° input_queue é˜Ÿåˆ—ä¸­ï¼Œè¿™æ„å‘³ç€UBatchSizeConverterå®ä¾‹çš„çº¿ç¨‹
            # å°†å¼€å§‹æ‰§è¡Œtensorå¤§å°çš„è½¬æ¢ï¼Œè€Œåå°†convertå¥½çš„tensoråˆ—è¡¨åŠ å…¥åˆ°MSGstashXçš„send_ditcå­—å…¸ä¸­ï¼Œè¿™ä¹Ÿæ„å‘³ç€
            # MSGstashXå®ä¾‹çš„çº¿ç¨‹å°†å¼€å§‹æ‰§è¡Œå‘ç›®æ ‡rankçš„å‘é€ä»»åŠ¡
            swapout_stashx_output_fn = stashx_ubs_converter.isend
        
        # initialize SWP locally
        # å¤šå¡çš„vPPä¸ç”¨ç®¡è¿™ä¸ª
        local_x = None
        if (CONFIGS['mode'] == 'vPP' and CONFIGS['N'] == 1) or (CONFIGS['mode'] == 'vDP'):
            local_x = msg_stash_x.LocalX(self.rank, list(range(CONFIGS['R'])))
            swapout_localx_output_fn = local_x.isend
            if self.is_convert_ubs: # initialize Optional UBatchSize Converter on CPU
                localx_ubs_converter = ubatchsize_converter.UBatchSizeConverter(self.rank, self.minibatchsize_local, CONFIGS['u_fwd'], self.ubatchszs_fwd_local, CONFIGS['u_bwd'], self.ubatchszs_bwd_local, local_x.isend, pack_ordering=False, pin_memory=not args.no_pin_x, nvprof=self.nvprof)
                swapout_localx_output_fn = localx_ubs_converter.isend
        
        # initialize P2P
        # å®ä¾‹åŒ–ä¸€ä¸ªP2Pç±»ï¼Œç”¨äºP2Pé€šä¿¡
        self.p2px_handler, self.p2pm_handler = None, None
        if CONFIGS['mode'] == 'vPP' and CONFIGS['N'] > 1:
            # CONFIGS['reverse_bwd']ï¼šé»˜è®¤ä¸ºfalseï¼Œè¯¥å‚æ•°å·²è¢«åºŸå¼ƒï¼Œä¸ç”¨ç®¡
            # 
            # 1.è®¿é—®æ¯ä¸€ä¸ªrankï¼Œåœ¨æ¯ä¸ªrankå’Œå…¶ä¸‹ä¸€ä¸ªranké—´å»ºç«‹ä¸€ä¸ªNCCLé€šä¿¡ç»„ã€‚è‹¥å½“å‰rankåŒ…å«åœ¨æ­£åœ¨å»ºç«‹çš„é€šä¿¡ç»„ä¸­ï¼Œ
            #   å°±ä¸ºå­—å…¸ self.groups æ·»åŠ ä¸€ä¸ªå€¼ï¼š{ "r1->r2": dist.group_obj }
            # 2.
            #   2.1.åˆ›å»ºä¸€ä¸ªåŒ…å«å•ä¸ªå…ƒç´ çš„å¼ é‡ï¼Œç”¨äºåˆå§‹åŒ– NCCL é€šä¿¡å™¨
            #   2.2.å°†å½“å‰rankæ‰€åœ¨çš„é€šä¿¡ç»„å–å‡ºï¼Œè¿›è¡Œä¸€æ¬¡r1->r2çš„ç‚¹å¯¹ç‚¹é€šä¿¡
            self.p2px_handler = p2p.P2PX(self.rank, self.world_size, CONFIGS['reverse_bwd'], verbose=self.verbose, nvprof=self.nvprof)
        elif CONFIGS['mode'] == 'vDP' and CONFIGS['N'] > 1:
            self.p2pm_handler = p2p.P2PModel(self.rank, self.world_size, verbose=self.verbose)

        # Get default cuda stream (already initialized by local_model_gpu)
        # è·å–å½“å‰ CUDA è®¾å¤‡ä¸Šçš„é»˜è®¤ CUDA æµ
        # ğŸ“Œåœ¨PyTorchä¸­ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼ŒGPUä¸Šçš„æ“ä½œæ˜¯åœ¨é»˜è®¤æµï¼ˆdefault streamï¼‰ä¸­æ‰§è¡Œçš„ã€‚é»˜è®¤æµæ˜¯ä¸€ä¸ªåºåˆ—åŒ–çš„æµï¼Œ
        # å…¶ä¸­çš„æ“ä½œæŒ‰ç…§å®ƒä»¬å‡ºç°çš„é¡ºåºé€ä¸ªæ‰§è¡Œã€‚è¿™æ„å‘³ç€åœ¨æ²¡æœ‰æ˜¾å¼æŒ‡å®šå…¶ä»–æµçš„æƒ…å†µä¸‹ï¼Œæ‰€æœ‰çš„æ“ä½œéƒ½ä¼šåœ¨é»˜è®¤æµä¸­æ‰§è¡Œã€‚
        self.default_stream = torch.cuda.default_stream(self.rank)

        # initialize Update in Background thread
        # å¼€å¯ä¸€ä¸ªupdateçº¿ç¨‹
        # ä¸æ–­å°è¯•ä»put_queueé˜Ÿåˆ—ä¸­æ‹¿å–ä»»åŠ¡ï¼Œå¯¹æ¯ä¸ªä»»åŠ¡æ‰§è¡Œï¼š
        # 1.ç­‰å¾…å½“å‰streamä¸­çš„æ‰€æœ‰æ“ä½œå…¨éƒ¨å®Œæˆï¼Œç„¶åæ‰ä¼šç»§ç»­æ‰§è¡Œåç»­çš„ä»£ç ã€‚å³ç­‰å¾…dW,B'è¢«swapåˆ°pinned memoryä¸­
        # 2.å¯¹ç»™å®švtaskä¸­æ‰€æœ‰layeræ‰§è¡Œæ›´æ–°bufferæ“ä½œï¼šå°†cpuä¸Špinned memoryä¸­çš„æ•°æ®å¤åˆ¶åˆ°åœ¨å…±äº«å†…å­˜çš„vlayerçš„ buffer ä¸­
        # 3.æ›´æ–°shared memoryä¸Švtä¸­æ¯ä¸€å±‚çš„å‚æ•°ï¼Œå¦‚æœé…ç½®äº†å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œè¿˜è¦è°ƒç”¨ç›¸åº”çš„å­¦ä¹ ç‡è°ƒåº¦å™¨æ¥æ›´æ–°å­¦ä¹ ç‡
        # 4.å°†å®Œæˆçš„ä»»åŠ¡çš„idxåŠ å…¥åˆ°get_queueé˜Ÿåˆ—ä¸­
        self.update_handler = shared_optim_cpu.UpdateInBkgd(self.default_stream, shared_optimizer, lr_scheduler, self.rank, nvprof=self.nvprof)

        # initialize Prefetch Model background thread
        # SyncPinModelInBkgdå®ä¾‹ ç”¨æ¥è¾…åŠ© PrefetchLocalModelGPUå®ä¾‹ï¼Œå³å¹¶è¡Œçš„å®Œæˆå…±äº«åˆ°å›ºå®šçš„å¤åˆ¶

        # å¼€å¯ä¸€ä¸ªåŒæ­¥pinned modelçš„çº¿ç¨‹ï¼Œå³å°†shared memoryä¸­æ¨¡å‹çš„å‚æ•°å’Œæ¢¯åº¦å¤åˆ¶åˆ°pinned memoryçš„modelä¸­
        # ä¸æ–­å°è¯•ä»put_queueä¸­æ‹¿å–ä»»åŠ¡ï¼ˆvtï¼‰ï¼Œå¯¹æ‹¿åˆ°çš„vtæ‰§è¡Œï¼š
        # 1.è‹¥W,Bçš„åª’ä»‹æ˜¯SHMï¼Œå°†å…±äº«æ¨¡å‹ä¸­çš„å‚æ•°å’Œç¼“å†²åŒºåŒæ­¥åˆ°æœ¬åœ°çš„å›ºå®šå†…å­˜æ¨¡å‹ä¸­(åœ¨pinned memoryä¸Š)
        #   --è‹¥Wå’ŒBå·²ç»è¢«å›ºå®šåœ¨rankä¸Šäº†ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸ç”¨åš
        # 2.å°†åŒæ­¥å®Œæˆçš„vtçš„idxåŠ å…¥get_queueé˜Ÿåˆ—
        syncpin_handler = shared_optim_cpu.SyncPinModelInBkgd(shared_optimizer, self.rank, nvprof=self.nvprof)

        # æ–°å»ºä¸€ä¸ª swapin_stream ï¼Œä¸“é—¨ç”¨æ¥ swap in model
        # ä¸æ–­å°è¯•ä» put_queue ä¸­æ‹¿å–(vt, ev_computeï¼ˆå‡†å¤‡å·¥ä½œçš„äº‹ä»¶ï¼Œå³åœ¨GPUä¸Šå…ˆåˆå§‹åŒ–Wå’ŒBçš„tensorï¼‰)ï¼Œæ‰§è¡Œï¼ˆè‹¥é˜Ÿåˆ—æ˜¯ç©ºçš„ä¼šè¢«é˜»å¡ï¼‰ï¼š
        # 1.ä» put_queue é˜Ÿåˆ—ä¸­å¼¹å‡º (vt, ev_computeï¼ˆå‡†å¤‡å·¥ä½œçš„äº‹ä»¶ï¼Œå³åœ¨GPUä¸Šå…ˆåˆå§‹åŒ–Wå’ŒBtensorï¼‰)ï¼Œè‹¥é˜Ÿåˆ—æ²¡æœ‰å…ƒç´ ä¼šè¢«é˜»å¡åœ¨è¿™
        # 2.è¿”å›syncpin_handlerå®ä¾‹çš„get_queueçš„é¦–ä¸ªå…ƒç´ ï¼ˆä»»åŠ¡çš„idxï¼‰ï¼Œå¹¶æŠŠå…¶ä»é˜Ÿåˆ—ä¸­åˆ é™¤ã€‚å³è¿”å›å·²ç»å®Œæˆä»å…±äº«æ¨¡å‹åˆ°å›ºå®šå†…å­˜æ¨¡å‹å¤åˆ¶W,Bçš„ä»»åŠ¡ï¼ˆå³åŒæ­¥ï¼‰
        # 3.ç­‰å¾…äº‹ä»¶ ev_compute åœ¨ CUDA æµ self.swapin_stream ä¸Šå®Œæˆï¼Œç„¶åå†ç»§ç»­æ‰§è¡Œåç»­çš„æ“ä½œï¼ˆåç»­æäº¤ç»™è¯¥stramçš„æ‰€æœ‰workéƒ½å¾—ç­‰ï¼‰
        #   å³ç­‰å¾…åœ¨GPUä¸Šåˆå§‹åŒ–vtæ‰€æœ‰å±‚çš„ Wå’ŒB(çš„tensor) çš„å®Œæˆ
        # 4.åœ¨swapin_streamä¸­å°†Wå’ŒBä»cpu memoryï¼ˆé»˜è®¤åœ¨å›ºå®šå†…å­˜ä¸Šï¼‰ä¸Šæ‹·è´åˆ°gpuçš„modelä¸Šï¼Œè‹¥vtçš„ç±»å‹ä¸ºBWDï¼Œè¿˜éœ€è¦
        #   æ˜¾ç¤ºçš„è®¾ç½®å‚æ•° param çš„ requires_grad å±æ€§ä¸º True
        # 5.åœ¨å½“å‰ CUDA æµä¸Šè®°å½•ä¸€ä¸ªäº‹ä»¶ ev_swapin
        # 6.å°† (idx(å½“å‰ä»»åŠ¡çš„id),ev_swapin) åŠ å…¥åˆ° get_queue ä¸­
        self.prefetch_model_handler = local_model_gpu.PrefetchLocalModelGPU(syncpin_handler, self.local_model, self.rank, swapin_stream=None, compute_stream=self.default_stream, nvprof=self.nvprof)
        
        # initialize SwapIn background thread
        # æ–°å»ºä¸€ä¸ªswapin_streamï¼Œä¸“é—¨ç”¨æ¥ swap in stashX
        # ä¸æ–­ä» put_queue ä¸­æ‹¿å– layer_id, cuda_named_tensors, ev_compute å¹¶æ‰§è¡Œï¼š
        # 1.å¦‚æœ ev_compute ä¸ä¸º Noneï¼Œåˆ™åœ¨å½“å‰ CUDA æµä¸Šç­‰å¾…è¯¥äº‹ä»¶çš„å®Œæˆã€‚è¿™æ˜¯ä¸ºäº†ç¡®ä¿åœ¨æ‰§è¡Œåç»­æ“ä½œä¹‹å‰ï¼Œ
        #   å¿…é¡»ç­‰å¾…å…ˆå‰çš„è®¡ç®—å®Œæˆ
        # 2.è°ƒç”¨ msg_stashx.recv æ–¹æ³•ï¼Œå³æ‹¿åˆ°ä»src_rankç©¿æ¥çš„ cpu_tensorï¼Œè‹¥æ²¡æœ‰tensorä¼šè¢«é˜»å¡ä½
        #   2.1.æ‰¾åˆ°å¯¹åº”ç»™å®šlayer_idçš„src_rankï¼Œå³ä»å“ªä¸ªrankä¸Šä¼ Xè¿‡æ¥çš„
        #   2.2.ä»è¯¥src rankå¯¹åº”çš„çº¿ç¨‹å®‰å…¨å­—å…¸ä¸Šï¼Œå³ä»å…¶å†…éƒ¨çš„ self.odict[layer_id] åˆ—è¡¨ä¸­å¼¹å‡ºå¹¶è¿”å›ç¬¬ä¸€ä¸ªå…ƒç´ 
        #       å³ä¸€ä¸ª ï¼ˆname, tensorï¼‰
        #       è‹¥å†…éƒ¨æ²¡æœ‰tensoræ˜¾ç„¶ä¼šè¢«é˜»å¡ä½(wait)
        # 3.å°†cpuä¸Šçš„tesnoræ‹·è´åˆ°gpuä¸Šçš„tensorã€‚è¯¥å‡½æ•°ä¼šè¿”å›ä¸€ä¸ªè®°å½•çš„äº‹ä»¶ï¼Œç”¨äºè®©compute streamç­‰å¾…
        # 4.å°† (cuda_named_tensors, ev_swapin) æ”¾å…¥ get_queue é˜Ÿåˆ—ä¸­
        self.swapin_stashx_handler = swp_x.SwapIn(msg_stashx.recv, self.rank, swapin_stream=None, compute_stream=self.default_stream, nvprof=self.nvprof) 

        # æš‚ç•¥ï¼ŒvDPä¸“ç”¨ï¼šæ–°å»ºä¸€ä¸ªswapin_streamï¼Œä¸“é—¨ç”¨æ¥ swap in LocalX(X/dx)
        self.swapin_localx_handler = swp_x.SwapIn(local_x.recv, self.rank, swapin_stream=None, compute_stream=self.default_stream, nvprof=self.nvprof) if local_x is not None else None
        
        # initialize SwapOut background thread
        # æ–°å»ºä¸€ä¸ªstreamï¼Œä¸“é—¨ç”¨äº swap_out
        swapout_stream = torch.cuda.Stream(device=self.rank)
        # ç”¨äºoffload vPP ä¸­çš„ stashX
        self.swapout_stashx_handler = swp_x.SwapOut(swapout_stashx_output_fn, self.rank,    
                                    swapout_stream=swapout_stream,
                                    compute_stream=self.default_stream, 
                                    blocking=True if args.no_offload_stashx else False,
                                    pin_memory=not args.no_pin_x,
                                    nvprof=self.nvprof)
        
        # æš‚ç•¥ï¼ŒvDPä¸“ç”¨
        self.swapout_localx_handler = swp_x.SwapOut(swapout_localx_output_fn, self.rank, 
                                    swapout_stream=swapout_stream, 
                                    compute_stream=self.default_stream, 
                                    blocking=True if args.no_offload_localx else False,
                                    pin_memory=not args.no_pin_x,
                                    nvprof=self.nvprof) \
                                    if local_x is not None else None
        
        # initialize MSG X on CPU # NOTE: tentatively only for last FWD to first BWD
        # ğŸ“Œè¿™ä¸ªMSGXå®ä¾‹ä¸“é—¨ç”¨æ¥ç®¡ç†æœ€åä¸€ä¸ªå‰å‘ä»»åŠ¡å‘ç¬¬ä¸€ä¸ªBWDä»»åŠ¡å‘é€Y å’Œ ç¬¬ä¸€ä¸ªBWDä»»åŠ¡æ¥æ”¶æœ€åä¸€ä¸ªFWDä»»åŠ¡å‘é€æ¥çš„Y
        #    æ³¨æ„æ˜¯åœ¨cpuä¸Šå‘é€æ¥æ”¶æ•°æ®ï¼ŒéGPUé€šä¿¡
        #
        # Handles gloo send/recv of Y/dX between cpu processes. 
        # MSGStashXçš„å­ç±»
        # 1.åˆ›å»ºä¸€ä¸ªå‘é€æ•°æ®çš„è¾…åŠ©çº¿ç¨‹ _send_helper_thread
        #   ä¸æ–­çš„ä»å¤´å¼€å§‹éå† send_order ä¸­ä¿å­˜çš„layer_idï¼Œå³éå†æ‰€æœ‰è¦æ¥æ”¶æœ€åä¸€ä¸ªfwdä»»åŠ¡è¾“å‡ºçš„Yçš„layer idã€‚è¦å‘é€çš„tensoréƒ½ä¿å­˜åœ¨
        #   send_dictä¸­ï¼Œä¸æ–­å°è¯•é€šè¿‡layer_idå–send_dictä¸­ä¿å­˜çš„tensorï¼Œå‘é€å‡ºå»
        #   è¦å‘é€å°±è¦æŠŠtensorä»dictä¸­åˆ æ‰ï¼Œå³removeï¼Œè‹¥send_dicté”®layer_idå¯¹åº”çš„å€¼ä¸ºç©ºï¼Œremoveå‡½æ•°ä¼šé˜»å¡ä½ï¼Œç›´åˆ°å…¶ä¸­åŠ å…¥äº†
        #   æ–°çš„tesnor
        # 2.ä¸ºæ¯ä¸ª src_rankï¼Œå³ç»™å½“å‰rankä¸Šç¬¬ä¸€ä¸ªbwdä»»åŠ¡å‘é€Yçš„æœ€åä¸€ä¸ªfwdä»»åŠ¡æ‰€åœ¨çš„rankï¼Œåˆ›å»ºä¸€ä¸ªæ¥æ”¶æ•°æ®çš„è¾…åŠ©çº¿ç¨‹
        #  _recv_helper_threadã€‚ä¸æ–­åœ°éå† self.recv_orders[src_rank]ï¼š{src_rankï¼š[(l,u),...], ...}
        #  å³ä¸æ–­å°è¯•ä»src_rankæ¥æ”¶å¯¹åº”layer lçš„microbatchå¤§å°ä¸ºuçš„è¾“å…¥Xã€‚ğŸ“Œè‹¥æ²¡æœ‰æ”¶åˆ°æ•°æ®ä¼šé˜»å¡ä½
        #  å°†è¯»å–åˆ°çš„ named_tensors è¿åŒå…¶ layer_id æ„æˆä¸€ä¸ªå…ƒç»„åŠ å…¥åˆ° self.recv_dicts[src_rank] è¿™ä¸ªçº¿ç¨‹å®‰å…¨å­—å…¸ä¸­
        msg_x = msg_stash_x.MSGX(self.rank, rTASKS, layer_X_names, XMETA, self.ubatchszs_bwd_local, 'pack-by-pack', pin_memory=not args.no_pin_x, nvprof=self.nvprof)
        
        # Call by upstream thread. Nonblocking send. 
        # å‘MSGXå®ä¾‹çš„ send_dict è¿™ä¸ªçº¿ç¨‹å®‰å…¨å­—å…¸ä¸­çš„ odict[layer_id] è¿™ä¸ªlistæ·»åŠ ï¼š
        # self.odict[layer_id].append(named_tensors)
        swapout_msgx_output_fn = msg_x.isend
        self.swapout_msgx_handler, self.swapin_msgx_handler = None, None

        # è‹¥å½“å‰rankä¸Š ä¸å­˜åœ¨ æœ€åä¸€ä¸ªFWDä»»åŠ¡ä¸”è¾“å‡ºYçš„åª’ä»‹ä¸ºMSGï¼Œä¹Ÿä¸å­˜åœ¨ç¬¬ä¸€ä¸ªBWDä»»åŠ¡è¦æ¥æ”¶å‘å‘è‡ªå·±çš„Xï¼ˆåŒæ ·åª’ä»‹ä¸ºMSGï¼‰ï¼Œåˆ é™¤msg_x
        # ğŸ“Œåˆ†æï¼švPPåº”è¯¥æ‰§è¡Œè¿™ä¸ªï¼Œå› ä¸ºvPPæœ€åä¸€ä¸ªFWDå‘é€Yçš„åª’ä»‹ï¼Œå’Œç¬¬ä¸€ä¸ªBWDä»»åŠ¡æ¥æ”¶Xçš„åª’ä»‹éƒ½ä¸ºP2P
        if msg_x.has_no_send() and msg_x.has_no_recv():
            del msg_x; msg_x = None
        # è‹¥å½“å‰rankä¸Šå­˜åœ¨æœ€åä¸€ä¸ªFWDä»»åŠ¡è¦å‘é€Yï¼Œä¸”è¾“å‡ºYçš„åª’ä»‹ä¸ºMSGï¼Œä½†ä¸å­˜åœ¨ç¬¬ä¸€ä¸ªBWDä»»åŠ¡è¦æ¥æ”¶å‘å‘è‡ªå·±çš„Xï¼ˆåŒæ ·åª’ä»‹ä¸ºMSGï¼‰
        elif not msg_x.has_no_send() and msg_x.has_no_recv(): # sender only
            if self.is_convert_ubs:
                msgx_ubs_converter = ubatchsize_converter.UBatchSizeConverter(self.rank, self.minibatchsize_local, CONFIGS['u_fwd'], self.ubatchszs_fwd_local, CONFIGS['u_bwd'], self.ubatchszs_bwd_local, msg_x.isend, pack_ordering=False, pin_memory=not args.no_pin_x, nvprof=self.nvprof)
                swapout_msgx_output_fn = msgx_ubs_converter.isend
            # ğŸ“Œè¿™ä¸ªSwapOutç›¸å½“äºMSGXçš„ä¸Šæ¸¸çº¿ç¨‹ï¼Œè¯¥çº¿ç¨‹ç­‰å¾…swapoutçš„äº‹ä»¶å®Œæˆå†æŠŠtensoræ”¾åˆ°MSGXçš„send_dictä¸­åï¼ŒMSGX
            #   çº¿ç¨‹æ‰ä¼šå‘é€Yç»™å…¶ä»–rank
            # åˆ›å»ºå¹¶å¼€å¯SwapOutçº¿ç¨‹
            # ç¡®ä¿tensoråœ¨å®Œå…¨offloadåˆ°cpuåï¼Œå†æ·»åŠ åˆ°MSGXçº¿ç¨‹çš„send_dictä¸­ï¼Œå‘é€å‡ºå»
            # ä¸æ–­å°è¯•ä» put_queue è¿™ä¸ªçº¿ç¨‹å®‰å…¨é˜Ÿåˆ—ä¸­æ‹¿å– layer_id, cpu_named_tensors, ev_swapout, flagï¼Œæ‰§è¡Œï¼š
            # 1.ç­‰å¾…ev_swapoutäº‹ä»¶æ‰§è¡Œå®Œæˆ
            # 2.è°ƒç”¨ output_fn å‡½æ•°ï¼Œå³ MSGX å®ä¾‹çš„isendæ–¹æ³•ï¼Œå‘ send_dict è¿™ä¸ªçº¿ç¨‹å®‰å…¨å­—å…¸ä¸­çš„ odict[layer_id] è¿™ä¸ª
            #   listæ·»åŠ ï¼šself.odict[layer_id].append(named_tensors)
            self.swapout_msgx_handler = swp_x.SwapOut(swapout_msgx_output_fn, self.rank, 
                                        swapout_stream=swapout_stream, 
                                        compute_stream=self.default_stream, 
                                        blocking=True if args.no_offload_msgx else False,
                                        pin_memory=not args.no_pin_x,
                                        nvprof=self.nvprof)
        # è‹¥å½“å‰rankä¸Šä¸å­˜åœ¨æœ€åä¸€ä¸ªFWDä»»åŠ¡ï¼Œä½†å­˜åœ¨ç¬¬ä¸€ä¸ªBWDä»»åŠ¡ï¼Œè¦æ¥æ”¶å…¶ä»–rankå‘å½“å‰rankå‘é€çš„X
        elif msg_x.has_no_send() and not msg_x.has_no_recv(): # recver only
            # ğŸ“Œè¿™ä¸ªSwapInçº¿ç¨‹ç›¸å½“äºMSGXçš„ä¸‹æ¸¸çº¿ç¨‹ï¼ŒMSGXæ”¶åˆ°äº†ä¼ æ¥çš„Yï¼ŒSwapInå†æŠŠä¼ æ¥çš„tensorå‘åˆ°GPUä¸Š
            # åˆ›å»ºå¹¶å¼€å¯SwapInçº¿ç¨‹
            # ä¸æ–­ä» put_queue ä¸­æ‹¿å– layer_id, cuda_named_tensors, ev_compute å¹¶æ‰§è¡Œï¼š
            # 1.å¦‚æœ ev_compute ä¸ä¸º Noneï¼Œåˆ™åœ¨å½“å‰ CUDA æµä¸Šç­‰å¾…è¯¥äº‹ä»¶çš„å®Œæˆã€‚è¿™æ˜¯ä¸ºäº†ç¡®ä¿åœ¨æ‰§è¡Œåç»­æ“ä½œä¹‹å‰ï¼Œ
            #   å¿…é¡»ç­‰å¾…å…ˆå‰çš„è®¡ç®—å®Œæˆ
            # 2.è°ƒç”¨ MSGX.recv æ–¹æ³•ï¼Œå³æ‹¿åˆ°ä»src_rankä¼ æ¥çš„ cpu_tensorï¼Œè‹¥æ²¡æœ‰tensorä¼šè¢«é˜»å¡ä½
            #   2.1.æ‰¾åˆ°å¯¹åº”ç»™å®šlayer_idçš„src_rankï¼Œå³ä»å“ªä¸ªrankä¸Šä¼ Xè¿‡æ¥çš„
            #   2.2.ä»è¯¥src rankå¯¹åº”çš„çº¿ç¨‹å®‰å…¨å­—å…¸ä¸Šï¼Œå³ä»å…¶å†…éƒ¨çš„ self.odict[layer_id] åˆ—è¡¨ä¸­å¼¹å‡ºå¹¶è¿”å›ç¬¬ä¸€ä¸ªå…ƒç´ 
            #       å³ä¸€ä¸ª ï¼ˆname, tensorï¼‰
            #       è‹¥å†…éƒ¨æ²¡æœ‰tensoræ˜¾ç„¶ä¼šè¢«é˜»å¡ä½(wait)
            # 3.å°†cpuä¸Šçš„tesnoræ‹·è´åˆ°gpuä¸Šçš„tensorã€‚è¯¥å‡½æ•°ä¼šè¿”å›ä¸€ä¸ªè®°å½•çš„äº‹ä»¶ï¼Œç”¨äºè®©compute streamç­‰å¾…
            # 4.å°† (cuda_named_tensors, ev_swapin) æ”¾å…¥ get_queue é˜Ÿåˆ—ä¸­
            self.swapin_msgx_handler = swp_x.SwapIn(msg_x.recv, self.rank, swapin_stream=None, compute_stream=self.default_stream, nvprof=self.nvprof)
        else:
            raise NotImplementedError
        
        # initialize succesor info for all prefetch
        self.sucinfo = SucInfoForPrefetch(self.rank, rTASKS, XMETA)

        # exit(0)

    ################### Initial Iteration ###################
    # å¯¹ä¸åŒ…å«è®¡ç®—losså±‚çš„vtæ‰§è¡Œ:
    # 1.æ ¹æ®ubatch_size, l(vlayer_id), X_namesä»XMETAä¸­æŠŠå…ƒæ•°æ®æ‹¿å‡ºæ¥ï¼Œæ ¹æ®å…ƒæ•°æ®ç”Ÿæˆä¸€ä¸ªéšæœºçš„tensor
    # 2.ç”¨éšæœºç”Ÿæˆçš„tensorä½œä¸ºè¾“å…¥ï¼Œæ‰§è¡Œä¸€æ¬¡vtçš„å‰å‘ä¼ æ’­
    # 3.æŠŠ Y_namesï¼ŒY_tensors è£…åˆ°ODictä¸­è¿”å›ï¼Œè‹¥namesåªæœ‰ä¸€ä¸ªï¼ŒODictä¸­æ˜¾ç„¶åªæœ‰ä¸€ä¸ªé”®å€¼å¯¹ï¼Œä¸ç„¶å°±æ˜¯å¤šä¸ªé”®å€¼å¯¹
    # 4.FWDä»»åŠ¡åˆ é™¤æ‰€æœ‰tesnorï¼Œè‹¥æ˜¯BWDä»»åŠ¡è°ƒç”¨çš„è¯¥å‡½æ•°ï¼Œè¿”å›éšæœºç”Ÿæˆçš„è¾“å…¥tensorå­—å…¸ã€è¾“å‡ºtensorå­—å…¸
    # å¯¹åŒ…å«è®¡ç®—losså±‚çš„vtï¼ŒåŒºåˆ«åœ¨äºï¼š
    # 1.è¿˜éœ€ç”Ÿæˆlabel tensor
    # 2.å¤šäº†ä¸€æ­¥è®¡ç®—loss
    # 3.æ— è®ºFWDè¿˜æ˜¯BWDï¼Œæœ€åéƒ½è¿”å›è¾“å…¥tensorå­—å…¸ã€è¾“å‡ºtensorå­—å…¸
    # 4.è¾“å‡ºçš„tensorå­—å…¸æ˜¯è¾“å‡ºçš„loss
    def _initial_a_pack_forward_an_ubatch(self, vt, ubatch_idx, ubatch_size, requires_grad=False, verbose=False, nvprof=False):
        # å¯¹ä¸åŒ…å«è®¡ç®—losså±‚çš„vtæ‰§è¡Œ
        if not vt.has_criterion:
            ### In {X}
            ### 1.æ ¹æ®ubatch_size, l(vlayer_id), X_namesä»XMETAä¸­æŠŠå…ƒæ•°æ®æ‹¿å‡ºæ¥ï¼Œæ ¹æ®å…ƒæ•°æ®ç”Ÿæˆä¸€ä¸ªéšæœºçš„tensor
            l, m = vt.layers[0], vt.In['X'][vt.layers[0]]
            X_names = self.local_model[l].X_names
            # æ ¹æ®ubatch_size, l(vlayer_id), X_namesä»XMETAä¸­æŠŠå…ƒæ•°æ®æ‹¿å‡ºæ¥ï¼Œæ ¹æ®å…ƒæ•°æ®ç”Ÿæˆä¸€ä¸ªéšæœºçš„tensorï¼Œ
            # è¿”å›ä¸€ä¸ªæœ‰åºå­—å…¸ï¼š{name: ç”Ÿæˆçš„tensor}ï¼Œé¡ºåºå³å‚æ•°namesä¸­nameçš„é¡ºåº
            # 1.è¿”å›self.stats[ubatchsize][vlayer_id][name]ï¼Œnameå°±æ˜¯è¯¥å±‚çš„è¾“å…¥åï¼Œè¿™ä¸ªè¿”å›çš„ä¸œè¥¿æ˜¯ä¸€ä¸ª TensorMetaï¼Œå³tensorçš„å…ƒæ•°æ®
            # 2.æ ¹æ®metaï¼ˆå…ƒæ•°æ®ï¼ŒTensorMetaï¼‰ç”ŸæˆçœŸå®çš„tensor
            X_named_tensors = realize_X(self.XMETA, ubatch_size, l, X_names, requires_grad, "cuda:%d"%self.rank, use_rand=False)
            ### Compute forward pass on GPU
            ### 2.ç”¨éšæœºç”Ÿæˆçš„tensorä½œä¸ºè¾“å…¥ï¼Œæ‰§è¡Œä¸€æ¬¡vtçš„å‰å‘ä¼ æ’­
            if nvprof: nvtx_range_push("task{}({}) {}(#{})".format(vt.idx, vt.show_layers(), "FWD" if not requires_grad else "Recompute", ubatch_idx)) 
            # ä¸ºä»€ä¹ˆé‡‡ç”¨è¿™ç§å¾ˆç»•çš„å‘½åæ–¹å¼ï¼Œæˆ‘ç†è§£ä¸ºèŠ‚çœç©ºé—´ï¼Œå¤ç”¨åŒä¸€ä¸ªå˜é‡
            Y_tensors = [X_named_tensors[name] for name in X_names]
            for l in vt.layers:
                Y_tensors = self.local_model[l](*Y_tensors)
                if not isinstance(Y_tensors, tuple):
                    Y_tensors = (Y_tensors,)
                Y_tensors = list(Y_tensors)
            if verbose: print("\trank{}: task{}({}) {}(#{})".format(self.rank, vt.idx, vt.show_layers(), "FWD" if not requires_grad else "Recompute", ubatch_idx))
            if nvprof: nvtx_range_pop()
            ### Save Y
            ### 3.æŠŠ Y_namesï¼ŒY_tensors è£…åˆ°ODictä¸­è¿”å›ï¼Œè‹¥namesåªæœ‰ä¸€ä¸ªï¼ŒODictä¸­æ˜¾ç„¶åªæœ‰ä¸€ä¸ªé”®å€¼å¯¹ï¼Œä¸ç„¶å°±æ˜¯å¤šä¸ªé”®å€¼å¯¹
            l = vt.layers[-1]
            Y_names = self.local_model[l].Y_names
            Y_named_tensors = make_tensors_named(Y_names, Y_tensors)
            ### Clean up
            ### 4.FWDä»»åŠ¡åˆ é™¤æ‰€æœ‰tesnorï¼ŒBWDä»»åŠ¡è¿”å›éšæœºç”Ÿæˆçš„è¾“å…¥tensorå­—å…¸ã€è¾“å‡ºtensorå­—å…¸
            del Y_tensors
            if not requires_grad:
                del X_named_tensors; del Y_named_tensors
            else:
                return X_named_tensors, Y_named_tensors
        else: # criterion pack
            assert requires_grad
            ### In {X}
            l, m = vt.layers[0], vt.In['X'][vt.layers[0]]
            X_names = self.local_model[l].X_names
            X_named_tensors = realize_X(self.XMETA, ubatch_size, l, X_names, requires_grad, "cuda:%d"%self.rank, use_rand=False)
            ### Recompute on GPU
            # è¯¥å‡½æ•°æ˜¯forwardæ—¶è°ƒç”¨çš„ï¼Œè¿™é‡Œæ³¨é‡Šä¸ºrecomputeä¸åˆç†
            if nvprof: nvtx_range_push("task{}({}) Recompute(#{})".format(vt.idx, vt.show_layers(), ubatch_idx)) 
            if len(vt.layers) > 1: # packed
                Y_tensors = [X_named_tensors[name] for name in X_names]
                for l in vt.layers[:-1]:
                    Y_tensors = self.local_model[l](*Y_tensors)
                    if not isinstance(Y_tensors, tuple):
                        Y_tensors = (Y_tensors,)
                    Y_tensors = list(Y_tensors)
                Y_names = self.local_model[vt.layers[-2]].Y_names
                Y_named_tensors = make_tensors_named(Y_names, Y_tensors)
            else: # only last vlayer
                Y_names = X_names
                Y_named_tensors = X_named_tensors
            ### In {T}
            # æ ¹æ®TMETAä¸­ä¿å­˜çš„target tesnorçš„å…ƒæ•°æ®éšæœºç”Ÿæˆä¸€ä¸ªtensorï¼Œæ”¾åœ¨å­—å…¸é‡Œè¿”å›ã€‚{"label": ç”Ÿæˆçš„tensor}
            T_named_tensors = realize_T(self.TMETA, ubatch_size, "cuda:%d"%self.rank, use_rand=False)
            ### Compute loss on GPU
            # 
            assert vt.layers[-1] == self.CONFIGS['R']-1
            # 
            last_vlayer = self.local_model[self.CONFIGS['R']-1]
            if self.compute_loss is not None: 
                # last_vlayerï¼šæœ€åä¸€å±‚ï¼Œå³è®¡ç®—lossçš„å±‚
                # Y_named_tensorsï¼šå€’æ•°ç¬¬äºŒå±‚è¾“å‡ºçš„tensorå­—å…¸ï¼Œ{åå­—ï¼štensor}
                # Y_namesï¼šå€’æ•°ç¬¬äºŒå±‚è¾“å‡ºå€¼çš„åç§°
                # T_named_tensorsï¼š{"label": tensor}
                Y_tensors = self.compute_loss(last_vlayer, Y_named_tensors, Y_names, T_named_tensors)
            else:
                Y_tensors = [last_vlayer(Y_named_tensors[name],T_named_tensors["target"]) for name in Y_names]
                Y_tensors = [sum(Y_tensors)]
            if verbose: print("\trank{}: task{}({}) Recompute(#{})".format(self.rank, vt.idx, vt.show_layers(), ubatch_idx))
            if nvprof: nvtx_range_pop()
            ### Save Y
            Y_named_tensors = make_tensors_named(['loss'], Y_tensors)
            ### Clean up
            del T_named_tensors; del Y_tensors; 
            return X_named_tensors, Y_named_tensors

    # 1.ä¸ºbackwardå‡½æ•°çš„ç¬¬äºŒä¸ªå‚æ•°å‡†å¤‡ä¸€ä¸ªå€¼å…¨ä¸º1çš„tensorï¼Œè‹¥æ˜¯ç¬¬ä¸€ä¸ªBWDä»»åŠ¡ï¼Œå³å¯¹lossæ±‚åå¯¼ï¼Œåˆ™æ— éœ€å‡†è¯¥tensor
    # 2.æ‰§è¡Œåå‘ä¼ æ’­
    # 3.åˆ é™¤æ‰€æœ‰ç”¨åˆ°çš„tensor
    def _initial_a_pack_backward_an_ubatch(self, vt, ubatch_idx, ubatch_size, X_named_tensors, Y_named_tensors, verbose=False, nvprof=False):
        ### In {dY}
        # è‹¥æ˜¯åŒ…å«è®¡ç®—losså±‚çš„ç¬¬ä¸€ä¸ªBWDä»»åŠ¡ï¼Œç”¨äºbackwardç¬¬äºŒä¸ªå‚æ•°çš„tesnorç›´æ¥è®¾ç½®ä¸ºç©ºï¼ŒåŒæ—¶å°†loss tensorè®¾ç½®ä¸ºrequires_grad
        if vt.has_criterion:
            dY_named_tensors = ODict({ 'loss': None })
            assert Y_named_tensors['loss'].requires_grad

        # è‹¥vtä¸æ˜¯ç¬¬ä¸€ä¸ªBWDä»»åŠ¡ï¼Œä¸ºbackwardçš„ç¬¬äºŒä¸ªå‚æ•°å‡†å¤‡ä¸€ä¸ªå€¼å…¨ä¸º1çš„tensor
        else:
            l, m = vt.layers[-1], vt.In['dY'][vt.layers[-1]]
            # ä½¿ç”¨åé¢é‚£ä¸€å±‚çš„è¾“å…¥çš„å…ƒæ•°æ®ç”Ÿæˆtensorï¼Œå³æ¢¯åº¦çš„å¤§å°å’Œå½“å‰å±‚çš„è¾“å‡ºä¸€æ ·å¤§
            # â“ä¸ºä»€ä¹ˆæ¢¯åº¦çš„å¤§å°å’Œå½“å‰å±‚çš„è¾“å‡ºä¸€æ ·å¤§ï¼Ÿ
            # ç­”ï¼šè¿™ä¸æ˜¯æ¢¯åº¦ï¼Œè€Œæ˜¯ä½œä¸ºbackward()å‡½æ•°çš„ç¬¬äºŒä¸ªå‚æ•°ï¼Œç”¨äºæ‰§è¡Œé›…å¯æ¯”å‘é‡ç§¯çš„ï¼Œå¯ä»¥ç†è§£ä¸ºè®¾ç½®äº†ä¸€ä¸ªæƒé‡ï¼Œ
            # ç”¨æ¥è°ƒæ•´å„ä¸ªå› å˜é‡yå¯¹æœ€ç»ˆé‚£ä¸ªâ€œæ ‡é‡æ¢¯åº¦â€çš„å½±å“å¤§å°
            # ç­”ï¼šäº‹å®ä¸Šä½¿ç”¨å½“å‰å±‚çš„è¾“å‡ºä¹Ÿæ˜¯ä¸€æ ·çš„ï¼švlayer_id, self.model[vlayer_id][2]
            dY_named_tensors = realize_dX(self.XMETA, ubatch_size, l+1, self.local_model[l+1].X_names, device="cuda:%d"%self.rank, use_rand=False)
        ### Compute backward pass
        if nvprof: nvtx_range_push("task{}({}) BWD(#{})".format(vt.idx, vt.show_layers(), ubatch_idx)) 
        # å‡†å¤‡å¥½åå‘ä¼ æ’­è¦ç”¨çš„tesnor
        Y_tensors = []
        Y_gradients = [] 
        for name in self.local_model[vt.layers[-1]].Y_names:
            # å–å‡ºè¯¥vtæœ€ç»ˆè¾“å‡ºçš„tensor
            Y = Y_named_tensors[name]
            if isinstance(Y,(torch.Tensor, Variable)) and (Y.requires_grad):
                Y_tensors.append(Y)
                Y_gradients.append(dY_named_tensors[name])
            elif isinstance(Y, list): 
                for i, y in enumerate(Y):
                    if isinstance(y,(torch.Tensor, Variable)) and (y.requires_grad):
                        Y_tensors.append(y)
                        Y_gradients.append(dY_named_tensors[name][i])
        # æ‰§è¡Œåå‘ä¼ æ’­
        torch.autograd.backward(tuple(Y_tensors), grad_tensors=tuple(Y_gradients))
        if verbose: print("\trank{}: task{}({}) BWD(#{})".format(self.rank, vt.idx, vt.show_layers(), ubatch_idx))
        if nvprof: nvtx_range_pop() 
        ### Clean up {X,Y,dX,dY}
        # åˆ é™¤æ‰€æœ‰ç”¨åˆ°çš„tensor
        del X_named_tensors; del Y_named_tensors
        del dY_named_tensors; del Y_tensors; del Y_gradients

    # â“ä¸ºä»€ä¹ˆè¦å…ˆç”¨å‡æ•°æ®è·‘ä¸€æ¬¡minibatchï¼ˆ1ä¸ªiterationï¼‰
    def run_initial_iteration(self, verbose=False, nvprof=False):
        # è¯¥å‚æ•°é»˜è®¤ä¸ºfalseï¼Œä¸æ‰§è¡Œ
        if self.args.no_initial_iter:
            print("rank%d: --- No Initial Iteration ---" % self.rank)
            return

        print("rank%d: initial iteration starts"%(self.rank))
        assert dist.get_rank() == self.rank and torch.cuda.current_device() == self.rank
        # clean memory before start
        # torch.cuda.synchronize(self.rank)ï¼šç­‰å¾…å½“å‰GPUä¸Šæ‰€æœ‰çš„æ ¸å‡½æ•°æ‰§è¡Œå®Œæ¯•
        # dist.barrier()ï¼šåœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­ï¼ŒåŒæ­¥æ‰€æœ‰è¿›ç¨‹ï¼Œç¡®ä¿åœ¨æ‰§è¡Œåç»­æ“ä½œä¹‹å‰ï¼Œæ‰€æœ‰è¿›ç¨‹éƒ½å·²ç»å®Œæˆäº†å‰é¢çš„å·¥ä½œ
        torch.cuda.synchronize(self.rank); dist.barrier()
        gc.collect(); torch.cuda.empty_cache() 
        torch.cuda.synchronize(self.rank)
        # æ–­è¨€å½“å‰ GPU è®¾å¤‡ä¸Šæ²¡æœ‰ä»»ä½•å†…å­˜è¢«ä¿ç•™
        assert torch.cuda.memory_reserved(self.rank)==0 # æŸ¥çœ‹æ€»å…±å ç”¨çš„æ˜¾å­˜
        dist.barrier()
        # task starts 
        if nvprof:
            probe_cuda_mem = ProbeCudaMem(self.rank)
            probe_cuda_mem.start()  
            cuda_profiler.start()
            nvtx_mark("cudaProfilerStart") 
            print("rank%d: cuda profiler starts" % self.rank)    

        time_start = pc()    
        #     
        for j, vt in enumerate(self.rTASKS[self.rank]): # { rank0: [task0,task2,task5,...] }
            if verbose: print("\trank{}: executing {}".format(self.rank, vt))
            if vt.type == 'FWD' and vt.is_gpu:
                # -----------------------------------------------      
                with torch.no_grad():
                    ### Swap-in model {W,B}
                    if nvprof: nvtx_range_push("task{}({}) SwapIn(W,B)".format(vt.idx, vt.show_layers())) 
                    if verbose: print_gpu_mem(self.rank, vt, "SwapIn(W,B) start")
                    # å½“å‰è¿™ä¸ªprefetchçº¿ç¨‹æ¥æ”¶ä¸€ä¸ªvtï¼Œå¼€å§‹è¿™ä¸ªvtçš„swap_inå·¥ä½œï¼Œå³æŠŠvtæ‰€æœ‰å±‚åœ¨cpuä¸Šçš„Wã€Bæ‹·è´åˆ°gpuä¸Šã€‚ç›¸å½“äºè§¦å‘äº†å½“å‰çº¿ç¨‹çš„å·¥ä½œ
                    # è‹¥suc_vtå‚æ•°ä¸ä¸ºç©ºï¼Œæ„å‘³ç€è¯¥å‡½æ•°ä¼šä¸ºæå‰æ‰§è¡Œä¸€éƒ¨åˆ†åç»§ä»»åŠ¡ï¼Œå³è°ƒç”¨self.syncpin_handler.iput(suc_vt)
                    # åˆ†æï¼šå¹¶è¡Œçš„åšä¸¤ä»¶äº‹ï¼Œ1ï¼‰è°ƒç”¨åŒæ­¥çº¿ç¨‹å°†vtä¸­çš„è¿™äº›åœ¨cpuå…±äº«å†…å­˜ä¸­çš„æ¨¡å‹å¤åˆ¶åˆ°pinned memoryä¸Šï¼›2ï¼‰åœ¨GPUä¸Šä¸ºvtä¸­çš„è¿™äº›å±‚åˆ†é…ä¸€ä¸ªç©ºtensor
                    #      ç¬¬2ä»¶äº‹ä¸æ‰§è¡Œï¼Œ_thread_funcä¼šé˜»å¡åœ¨removeä¸Šã€‚åœ¨ä»¥ä¸Šä¸¤ä»¶äº‹å…¨éƒ¨æ‰§è¡Œå®Œåï¼Œæ‰ä¼šæ‰§è¡Œ swap_in æ“ä½œ
                    cur_vt_idx = self.prefetch_model_handler.get(vt, None)
                    assert cur_vt_idx == vt.idx
                    if verbose: print_gpu_mem(self.rank, vt, "SwapIn(W,B) end")
                    if nvprof: nvtx_range_pop() 
                    ### Run through each microbatch in a data batch
                    # å¯¹æ¯ä¸€ä¸ª microbatch size æ‰§è¡Œä¸€æ¬¡
                    for i, u in enumerate(vt.ubatchszs):# [u1, u2, u3] 
                        # å¯¹ä¸åŒ…å«è®¡ç®—losså±‚çš„vtæ‰§è¡Œ:
                        # 1.æ ¹æ®ubatch_size, l(vlayer_id), X_namesä»XMETAä¸­æŠŠå…ƒæ•°æ®æ‹¿å‡ºæ¥ï¼Œæ ¹æ®å…ƒæ•°æ®ç”Ÿæˆä¸€ä¸ªéšæœºçš„tensor
                        # 2.ç”¨éšæœºç”Ÿæˆçš„tensorä½œä¸ºè¾“å…¥ï¼Œæ‰§è¡Œä¸€æ¬¡vtçš„å‰å‘ä¼ æ’­
                        # 3.æŠŠ Y_namesï¼ŒY_tensors è£…åˆ°ODictä¸­è¿”å›ï¼Œè‹¥namesåªæœ‰ä¸€ä¸ªï¼ŒODictä¸­æ˜¾ç„¶åªæœ‰ä¸€ä¸ªé”®å€¼å¯¹ï¼Œä¸ç„¶å°±æ˜¯å¤šä¸ªé”®å€¼å¯¹
                        # 4.FWDä»»åŠ¡åˆ é™¤æ‰€æœ‰tesnorï¼Œè‹¥æ˜¯BWDä»»åŠ¡è°ƒç”¨çš„è¯¥å‡½æ•°ï¼Œè¿”å›éšæœºç”Ÿæˆçš„è¾“å…¥tensorå­—å…¸ã€è¾“å‡ºtensorå­—å…¸
                        # å¯¹åŒ…å«è®¡ç®—losså±‚çš„vtï¼ŒåŒºåˆ«åœ¨äºï¼š
                        # 1.è¿˜éœ€ç”Ÿæˆlabel tensor
                        # 2.å¤šäº†ä¸€æ­¥è®¡ç®—loss
                        # 3.æ— è®ºFWDè¿˜æ˜¯BWDï¼Œæœ€åéƒ½è¿”å›è¾“å…¥tensorå­—å…¸ã€è¾“å‡ºtensorå­—å…¸
                        # 4.è¾“å‡ºçš„tensorå­—å…¸æ˜¯è¾“å‡ºçš„loss tensor
                        self._initial_a_pack_forward_an_ubatch(vt, i, u, requires_grad=False, verbose=verbose, nvprof=nvprof)
                        gc.collect()
                        if verbose: print_gpu_mem(self.rank, vt, "End(#%d)" % i)
                    ### Delete model {W,B}
                    self.default_stream.synchronize() # CPU wait Compute
                    if nvprof: nvtx_range_push("task{}({}) Del(W,B)".format(vt.idx, vt.show_layers())) 
                    for l in vt.layers:
                        # è‹¥å½“å‰ä»»åŠ¡ä¸éœ€è¦è¾“å‡ºWå’ŒBï¼Œ
                        if not (l in vt.Out['W']) and not (l in vt.Out['B']):
                            # é€’å½’åœ°åˆ é™¤æ¨¡å—ï¼ˆåŒ…æ‹¬å­æ¨¡å—ï¼‰ä¸­çš„æ‰€æœ‰å‚æ•°ã€æ¢¯åº¦å’Œç¼“å†²åŒº
                            self.local_model[l].del_param_grad_buf()
                        elif vt.Out['W'][l].medium=='PIN' and vt.Out['B'][l].medium=='PIN':
                            pass
                        else: # P2P
                            raise ValueError("Underdevelopment")
                    gc.collect()
                    if verbose: print_gpu_mem(self.rank, vt, "Deleted(W,B)")
                    if nvprof: nvtx_range_pop() 
                # -----------------------------------------------
            elif vt.type == 'BWD' and vt.is_gpu:
                # -----------------------------------------------
                ### Swap-in model {W,B}
                if nvprof: nvtx_range_push("task{}({}) SwapIn(W,B)".format(vt.idx, vt.show_layers())) 
                if verbose: print_gpu_mem(self.rank, vt, "SwapIn(W,B) start")
                cur_vt_idx = self.prefetch_model_handler.get(vt, None)
                assert cur_vt_idx == vt.idx 
                if verbose: print_gpu_mem(self.rank, vt, "SwapIn(W,B) end")
                if nvprof: nvtx_range_pop() 
                ### Run through each microbatch in a data batch. 
                for i, u in enumerate(vt.ubatchszs):
                    ### Recompute to create pytorch graph
                    # requires_grad=Trueï¼Œå³è¦ä¿å­˜ X_named_tensors, Y_named_tensors
                    X_named_tensors, Y_named_tensors = \
                        self._initial_a_pack_forward_an_ubatch(vt, i, u, requires_grad=True, verbose=verbose, nvprof=nvprof) 
                    ### Backward pass on recomputed graph
                    # 1.ä¸ºbackwardå‡½æ•°çš„ç¬¬äºŒä¸ªå‚æ•°å‡†å¤‡ä¸€ä¸ªå€¼å…¨ä¸º1çš„tensorï¼Œè‹¥æ˜¯ç¬¬ä¸€ä¸ªBWDä»»åŠ¡ï¼Œå³å¯¹lossæ±‚åå¯¼ï¼Œåˆ™æ— éœ€å‡†è¯¥tensor
                    # 2.æ‰§è¡Œåå‘ä¼ æ’­
                    # 3.åˆ é™¤æ‰€æœ‰ç”¨åˆ°çš„tensor
                    self._initial_a_pack_backward_an_ubatch(vt, i, u, X_named_tensors, Y_named_tensors, verbose=verbose, nvprof=nvprof)
                    ### Clean up
                    del X_named_tensors; del Y_named_tensors # very important!
                    gc.collect()
                    if verbose: print_gpu_mem(self.rank, vt, "End(#%d)" % i)
                ### Swap-out model {W,dW,B}
                if self.CONFIGS["opt_offld"]:                
                    ### Delete model {W,dW,B}
                    self.default_stream.synchronize() # CPU wait for SwapOut
                    if nvprof: nvtx_range_push("task{}({}) Del(W,dW,B)".format(vt.idx, vt.show_layers())) 
                    for l in vt.layers: 
                        # è‹¥dWçš„è¾“å‡ºåª’ä»‹æ˜¯LOCï¼ŒBçš„è¾“å‡ºåª’ä»‹æ˜¯SHM
                        if vt.Out['dW'][l].medium == "LOC" and vt.Out['B'][l].medium == "SHM":
                            # é€’å½’åœ°åˆ é™¤æ¨¡å—ï¼ˆåŒ…æ‹¬å­æ¨¡å—ï¼‰ä¸­çš„æ‰€æœ‰å‚æ•°ã€æ¢¯åº¦å’Œç¼“å†²åŒº
                            self.local_model[l].del_param_grad_buf()
                        else: # 'B' == PIN
                            raise ValueError("Underdevelopment")
                    gc.collect()
                    if verbose: print_gpu_mem(self.rank, vt, "Deleted(W,B)")
                    if nvprof: nvtx_range_pop() 
                else:
                    raise ValueError("GPU Optimizer Underdevelopment.")
                # -----------------------------------------------
            elif vt.type == 'UPD' and not vt.is_gpu:
                # -----------------------------------------------
                pass
                # -----------------------------------------------
            else:
                raise ValueError("Unknown vTask.type {} with .device {} !".format(vt.type,vt.device))
        # tasks ends
        torch.cuda.synchronize(self.rank); dist.barrier()
        time_end = pc() 
        if nvprof:
            nvtx_mark("cudaProfilerStop") 
            cuda_profiler.stop()
            probe_cuda_mem.stop()
            print("rank%d: cuda profiler stops" % self.rank) 
        print("rank%d: initial iteration ends. time %.3f s"%(self.rank, time_end-time_start))
        # clean memory
        gc.collect(); torch.cuda.empty_cache() 
        torch.cuda.synchronize(self.rank)
        assert torch.cuda.memory_reserved(self.rank)==0
        dist.barrier()
        
        if self.args.initial_iter_only:
            print("rank%d: --- Initial Iteration Only ---" % self.rank)
            exit(0) 

    ################### Regular Training Loop ###################
    #
    def _a_pack_forward_an_ubatch(self, vt, ubatch_idx, ubatch_size,
                                data_ubatches, target_ubatches, 
                                requires_grad=False, 
                                prefetch_model_handler=None,
                                swapin_stashx_handler=None,
                                swapin_localx_handler=None,
                                swapin_msgx_handler=None,
                                swapout_stashx_handler=None,
                                swapout_localx_handler=None,
                                swapout_msgx_handler=None,
                                sucinfo=None):
        """ requires_grad == False: FWD (non-criterion)
            requires_grad == True: Recompute (for all) """
        is_last_ubatch = ubatch_idx == len(vt.ubatchszs)-1

        # å¤§éƒ¨åˆ†FWDã€BWDéƒ½æ‰§è¡Œè¿™ä¸ª, åªæœ‰ç¬¬ä¸€ä¸ªBWD vtåŒ…å«è®¡ç®—losså±‚ä¸ä¼šæ‰§è¡Œè¿™ä¸ª
        # ğŸ“Œåˆ†æï¼šå¯¹BWDçš„å†²è®¡ç®—ä»»åŠ¡ï¼ˆå³BWDè¿‡ç¨‹ä¸­çš„FWDä»»åŠ¡ï¼‰ï¼Œä¼šé€šè¿‡medium=='MSG'æ‹¿å–æš‚å­˜çš„stashXï¼Œè€Œé
        # ä»…ä»…é’ˆå¯¹FWDä»»åŠ¡ã€‚æ¯”è¾ƒç»•çš„ç‚¹å°±åœ¨äºBWDæ‹¿å–stashXçš„ä»»åŠ¡æ˜¯åœ¨FWDï¼ˆé‡è®¡ç®—ï¼‰çš„é€»è¾‘ä¸­æ‰§è¡Œçš„ã€‚
        if not vt.has_criterion: # not last pack yet
            ### In {X}
            # 1.æ¥å—æ•´ä¸ªvtçš„è¾“å…¥Xï¼Œåˆ†å‡ ç§æƒ…å†µï¼š
            #   --æ•´ä¸ªæ¨¡å‹çš„ç¬¬ä¸€å±‚ï¼Œè¾“å…¥çš„å°±æ˜¯è¾“å…¥æ•°æ®microbatchï¼Œç›´æ¥å°†è¯¥microbatchå¤åˆ¶åˆ°GPUä¸Š
            #   --ä¸­é—´çš„vtï¼Œè¾“å…¥è‚¯å®šæ˜¯å‰é¢çš„vtè¾“å‡ºçš„ç»“æœï¼Œé€šè¿‡P2Pé€šä¿¡å¹¿æ’­è¿‡æ¥
            #   --...
            l, m = vt.layers[0], vt.In['X'][vt.layers[0]]
            # å½“å‰vtçš„è¾“å…¥åç§°
            X_names = self.local_model[l].X_names
            if m.medium == "DAT": # Get one microbatch data
                # Data as X
                if self.nvprof: nvtx_range_push("task{}({}) SwapIn(#{}Data)".format(vt.idx, vt.show_layers(), ubatch_idx)) 
                # å°†å­—å…¸ä¸­çš„tensoræ›¿æ¢ä¸ºGPUç‰ˆæœ¬ï¼Œå³ç§»åŠ¨åˆ°GPUä¸Š
                X_named_tensors = swp_x.swapin(data_ubatches[ubatch_idx])
                # print("\trank{}: task{}({}) SwapIn(#{}Data)".format(self.rank, vt.idx, vt.show_layers(), ubatch_idx))
            elif m.medium == "P2P":
                if self.nvprof: nvtx_range_push("task{}({}) P2PIn(#{}X)".format(vt.idx, vt.show_layers(), ubatch_idx)) 
                # è¯¥å‚æ•°é»˜è®¤ä¸ºfalseï¼Œæ‰§è¡Œelse
                if self.args.no_p2p_prerecv:
                    X_named_tensors = self.p2px_handler.recv(self.XMETA.get(ubatch_size,l), src=m.rank)
                else:
                    # â“ï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿ
                    X_named_tensors = self.p2px_handler.prerecv(self.XMETA.get(ubatch_size,l), src=m.rank, is_end=is_last_ubatch) 
                # print("\trank{}: task{}({}) P2PIn(#{}X)".format(self.rank, vt.idx, vt.show_layers(), ubatch_idx))
            
            # ğŸ“ŒBWDçš„é‡è®¡ç®—ä»»åŠ¡ä¼šåœ¨æ­¤å¤„æ‹¿å–stashX
            elif m.medium == "MSG": # message pass stashed input
                if self.nvprof: nvtx_range_push("task{}({}) SwapIn(#{}StashX)".format(vt.idx, vt.show_layers(), ubatch_idx)) 
                # è¯¥å‚æ•°é»˜è®¤ä¸ºfalseï¼Œæ‰§è¡Œelse
                if self.args.no_prefetch_stashx:
                    X_named_tensors = swapin_stashx_handler.fetch(l, self.XMETA.get(ubatch_size,l))
                else:

                    X_named_tensors = swapin_stashx_handler.prefetch(l, self.XMETA.get(ubatch_size,l), is_last_ubatch)
                # print("\trank{}: task{}({}) SwapIn(#{}StashX)".format(self.rank, vt.idx, vt.show_layers(), ubatch_idx))
            elif m.medium == "SWP": # swap locally for vDP
                if self.nvprof: nvtx_range_push("task{}({}) SwapIn(#{}LocalX)".format(vt.idx, vt.show_layers(), ubatch_idx)) 
                if self.args.no_prefetch_localx:
                    X_named_tensors = swapin_localx_handler.fetch(l, self.XMETA.get(ubatch_size,l))
                else:
                    X_named_tensors = swapin_localx_handler.prefetch(l, self.XMETA.get(ubatch_size,l), is_last_ubatch)
                # print("\trank{}: swp_recv'ed L{}-X".format(self.rank, l))
            else:
                raise NotImplementedError
            if self.nvprof: nvtx_range_pop() 

            # print(f"rank:{self.rank}, vt:{vt.idx}({vt.show_layers()}), æ¥æ”¶çš„tensorä¸º:{X_named_tensors} ({ubatch_idx})")

            ### Prefetch point @ FWD/Recompute (non-criterion)'s ULast 
            # 2.è‹¥å½“å‰æ‰§è¡Œåˆ°æœ€åä¸€ä¸ªmicro batchï¼Œä¸ºå½“å‰rankä¸Šä¸‹ä¸€ä¸ªvté¢„æ¥æ”¶å…¶éœ€è¦çš„è¾“å…¥æ•°æ®
            # 2.1.è‹¥å½“å‰ä»»åŠ¡æ˜¯FWDä»»åŠ¡ï¼ˆnot requires_gradï¼‰ï¼Œè€ŒéBWDæ—¶æ‰§è¡Œçš„é‡è®¡ç®—ï¼Œåˆ™ä¸ºåç»§vté¢„å– X/dY
            # 2.2.è‹¥è¯¥rankä¸Šçš„ä¸‹ä¸€ä¸ªä»»åŠ¡æ˜¯BWDä»»åŠ¡ï¼Œå°±æŠŠstashXæ‹¿è¿›æ¥ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨sucinfo.stashx()å‡½æ•°ä¸­ï¼Œè‹¥åç»§ä»»åŠ¡æ˜¯FWDä»»åŠ¡ï¼Œ
            #     ç›´æ¥è¿”å›Noneã€‚prefetch_sucå‡½æ•°åœ¨æ”¶åˆ°Noneåä¹Ÿä¼šç›´æ¥è¿”å›ï¼Œä¸åšä»»ä½•å¤„ç†
            if is_last_ubatch:
                if self.nvprof: nvtx_range_push("task{}({}) PrefetchPt".format(vt.idx, vt.show_layers() )) 

                # 2.1
                # è‹¥å½“å‰ä»»åŠ¡æ˜¯FWDä»»åŠ¡ï¼ˆnot requires_gradï¼‰ï¼Œè€ŒéBWDæ—¶æ‰§è¡Œçš„é‡è®¡ç®—ï¼Œåˆ™ä¸ºåç»§vté¢„å– X/dY
                # åˆ†æï¼šè‹¥æ˜¯é‡è®¡ç®—ä»»åŠ¡ï¼Œåˆ™ä¸ä¼šé¢„å–è¾“å…¥Xï¼ŒåŸå› å¾ˆç®€å•ï¼Œé‡è®¡ç®—ä»»åŠ¡è¦æ‹¿çš„æ˜¯æš‚å­˜çš„stashXï¼Œä¸å­˜åœ¨å‰é¢çš„ä»»åŠ¡ç»™ä½ å‘Xï¼Œæ‹¿stashX
                #      çš„ä»£ç å°±åœ¨æ‹¿Xçš„ä¸‹é¢
                #      å¯¹äºBWDä»»åŠ¡çš„åç»§BWDä»»åŠ¡éœ€è¦çš„dYçš„é—®é¢˜ï¼Œè¿™ä¸ªé€»è¾‘è‚¯å®šæ˜¯åœ¨ _a_pack_backward_an_ubatch å‡½æ•°ä¸­æ‰§è¡Œï¼Œ
                #      è¿™é‡Œç”±äº not requires_grad æ‰ä¼šæ‰§è¡Œï¼Œæ˜¾ç„¶ç›´æ¥ä¸éœ€è¦è€ƒè™‘è¿™ç§æƒ…å†µäº†
                if self.p2px_handler is not None and \
                    not self.args.no_p2p_prerecv and not requires_grad:
                    # sucinfo.p2pin()ï¼šè‹¥åç»§ä»»åŠ¡æ¥æ”¶X/dYçš„åª’ä»‹ä¸ºP2Pï¼Œè¿”å›å…¶å…ƒæ•°æ®å’Œsrc_rankï¼Œç”¨äºprerecv_sucæ–¹æ³•
                    #                  æå‰ä½¿ç”¨P2Pæ–¹æ³•æ¥æ”¶åç»§FWDæˆ–BWDä»»åŠ¡çš„è¾“å…¥X/dY
                    self.p2px_handler.prerecv_suc(sucinfo.p2pin())
                # if swapin_msgx_handler is not None and \
                #     not self.args.no_prefetch_msgx and not requires_grad:
                #     swapin_msgx_handler.prefetch_suc(sucinfo.msgx())
                # if prefetch_model_handler is not None and \
                #     not self.args.no_prefetch_model and not requires_grad:
                #     prefetch_model_handler.iput(sucinfo.model()) 

                # 2.2
                # è‹¥è¯¥rankä¸Šçš„ä¸‹ä¸€ä¸ªä»»åŠ¡æ˜¯BWDä»»åŠ¡ï¼Œå°±æŠŠstashXæ‹¿è¿›æ¥ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨sucinfo.stashx()å‡½æ•°ä¸­ï¼Œè‹¥åç»§ä»»åŠ¡æ˜¯FWDä»»åŠ¡ï¼Œ
                # ç›´æ¥è¿”å›Noneã€‚prefetch_sucå‡½æ•°åœ¨æ”¶åˆ°Noneåä¹Ÿä¼šç›´æ¥è¿”å›ï¼Œä¸åšä»»ä½•å¤„ç†
                if swapin_stashx_handler is not None and \
                    not self.args.no_prefetch_stashx:
                    # sucinfo.stashx()ï¼š
                    # è‹¥åç»§ä»»åŠ¡æ˜¯BWDï¼ˆéç¬¬ä¸€ä¸ªBWDï¼‰ï¼Œä¸”è¾“å…¥åª’ä»‹æ˜¯MSGï¼Œè¿”å› (l(åç»§ä»»åŠ¡çš„é¦–å±‚id), åç»§ä»»åŠ¡è¾“å…¥Xçš„å…ƒæ•°æ®) ã€‚éMSGç›´æ¥è¿”å›None
                    # å…¶ä»–æƒ…å†µç›´æ¥è¿”å›None
                    # ğŸ“Œåˆ†æï¼šåªæœ‰åç»§ä»»åŠ¡ä¸ºBWDä»»åŠ¡ï¼Œstashx()æ‰æœ‰è¿”å›å€¼ï¼Œä¹Ÿå°±æ˜¯è¯´è‹¥åç»§ä»»åŠ¡ä¸ºFWDï¼Œè¿™é‡Œæ ¹æœ¬ä¸ä¼šé¢„å–
                    #
                    # åœ¨gpuä¸ŠæŒ‰ç…§sucinfo.stashx()è¿”å›çš„å…ƒæ•°æ®åœ¨gpuä¸Šç”Ÿæˆä¸€ä¸ªç©ºtensorï¼Œéšåå°†
                    # (suc_layer_id, cuda_named_tensors, ev_compute)æ·»åŠ åˆ° put_queue ä¸­ï¼Œ
                    # ğŸ“Œè¿™æ„å‘³ç€SwapInçº¿ç¨‹ä¼šå¼€å§‹cpuåˆ°gpuçš„æ‹·è´æ“ä½œ
                    swapin_stashx_handler.prefetch_suc(sucinfo.stashx())
                # if swapin_stashx_handler is not None and \
                #     not self.args.no_prefetch_stashx and requires_grad:
                #     swapin_stashx_handler.prefetch_suc(sucinfo.stashx())

                # swapin_localx_handler ä¸º vDP   ä¸“ç”¨ï¼Œæš‚ç•¥
                if swapin_localx_handler is not None and \
                    not self.args.no_prefetch_localx and not requires_grad:
                    # sucinfo.localx()ï¼š
                    # ä¸ºåç»§ä»»åŠ¡å‡†å¤‡è¾“å…¥ä¿¡æ¯(å…ƒæ•°æ®)ï¼Œåç»§ä¸ºFWD/é¦–ä¸ªBWDåˆ™å‡†å¤‡è¾“å…¥Xï¼Œåç»§ä¸ºBWDåˆ™å‡†å¤‡è¾“å…¥dY
                    # ä¸¤ç§æƒ…å†µ
                    # 1.FWD->FWDã€æœ€åä¸€ä¸ªFWD->ç¬¬ä¸€ä¸ªBWD(åŒ…å«è®¡ç®—å±‚)
                    #   è‹¥suc_vté¦–å±‚æ¥æ”¶Xçš„åª’ä»‹ä¸ä¸ºSWPï¼Œè¿”å›Noneï¼Œå¦åˆ™è¿”å› (l(suc_vtçš„é¦–å±‚)ï¼Œlè¿™å±‚æ¥æ”¶Xçš„å…ƒæ•°æ®)
                    # 2.é¦–ä¸ªBWD->BWDã€BWD(éé¦–ä¸ª)->BWD(éé¦–ä¸ª)
                    #   è‹¥suc_vtæœ€åä¸€å±‚æ¥æ”¶dYçš„åª’ä»‹ä¸ä¸ºSWPï¼Œè¿”å›Noneï¼Œ
                    #   å¦åˆ™è¿”å› (l+1(suc_vtçš„æœ€åä¸€å±‚+1å³ä¸ºå½“å‰vtçš„é¦–å±‚)ï¼Œl+1è¿™å±‚æ¥æ”¶Xçš„å…ƒæ•°æ®)
                    swapin_localx_handler.prefetch_suc(sucinfo.localx())
                if self.nvprof: nvtx_range_pop() 

            ### Compute forward pass on GPU
            # 3.è‹¥å½“å‰æ˜¯BWDä»»åŠ¡è°ƒç”¨çš„FWDä»»åŠ¡ï¼Œå³é‡è®¡ç®—
            #   å¯ç”¨tensorçš„æ¢¯åº¦è®¡ç®—ï¼Œå¹¶è®¾ç½®ä¸ºä¿ç•™æ¢¯åº¦ã€‚è‹¥è¾“å…¥çš„tensoræ˜¯å¤ç”¨ä¹‹å‰çš„tensorï¼Œè¿˜éœ€è¿›è¡Œdetach_()ä»¥åŠæ¢¯åº¦æ¸…é›¶æ“ä½œ
            if requires_grad:
                # å¯ç”¨tensorçš„æ¢¯åº¦è®¡ç®—ï¼Œå¹¶è®¾ç½®ä¸ºä¿ç•™æ¢¯åº¦ã€‚è‹¥è¾“å…¥çš„tensoræ˜¯å¤ç”¨ä¹‹å‰çš„tensorï¼Œè¿˜éœ€è¿›è¡Œdetach_()ä»¥åŠæ¢¯åº¦æ¸…é›¶æ“ä½œ
                turn_on_X_grad(X_named_tensors) 
            if self.nvprof: nvtx_range_push("task{}({}) {}(#{})".format(vt.idx, vt.show_layers(), "FWD" if not requires_grad else "Recompute", ubatch_idx)) 
            # å½“å‰vtçš„è¾“å…¥tensor
            Y_tensors = [X_named_tensors[name] for name in X_names]

            # 4.Swap X: å¯¹vtä¸­çš„æ¯ä¸€å±‚è·‘ä¸€æ¬¡å‰å‘ï¼Œå¯¹vtä¸­çš„é¦–å±‚è¿˜éœ€è¿›è¡Œé¢å¤–çš„å¤„ç†ï¼Œå³swapæ‰å…¶è¾“å…¥Xï¼Œå¹¶ä¼ ç»™ç›®æ ‡rank
            for l in vt.layers:
                # è‹¥å½“å‰å±‚lï¼Œå…¶è¾“å…¥Xéœ€è¦swap outæ‰ï¼Œä¸”è¾“å‡ºXçš„åª’ä»‹ä¸ºMSGï¼Œåˆ™è°ƒç”¨SwapOutå®ä¾‹çš„çº¿ç¨‹ï¼Œå°†tensorå¸è½½åˆ°cpuçš„pinned memoryä¸Š
                # ğŸ“Œè¯¥swapoutçº¿ç¨‹è¿˜ä¼šè°ƒç”¨ MSGstashX çš„æ–¹æ³•ï¼Œè§¦å‘ MSGstashX å‘é€çº¿ç¨‹çš„è¿è¡Œï¼Œå³å°†swapoutçš„tensor å‘é€åˆ°ç›®æ ‡rankä¸Š
                if not requires_grad and l in vt.Out['X']: ### Out {stashX}
                    if self.nvprof: nvtx_range_push("task{}(L{}) SwapOut(#{}StashX)".format(vt.idx, l, ubatch_idx)) 
                    if vt.Out['X'][l].medium == "MSG": # message pass stashed X
                        # 1.è®°å½•ä¸€ä¸ªé»˜è®¤è®¡ç®—æµä¸Šçš„äº‹ä»¶ ev_compute
                        # 2.åœ¨swapout streamä¸Šç­‰å¾… ev_compute äº‹ä»¶å®Œæˆï¼Œå³ç¡®ä¿è®¡ç®—å®Œæˆåæ‰èƒ½swapout
                        # 3.åœ¨swapout_streamä¸Š:
                        #   3.1.åœ¨cpuä¸Šçš„pinned memoryä¸Šåˆ›å»ºä¸€ä¸ªç©ºtensor
                        #   3.2.å¼‚æ­¥çš„å°†gpuä¸Šçš„tensoræ‹·è´åˆ°åˆšåˆšåˆ†é…çš„ç©ºtensorä¸Š
                        #   è¿”å›cpu_named_tensors
                        # 4.å°† (layer_id, cpu_named_tensors, ev_swapout, flag) æ·»åŠ åˆ° put_queue é˜Ÿåˆ—ä¸­ã€‚ğŸ“Œè¿™æ„å‘³ç€å½“å‰å®ä¾‹çš„çº¿ç¨‹ä¼šå°†å·²ç»å¸è½½
                        #   åˆ°cpuä¸Šçš„tensoræ”¾åˆ° MSGstashX å®ä¾‹çš„ send_dict ä¸­ã€‚
                        #   ğŸ“Œè¿™ä¹Ÿæ„å‘³ç€ MSGstashX çš„å‘é€çº¿ç¨‹å°†å‘ dst_rank å‘é€æ­¤ tensor
                        swapout_stashx_handler.offload(l, 
                                make_tensors_named(self.local_model[l].X_names, Y_tensors))
                        # print("\trank{}: task{}(L{}) SwapOut(#{}StashX)".format(self.rank, vt.idx, l, ubatch_idx))
                    else:
                        raise NotImplementedError
                    if self.nvprof: nvtx_range_pop() 
                # print("\trank{}: task{}(L{}) {}".format(self.rank, vt.idx, l, "FWD" if not requires_grad else "Recompute"))
                # total_params = 0
                # total_memory_bytes = 0
                # for name, param in self.local_model[l].model.named_parameters():
                #     num_params = param.numel()
                #     dtype = param.dtype
                #     memory_bytes = num_params * param.element_size()
                    
                #     total_params += num_params
                #     total_memory_bytes += memory_bytes
                    
                #     # print(f"å‚æ•°åç§°: {name}, å‚æ•°é‡: {num_params}, æ•°æ®ç±»å‹: {dtype}, ç©ºé—´å ç”¨: {memory_bytes / (1024 ** 2):.6f} MB")
                # print(f"rank:{self.rank}, layer{l}, æ€»å‚æ•°é‡: {total_params}, æ€»ç©ºé—´å ç”¨: {total_memory_bytes / (1024 ** 2):.6f} MB\n")
                Y_tensors = self.local_model[l](*Y_tensors)
                if not isinstance(Y_tensors, tuple):
                    Y_tensors = (Y_tensors,)
                Y_tensors = list(Y_tensors)
            if self.verbose: print("\trank{}: task{}({}) {} (#{})".format(self.rank, vt.idx, vt.show_layers(), "FWD" if not requires_grad else "Recompute", ubatch_idx))
            if self.nvprof: nvtx_range_pop() 
            ### Save Y
            l = vt.layers[-1]
            Y_names = self.local_model[l].Y_names
            Y_named_tensors = make_tensors_named(Y_names, Y_tensors)

            # 5.è‹¥ä¸éœ€è¦æ¢¯åº¦ï¼Œå³å½“å‰ä¸æ˜¯BWDä¸­çš„é‡è®¡ç®—è¿‡ç¨‹ï¼Œéœ€è¦å¼‚æ­¥çš„å°†vtçš„è¾“å‡ºå‘é€åˆ°ç›®æ ‡rankä¸Š
            if not requires_grad:

                num_elements = Y_tensors[0].numel()
                element_size = Y_tensors[0].element_size()
                memory_usage = num_elements * element_size / (1024 ** 2)
                print(f"rank:{self.rank}, æ¿€æ´»çš„å‚æ•°é‡:{num_elements}, æ¿€æ´»çš„æ•°æ®ç±»å‹:{Y_tensors[0].dtype}, æ¿€æ´»çš„å†…å­˜å ç”¨: {memory_usage} mb")

                # print(f"rank:{self.rank}, vt:{vt.idx}({vt.show_layers()}), FWDå®Œæˆ, å‘é€çš„tensor:{Y_named_tensors} ({ubatch_idx})")

                ### Out {Y}
                m = vt.Out['Y'][l]
                # éé˜»å¡çš„å°† tensor å‘é€åˆ°ç›®æ ‡rankçš„GPUä¸Šï¼Œè¿”å›ä¸€ä¸ªå¼‚æ­¥workå¥æŸ„
                if m.medium == "P2P":
                    if self.nvprof: nvtx_range_push("task{}({}) P2POut(#{}Y)".format(vt.idx, vt.show_layers(), ubatch_idx)) 
                    self.p2px_handler.isend(Y_named_tensors, dst=m.rank)
                    # print("\trank{}: task{}({}) P2POut(#{}Y)".format(self.rank, vt.idx, vt.show_layers(), ubatch_idx))
                elif m.medium == "MSG": # last FWD convert to first BWD
                    if self.nvprof: nvtx_range_push("task{}({}) MSGOut(#{}Y)".format(vt.idx, vt.show_layers(), ubatch_idx)) 
                    swapout_msgx_handler.offload(l+1, Y_named_tensors)
                    # print("\trank{}: task{}({}) MSGOut(#{}Y)".format(self.rank, vt.idx, vt.show_layers(), ubatch_idx))
                elif m.medium == "SWP": # swap locally for vDP
                    if self.nvprof: nvtx_range_push("task{}({}) SwapOut(#{}Y)".format(vt.idx, vt.show_layers(), ubatch_idx)) 
                    if self.is_convert_ubs:
                        flag_is_convert = True if vt.is_last_fwd else False
                        swapout_localx_handler.offload(l+1, Y_named_tensors, flag_is_convert)
                    else:
                        swapout_localx_handler.offload(l+1, Y_named_tensors)
                    # print("\trank{}: swp_send'ed L{}-Y".format(self.rank, l))
                else:
                    raise NotImplementedError
                if self.nvprof: nvtx_range_pop() 
            ### Clean up
            if self.nvprof: nvtx_range_push("task{}({}) FWDClean(#{})".format(vt.idx, vt.show_layers(), ubatch_idx)) 
            # print("\trank{}: task{}({}) FWDClean(#{})".format(self.rank, vt.idx, vt.show_layers(), ubatch_idx))
            del Y_tensors
            # å¯¹FWDä»»åŠ¡ï¼Œæ— éœ€ä¿å­˜è¾“å…¥å’Œè¾“å‡º
            if not requires_grad:
                del X_named_tensors; del Y_named_tensors
            else: # for backward pass
                return X_named_tensors, Y_named_tensors

        # å¯¹äºåŒ…å«è®¡ç®—losså±‚çš„, æ­¤å¤„å®é™…ä¸Šæ˜¯åœ¨BWDçš„æ‰§è¡Œè¿‡ç¨‹ä¸­æ‰§è¡Œ,å³é¦–ä¸ªBWDä»»åŠ¡æ‰æ˜¯å®é™…ä¸Šçš„æœ€åä¸€ä¸ª
        # FWDä»»åŠ¡, è¦å…ˆæ‰§è¡ŒFWDäº§ç”Ÿä¸€ä¸ªloss
        else: # criterion pack
            assert requires_grad # fused forward and backward
            ### In {X}
            l, m = vt.layers[0], vt.In['X'][vt.layers[0]]
            X_names = self.local_model[l].X_names

            # 1.æ¥å—æ•´ä¸ªvtçš„è¾“å…¥Xï¼Œåˆ†å‡ ç§æƒ…å†µï¼š
            #   --æ•´ä¸ªæ¨¡å‹çš„ç¬¬ä¸€å±‚ï¼Œè¾“å…¥çš„å°±æ˜¯è¾“å…¥æ•°æ®microbatchï¼Œç›´æ¥å°†è¯¥microbatchå¤åˆ¶åˆ°GPUä¸Š
            #   --ä¸­é—´çš„vtï¼Œè¾“å…¥è‚¯å®šæ˜¯å‰é¢çš„vtè¾“å‡ºçš„ç»“æœï¼Œé€šè¿‡P2Pé€šä¿¡å¹¿æ’­è¿‡æ¥
            #   --...
            if m.medium == "DAT": # a single BWD task
                if self.nvprof: nvtx_range_push("task{}({}) SwapIn(#{}Data)".format(vt.idx, vt.show_layers(), ubatch_idx)) 
                X_named_tensors = swp_x.swapin(data_ubatches[ubatch_idx])
                # print("\trank{}: task{}({}) SwapIn(#{}Data)".format(self.rank, vt.idx, vt.show_layers(), ubatch_idx))
            elif m.medium == "P2P": # the same above
                if self.nvprof: nvtx_range_push("task{}({}) P2PIn(#{}X)".format(vt.idx, vt.show_layers(), ubatch_idx)) 
                if self.args.no_p2p_prerecv:
                    X_named_tensors = self.p2px_handler.recv(self.XMETA.get(ubatch_size,l), src=m.rank)
                else:
                    X_named_tensors = self.p2px_handler.prerecv(self.XMETA.get(ubatch_size,l), src=m.rank, is_end=is_last_ubatch) 
                # print("\trank{}: task{}({}) P2PIn(#{}X)".format(self.rank, vt.idx, vt.show_layers(), ubatch_idx))
            elif m.medium == "MSG": # last FWD convert to first BWD
                if self.nvprof: nvtx_range_push("task{}({}) MSGIn(#{}X)".format(vt.idx, vt.show_layers(), ubatch_idx)) 
                if self.args.no_prefetch_msgx:
                    X_named_tensors = swapin_msgx_handler.fetch(l, self.XMETA.get(ubatch_size,l))
                else:
                    X_named_tensors = swapin_msgx_handler.prefetch(l, self.XMETA.get(ubatch_size,l), is_last_ubatch)
                # print("\trank{}: task{}({}) MSGIn(#{}X)".format(self.rank, vt.idx, vt.show_layers(), ubatch_idx))
            elif m.medium == "SWP": # swap locally for vDP
                if self.nvprof: nvtx_range_push("task{}({}) SwapIn(#{}LocalX)".format(vt.idx, vt.show_layers(), ubatch_idx)) 
                if self.args.no_prefetch_localx:
                    X_named_tensors = swapin_localx_handler.fetch(l, self.XMETA.get(ubatch_size,l))
                else:
                    X_named_tensors = swapin_localx_handler.prefetch(l, self.XMETA.get(ubatch_size,l), is_last_ubatch)
                # print("\trank{}: swp_recv'ed L{}-X".format(self.rank, l))
            else:
                raise NotImplementedError
            if self.nvprof: nvtx_range_pop() 

            # print(f"rank:{self.rank}, vt:{vt.idx}({vt.show_layers()}), åœ¨æ‰§è¡Œloss vtä¹‹å‰, æ¥æ”¶åˆ°çš„è¾“å…¥ä¸º{X_named_tensors} ({ubatch_idx})")

            ### Prefetch point @ Recompute(criterion) ULast
            # 2.è‹¥å½“å‰æ‰§è¡Œåˆ°æœ€åä¸€ä¸ªmicro batchï¼Œä¸ºå½“å‰rankä¸Šä¸‹ä¸€ä¸ªvté¢„å–å…¶éœ€è¦çš„è¾“å…¥æ•°æ®
            # 2.1.ä¸ºåç»§vté¢„å– dY
            # 2.2.è‹¥è¯¥rankä¸Šçš„ä¸‹ä¸€ä¸ªä»»åŠ¡æ˜¯BWDä»»åŠ¡ï¼Œå°±æŠŠstashXæ‹¿è¿›æ¥ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨sucinfo.stashx()å‡½æ•°ä¸­ï¼Œè‹¥åç»§ä»»åŠ¡æ˜¯FWDä»»åŠ¡ï¼Œ
            #     ç›´æ¥è¿”å›Noneã€‚prefetch_sucå‡½æ•°åœ¨æ”¶åˆ°Noneåä¹Ÿä¼šç›´æ¥è¿”å›ï¼Œä¸åšä»»ä½•å¤„ç†
            if is_last_ubatch:
                if self.nvprof: nvtx_range_push("task{}({}) PrefetchPt".format(vt.idx, vt.show_layers() )) 
                
                # 2.1.ä¸ºåç»§vté¢„å– dY
                if self.p2px_handler is not None and \
                    not self.args.no_p2p_prerecv:
                    self.p2px_handler.prerecv_suc(sucinfo.p2pin())

                # è‹¥è¯¥rankä¸Šçš„ä¸‹ä¸€ä¸ªä»»åŠ¡æ˜¯BWDä»»åŠ¡ï¼Œè¿™ä¸ªå°±ä¼šæ‰§è¡Œï¼ŒæŠŠstashXæ‹¿è¿›æ¥
                if swapin_stashx_handler is not None and \
                    not self.args.no_prefetch_stashx:
                    # sucinfo.stashx()ï¼š
                    # è‹¥åç»§ä»»åŠ¡æ˜¯BWDï¼ˆéç¬¬ä¸€ä¸ªBWDï¼‰ï¼Œä¸”è¾“å…¥åª’ä»‹æ˜¯MSGï¼Œè¿”å› (l(åç»§ä»»åŠ¡çš„é¦–å±‚id), åçº§ä»»åŠ¡è¾“å…¥Xçš„å…ƒæ•°æ®) ã€‚éMSGç›´æ¥è¿”å›None
                    # å…¶ä»–æƒ…å†µç›´æ¥è¿”å›None
                    #
                    # åœ¨gpuä¸ŠæŒ‰ç…§sucinfo.stashx()è¿”å›çš„å…ƒæ•°æ®åœ¨gpuä¸Šç”Ÿæˆä¸€ä¸ªç©ºtensorï¼Œéšåå°†
                    # (suc_layer_id, cuda_named_tensors, ev_compute)æ·»åŠ åˆ° put_queue ä¸­ï¼Œ
                    # ğŸ“Œè¿™æ„å‘³ç€SwapInçº¿ç¨‹ä¼šå¼€å§‹cpuåˆ°gpuçš„æ‹·è´æ“ä½œ
                    swapin_stashx_handler.prefetch_suc(sucinfo.stashx())
                if self.nvprof: nvtx_range_pop() 

            ### Recompute on GPU
            # 3.å¯ç”¨tensorçš„æ¢¯åº¦è®¡ç®—ï¼Œå¹¶è®¾ç½®ä¸ºä¿ç•™æ¢¯åº¦ã€‚è‹¥è¾“å…¥çš„tensoræ˜¯å¤ç”¨ä¹‹å‰çš„tensorï¼Œè¿˜éœ€è¿›è¡Œdetach_()ä»¥åŠæ¢¯åº¦æ¸…é›¶æ“ä½œ
            turn_on_X_grad(X_named_tensors)
            if self.nvprof: nvtx_range_push("task{}({}) Recompute(#{})".format(vt.idx, vt.show_layers(), ubatch_idx)) 
           
            # 4.æ‰§è¡Œå‰å‘è®¡ç®—å¹¶ä¿ç•™è¾“å‡ºtensor
            if len(vt.layers) > 1: # packed
                Y_tensors = [X_named_tensors[name] for name in X_names]
                for l in vt.layers[:-1]:
                    Y_tensors = self.local_model[l](*Y_tensors)
                    if not isinstance(Y_tensors, tuple):
                        Y_tensors = (Y_tensors,)
                    Y_tensors = list(Y_tensors)
                Y_names = self.local_model[vt.layers[-2]].Y_names
                Y_named_tensors = make_tensors_named(Y_names, Y_tensors)
            else: # only last vlayer
                Y_names = X_names
                Y_named_tensors = X_named_tensors

            ### In {T}
            # 5.å°†target tensoræ‹¿åˆ°GPUä¸Š
            if self.nvprof: nvtx_range_push("task{}({}) SwapIn(#{}T)".format(vt.idx, vt.show_layers(), ubatch_idx)) 
            T_named_tensors = swp_x.swapin(target_ubatches[ubatch_idx])
            if self.nvprof: nvtx_range_pop() 
            
            ### Compute loss on GPU
            # 6.è®¡ç®—loss
            assert vt.layers[-1] == self.CONFIGS['R']-1
            last_vlayer = self.local_model[self.CONFIGS['R']-1]        
            if self.compute_loss is not None: # "bert_thomwolf", "gpt2_2bw", "gpt2_huggingface"
                Y_tensors = self.compute_loss(last_vlayer, Y_named_tensors, Y_names, T_named_tensors)
            else:
                Y_tensors = [last_vlayer(Y_named_tensors[name],T_named_tensors["target"]) for name in Y_names]
                Y_tensors = [sum(Y_tensors)]
            if self.verbose: print("\trank{}: task{}({}) Recompute(#{})".format(self.rank, vt.idx, vt.show_layers(), ubatch_idx))
            if self.nvprof: nvtx_range_pop() 
            
            ### Save Y
            # 7.ä¿å­˜loss
            Y_named_tensors = make_tensors_named(['loss'], Y_tensors)
            ### Clean up
            if self.nvprof: nvtx_range_push("task{}({}) FWDClean(#{})".format(vt.idx, vt.show_layers(), ubatch_idx)) 
            # print("\trank{}: task{}({}) FWDClean(#{})".format(self.rank, vt.idx, vt.show_layers(), ubatch_idx))
            del T_named_tensors; del Y_tensors; 
            return X_named_tensors, Y_named_tensors

    def _a_pack_backward_an_ubatch(self, vt, ubatch_idx, ubatch_size,
                                X_named_tensors, Y_named_tensors,
                                swapin_localx_handler=None,
                                swapout_localx_handler=None,
                                sucinfo=None,
                                iteration_num=None):
        is_last_ubatch = ubatch_idx == len(vt.ubatchszs) - 1
        ### In {dY}
        # 1.æ¥å—åä¸€ä¸ªBWDä»»åŠ¡å‘æ¥çš„dY
        # 1.1.å¯¹é¦–ä¸ªBWDä»»åŠ¡,æ˜¾ç„¶ä¸éœ€è¦
        if vt.has_criterion:
            dY_named_tensors = ODict({ 'loss': None })
            assert Y_named_tensors['loss'].requires_grad

        # 1.2.éç¬¬ä¸€ä¸ªBWDä»»åŠ¡ï¼Œé¡»æ¥æ”¶å‰ä¸€ä¸ªBWDä»»åŠ¡å‘æ¥çš„dY
        else:
            l, m = vt.layers[-1], vt.In['dY'][vt.layers[-1]]
            # è¿”å›å½“å‰vtè¾“å‡ºXçš„å…ƒæ•°æ®
            dY_named_metas = make_dY_named_metas(self.XMETA, ubatch_size, l)
            # åŒæ­¥çš„æ¥æ”¶å‘æ¥çš„ dYï¼ˆå¼‚æ­¥æ¥æ”¶ï¼Œä½†ä¼šé˜»å¡è‡³æ¥æ”¶å®Œæ¯•ï¼‰ï¼Œéç¬¬ä¸€ä¸ªBWDä»»åŠ¡ï¼Œæ¥æ”¶dYçš„æ­¥éª¤åœ¨ä¸Šä¸€ä¸ªvtå·²ç»æ‰§è¡Œ
            if m.medium == "P2P":
                if self.nvprof: nvtx_range_push("task{}({}) P2PIn(#{}dY)".format(vt.idx, vt.show_layers(), ubatch_idx)) 
                if self.args.no_p2p_prerecv:
                    dY_named_tensors = self.p2px_handler.recv(dY_named_metas, src=m.rank)
                else:
                    now = datetime.datetime.now()
                    print(f"rank:{self.rank}, vt{vt.idx}({vt.show_layers()})({ubatch_idx})æ¥æ”¶æ—¶é—´:{now.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]}")
                    dY_named_tensors = self.p2px_handler.prerecv(dY_named_metas, src=m.rank, is_end=is_last_ubatch) 
                # print("\trank{}: task{}({}) P2PIn(#{}dY)".format(self.rank, vt.idx, vt.show_layers(), ubatch_idx))
            elif m.medium == "SWP": # swap locally for vDP
                if self.nvprof: nvtx_range_push("task{}({}) SwapIn(#{}dY)".format(vt.idx, vt.show_layers(), ubatch_idx)) 
                if self.args.no_prefetch_localx:
                    dY_named_tensors = swapin_localx_handler.fetch(l+1, dY_named_metas)
                else:
                    dY_named_tensors = swapin_localx_handler.prefetch(l+1, dY_named_metas, is_last_ubatch)
                # print("\trank{}: swp_recv'ed L{}-dY".format(self.rank, l))
            else:
                raise NotImplementedError
            if self.nvprof: nvtx_range_pop()         

        # print(f"rank:{self.rank}, vt:{vt.idx}({vt.show_layers()})({vt.type}), æ¥å—çš„dYä¸º:{dY_named_tensors} (it:{iteration_num})({ubatch_idx})")
       
        ### Prefetch point @ BWD's ULast
        # è‹¥å½“å‰æ˜¯æœ€åä¸€ä¸ªmicro batchï¼Œä¸”å½“å‰ä¸æ˜¯ç¬¬ä¸€ä¸ªBWDä»»åŠ¡ï¼Œåˆ™ä¸ºåç»§BWDä»»åŠ¡ é¢„æ¥æ”¶dYã€‚ä»…ä»…æ˜¯å¼€å§‹æ¥æ”¶ï¼Œè¦å‘é€çš„dXè¿˜æ²¡ç®—å‡ºæ¥å‘¢
        if is_last_ubatch:
            if self.nvprof: nvtx_range_push("task{}({}) PrefetchPt".format(vt.idx, vt.show_layers() )) 
            # è‹¥å½“å‰ä¸æ˜¯ç¬¬ä¸€ä¸ªBWDä»»åŠ¡ï¼Œ
            if self.p2px_handler is not None and \
                not self.args.no_p2p_prerecv and not vt.has_criterion:
                # sucinfo.p2pin()ï¼šè‹¥åç»§BWDä»»åŠ¡æ¥æ”¶dYçš„åª’ä»‹ä¸ºP2Pï¼Œè¿”å›å½“å‰ä»»åŠ¡è¾“å…¥Xçš„å…ƒæ•°æ®ä½œä¸ºåç»§BWDä»»åŠ¡è¾“å…¥dYçš„å…ƒæ•°æ®ï¼Œç”¨äºprerecv_sucæ–¹æ³•
                # è¿”å› ( { name:TensorMeta }, æ¥æºrank )
                # æå‰ä½¿ç”¨P2Pæ–¹æ³•æ¥æ”¶åç»§BWDä»»åŠ¡çš„è¾“å…¥dY
                self.p2px_handler.prerecv_suc(sucinfo.p2pin())
            if swapin_localx_handler is not None and \
                not self.args.no_prefetch_localx:
                swapin_localx_handler.prefetch_suc(sucinfo.localx())
            if self.nvprof: nvtx_range_pop() 

        ### Compute backward pass
        # 3.æ‰§è¡Œåå‘ä¼ æ’­ï¼Œè®¡ç®—æ¢¯åº¦
        if self.nvprof: nvtx_range_push("task{}({}) BWD(#{})".format(vt.idx, vt.show_layers(), ubatch_idx)) 
        Y_tensors = []
        Y_gradients = [] 
        for name in self.local_model[vt.layers[-1]].Y_names: # only tensor & required_grad can run autograd
            Y = Y_named_tensors[name]
            # print(f"rank:{self.rank}, Y.grad:{Y.grad}")
            if isinstance(Y,(torch.Tensor, Variable)) and (Y.requires_grad):
                Y_tensors.append(Y)
                Y_gradients.append(dY_named_tensors[name])
            elif isinstance(Y, list): # output tuple of bert pretrainheader
                for i, y in enumerate(Y):
                    if isinstance(y,(torch.Tensor, Variable)) and (y.requires_grad):
                        Y_tensors.append(y)
                        Y_gradients.append(dY_named_tensors[name][i])
        #
        # print(f"rank:{self.rank}, åå‘å‰:Y.grad:{Y_named_tensors[self.local_model[vt.layers[-1]].Y_names[0]].grad}")
        torch.autograd.backward(tuple(Y_tensors), grad_tensors=tuple(Y_gradients))
        # print(f"rank:{self.rank}, åå‘å:Y.grad:{Y_named_tensors[self.local_model[vt.layers[-1]].Y_names[0]].grad}")
        if self.verbose: print("\trank{}: task{}({}) BWD(#{},{})".format(self.rank, vt.idx, vt.show_layers(), ubatch_idx, ubatch_size))
        if self.nvprof: nvtx_range_pop() 

        ### Out {dX}
        # 4.è‹¥å½“å‰ä»»åŠ¡éœ€è¦è¾“å‡ºdXï¼ˆæ˜¾ç„¶æœ€åä¸€ä¸ªBWDä»»åŠ¡ä¸éœ€è¦ï¼‰ï¼Œå–å‡ºè¾“å…¥Xçš„grad tensor(dX)ï¼Œä½¿ç”¨å¼‚æ­¥é€šä¿¡å°†dXç‚¹å¯¹ç‚¹çš„å‘é€åˆ°ç›®æ ‡rankä¸Š
        if vt.Out['dX']:
            ### Save dX
            # å–å‡ºç»™å®štensorçš„grad tensorï¼Œè£…åœ¨named_tensorå­—å…¸ä¸­è¿”å›ï¼Œä½¿ç”¨å¼‚æ­¥é€šä¿¡å°†dXç‚¹å¯¹ç‚¹çš„å‘é€åˆ°ç›®æ ‡rankä¸Š
            dX_named_tensors = make_dX_from_X(X_named_tensors) # ref to .grad

            # for name,tensor in dX_named_tensors.items():
            #     num_elements = tensor.numel()
            #     element_size = tensor.element_size()
            #     memory_usage = num_elements * element_size / (1024 ** 2)
            #     print(f"rank:{self.rank}, BWDæ¿€æ´»çš„å‚æ•°é‡:{num_elements}, æ¿€æ´»çš„æ•°æ®ç±»å‹:{tensor.dtype}, æ¿€æ´»çš„å†…å­˜å ç”¨: {memory_usage} mb")

            l, m = vt.layers[0], vt.Out['dX'][vt.layers[0]] 
            if m.medium == "P2P":
                if self.nvprof: nvtx_range_push("task{}({}) P2POut(#{}dX)".format(vt.idx, vt.show_layers(), ubatch_idx)) 
                now = datetime.datetime.now()
                print(f"rank:{self.rank}, vt{vt.idx}({vt.show_layers()})({ubatch_idx})å‘é€æ—¶é—´:{now.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]}")
                self.p2px_handler.isend(dX_named_tensors, dst=m.rank)
                # print("\trank{}: task{}({}) P2POut(#{}dX)".format(self.rank, vt.idx, vt.show_layers(), ubatch_idx))
            elif m.medium == "SWP": # swap locally for vDP
                if self.nvprof: nvtx_range_push("task{}({}) SwapOut(#{}dX)".format(vt.idx, vt.show_layers(), ubatch_idx)) 
                if self.is_convert_ubs:
                    swapout_localx_handler.offload(l, dX_named_tensors, False)
                else:
                    swapout_localx_handler.offload(l, dX_named_tensors)
                # print("\trank{}: swp_send'ed L{}-dX".format(self.rank,l))
            else:
                raise NotImplementedError
            del dX_named_tensors; 
            if self.nvprof: nvtx_range_pop() 
        ### Clean up {X,Y,dX,dY}
        if self.nvprof: nvtx_range_push("task{}({}) BWDClean(#{})".format(vt.idx, vt.show_layers(), ubatch_idx)) 
        # print("\trank{}: task{}({}) BWDClean(#{})".format(self.rank, vt.idx, vt.show_layers(), ubatch_idx))
        del X_named_tensors; del Y_named_tensors
        del dY_named_tensors; del Y_tensors; del Y_gradients

    # 
    def run_training_loop(self):
        local_losses = [] # per-minibatch
        global_losses = [] # per-minibatch
        if self.args.no_update: 
            grad_sums = [] # per-minibatch
        self.update_cnt = 0
        self.time_iters = []

        self.delete_time = []
        self.get_time = []
        self.swapout_time = []
        self.gc_time = []
        self.compute_time = []
        self.update_time = []
        self.offload_time = []

        # num_itersï¼šä¸€ä¸ªepochè¿­ä»£ï¼ˆiterationï¼‰çš„æ¬¡æ•°ï¼Œæ‰‹åŠ¨è®¾ç½®æˆ–dataloader minibatchçš„æ•°é‡
        # num_epochsï¼šepochçš„æ•°é‡ï¼Œæ‰‹åŠ¨è®¾ç½®
        # å³æ•´ä¸ªè¿­ä»£æ¬¡æ•°çš„ä¸€åŠ
        self.avg_it = int(self.args.num_iters * self.args.num_epochs /2.) # from this iter to average time
        
        ### clean memory before start
        # torch.cuda.synchronize(self.rank)ï¼šç­‰å¾…å½“å‰GPUä¸Šæ‰€æœ‰çš„æ ¸å‡½æ•°æ‰§è¡Œå®Œæ¯•
        torch.cuda.synchronize(self.rank); dist.barrier()
        gc.collect(); torch.cuda.empty_cache() 
        torch.cuda.synchronize(self.rank)
        assert torch.cuda.memory_reserved(self.rank)==0
        self.cgm = CheckGPUMem(self.rank)
        dist.barrier()
        print("rank%d: --- training starts ---" % self.rank)
        
        ### start
        self.rand_state_train.set()
        for epoch in range(self.args.num_epochs): # traverse epoches
            for it, minibatch in enumerate(self.data_loader): # traverse each minibatch
                if it >= self.args.num_iters:
                    break
                ### clean start
                gc.collect() 
                # è¯¥å‚æ•°é»˜è®¤ä¸º false
                if self.args.empty_cache: torch.cuda.empty_cache() 
                torch.cuda.synchronize(self.rank)
                assert torch.cuda.memory_allocated(self.rank)==0, "iteration with rank = {} begins w/ alloc = {} B".format(self.rank, torch.cuda.memory_allocated(self.rank)) 
                dist.barrier()
                if self.nvprof and it == self.args.nvprof_iter["start"]:
                    probe_cuda_mem = ProbeCudaMem(self.rank)
                    probe_cuda_mem.start()  
                    cuda_profiler.start()
                    nvtx_mark("cudaProfilerStart") 
                    print("rank%d: cuda profiler starts"%self.rank)
                else:
                    # é‡ç½®CUDAè®¾å¤‡ä¸Šçš„å†…å­˜å³°å€¼ç»Ÿè®¡ä¿¡æ¯
                    torch.cuda.reset_peak_memory_stats(self.rank) 
                time_start = pc() 
                ### data minibatch
                # è¯¥å‚æ•°é»˜è®¤ä¸ºfalseï¼Œæ‰§è¡Œelse
                if self.args.synthetic_data:
                    data_ubatches, target_ubatches = self.data_ubatches, self.target_ubatches
                else:
                    # åœ¨gpt2ä¸­ï¼Œè¿™ä¸ªå‚æ•°ä¸ºtrueï¼ŒğŸ“Œç°åœ¨minibatchæ˜¯ä¸€ä¸ªæœ‰ä¸¤ä¸ªå…ƒç´ çš„å…ƒç»„ï¼Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯è‡ªå·±çš„å¤åˆ¶
                    #
                    # 1.å¤åˆ¶ä¸€ä»½minibatchï¼Œå°†ä¸¤ä¸ªminibatchæ”¾è¿›å…ƒç»„é‡Œï¼Œç¬¬ä¸€ä¸ªminibatchæ˜¯å‰å‘ç”¨çš„minibatchï¼Œç¬¬äºŒä¸ª
                    #   minibatchæ˜¯åå‘ç”¨çš„minibatchï¼Œä¸¤è€…å°†æŒ‰ç…§å‰åå‘ä¸åŒçš„microbatchsizeè¿›è¡Œåˆ‡åˆ†ï¼Œåˆ‡åˆ†æˆmicrobatch
                    if self.is_copy_minibatch: # "gpt2_huggingface"
                        minibatch = (minibatch, deepcopy(minibatch))

                    # 2.å¿½ç•¥sampleæ•°é‡ä¸å¤Ÿå’Œsampleç»´åº¦ä¸å¯¹çš„minibatchï¼Œç›´æ¥è·³è¿‡æ­¤æ¬¡å¾ªç¯
                    # è‹¥å½“å‰minibatchçš„ç¬¬0ç»´æ•°é‡å’Œå®šä¹‰çš„Minibatchsizeå¤§å°ä¸åŒï¼Œè¿”å›Trueï¼Œå³sampleçš„æ•°é‡ä¸å¯¹ã€‚æœ€åä¸€ä¸ªminibatchå¯èƒ½æ•°é‡ä¸å¤Ÿ
                    # è‹¥minibatchç¬¬1ç»´æ•°é‡å’Œdefined_seq_lenä¸åŒï¼Œè¿”å›True
                    if self.is_skip_minibatch(minibatch, self.CONFIGS['D'], self.fdim, verbose=self.verbose): # skip fractional minibatch
                        assert (not self.nvprof) or (self.nvprof and it != self.args.nvprof_iter["end"]), "Unstoped Profiling"
                        continue
                    # preprocess_minibatch å‡½æ•°å®é™…ä¸Šä¸åšä»»ä½•äº‹æƒ…
                    minibatch = self.preprocess_minibatch(minibatch) # preprocess as if single GPU

                    # self.bnamesï¼š{"is_data" = [True, False]ï¼Œ "name" = ["input0", "labels"]}
                    # self.ubatchszs_fwd_localï¼šfwd minibatchsizeçš„åˆ—è¡¨
                    # self.ubatchszs_bwd_localï¼šbwd minibatchsizeçš„åˆ—è¡¨
                    #
                    # 3.å°†ä¼ è¿›æ¥çš„ä¸¤ä¸ªç›¸åŒçš„minibatchåˆ†åˆ«æŒ‰ç…§å‰å‘microbatch sizeåˆ—è¡¨å’Œåå‘Microbatchåˆ—è¡¨è¿›è¡Œæ‹†åˆ†ï¼Œæ‹†åˆ†æˆmicorbatchã€‚
                    #   è¿”å›å‰å‘å’Œåå‘çš„microbatch tensoråˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªnamed_tensorå­—å…¸
                    data_ubatches, target_ubatches = decompose_minibatch(minibatch, self.bnames, self.ubatchszs_fwd_local, self.ubatchszs_bwd_local, self.XMETA, self.TMETA, self.CONFIGS, self.rank, pin_memory=not self.args.no_pin_data) # make microbatches
                    # print(f"data_ubatches:{data_ubatches}")
                ### task starts    
                # å¯¹å½“å‰rankçš„æ¯ä¸€ä¸ªvt
                if self.nvprof: nvtx_range_push("rank{}, iteration:{}".format(self.rank,it))
                delete_time = []
                get_time = []
                swapout_time = []
                gc_time = []
                compute_time = []
                update_time = []
                offload_time = []
                for j, vt in enumerate(self.rTASKS[self.rank]): # { rank0: [task0,task2,...] }
                    if self.verbose: print("\trank{}: executing {}".format(self.rank, vt))
                    # è®¾ç½® SucInfoForPrefetch å®ä¾‹çš„ self.vt = vtï¼›self.rank_vt_idx = rank_vt_idx
                    self.sucinfo.set(vt, j)
                    if self.nvprof: nvtx_range_push("task{}({})({})".format(vt.idx, vt.show_layers(), vt.type)) 
                    if vt.type == 'FWD' and vt.is_gpu:
                        # -----------------------------------------------      
                        with torch.no_grad():
                            ### Swap-in model {W,B}
                            if self.nvprof: nvtx_range_push("task{}({}) SwapIn(W,B)".format(vt.idx, vt.show_layers())) 
                            if self.verbose: print_gpu_mem(self.rank, vt, "SwapIn(W,B) start")
                            # no_prefetch_modelï¼šè¯¥å‚æ•°é»˜è®¤ä¸ºfalseï¼Œæ‰§è¡Œelse
                            # è¿”å›åç»­ä»»åŠ¡ï¼ˆFWDæˆ–BWDä»»åŠ¡ï¼‰ï¼Œå³å½“å‰rankä¸Šç¬¬j+1æˆ–j+2ä¸ªä»»åŠ¡
                            suc_vt = None if self.args.no_prefetch_model else self.sucinfo.model()

                            # 1.å°†vtä¸­æ‰€æœ‰layerçš„Wå’ŒBå¤åˆ¶GPU(çš„layer)ä¸Šï¼ˆGPUä¹Ÿæœ‰ä¸€ä»½æ‰€æœ‰çš„layerï¼Œä½†ä¸€å¼€å§‹éƒ½æ˜¯ç©ºçš„ï¼‰
                            # 1.1.å‡†å¤‡å·¥ä½œ1ï¼šè°ƒç”¨syncpin_handlerå®ä¾‹çš„çº¿ç¨‹å°†vtä¸­çš„è¿™äº›åœ¨cpuå…±äº«å†…å­˜ä¸­çš„layerå¤åˆ¶åˆ°pinned memoryä¸Šï¼›
                            # 1.2.å‡†å¤‡å·¥ä½œ2ï¼šåœ¨é»˜è®¤è®¡ç®—æµä¸Šï¼ŒæŒ‰ç…§Pinned memoryä¸­layerçš„W,Bçš„å¤§å°ã€ç±»å‹ï¼Œä¸ºç»™å®švtåœ¨GPU(çš„å¯¹åº”å±‚)ä¸Šçš„æ‰€æœ‰layeråˆå§‹åŒ–Wå’ŒBï¼ˆå€¼æ˜¯éšæœºçš„ï¼‰
                            #   åŒæ—¶ä¹Ÿæ˜¯å½“å‰PrefetchLocalModelGPUå®ä¾‹çš„çº¿ç¨‹çš„è§¦å‘å·¥ä½œï¼Œå°†ä¸œè¥¿æ”¾è¿›put_queueï¼Œè¿™æ„å‘³ç€çº¿ç¨‹å¼€å§‹æ‰§è¡Œ3
                            # 1.3.åœ¨ swapin_stream ä¸­å°†Wå’ŒBä»cpu memoryï¼ˆé»˜è®¤åœ¨å›ºå®šå†…å­˜ä¸Šï¼‰ä¸Šæ‹·è´åˆ°gpuçš„modelä¸Šï¼Œè‹¥vtçš„ç±»å‹ä¸ºBWDï¼Œè¿˜éœ€è¦
                            #   æ˜¾ç¤ºçš„è®¾ç½®å‚æ•° param çš„ requires_grad å±æ€§ä¸º True
                            # 1.4.è°ƒç”¨_waitå°†is_running ç½®ä¸ºfalseï¼Œè¿”å›get_queue çš„é¦–ä¸ª (vt.idxï¼Œev_swapin)
                            # 1.5.self.compute_stream.wait_event(ev_swapin)
                            # 1.6.è‹¥suc_vtå‚æ•°ä¸ä¸ºç©ºï¼Œæ„å‘³ç€è¯¥å‡½æ•°ä¼šä¸ºæå‰æ‰§è¡Œä¸€éƒ¨åˆ†åç»§ä»»åŠ¡ï¼Œå³è°ƒç”¨self.syncpin_handler.iput(suc_vt)ï¼Œä¸1.1ç›¸åŒ
                            start_time = time.time()
                            cur_vt_idx = self.prefetch_model_handler.get(vt, suc_vt)
                            end_time = time.time()
                            execution_time = end_time - start_time
                            print(f"rank{self.rank}, vt.idx:{vt.idx}, {vt.type}, å–æ¨¡å‹æ‰§è¡Œäº†:{execution_time:.6f}ç§’")
                            get_time.append(execution_time)
                            assert cur_vt_idx == vt.idx
                            if self.verbose: print_gpu_mem(self.rank, vt, "SwapIn(W,B) end")
                            if self.nvprof: nvtx_range_pop() 
                            ### Run through each microbatch in a data batch
                            # 2.æœ‰å¤šå°‘ä¸ªmicrobatchå°±è·‘å¤šå°‘æ¬¡å‰å‘
                            #   ä»å‡½æ•°çš„è¿è¡Œç»“æœæ¥çœ‹, å°±æ˜¯ä¸æ–­çš„å‘ç›®æ ‡rankå‘é€è®¡ç®—å‡ºæ¥çš„Y
                            for i, u in enumerate(vt.ubatchszs):
                                start_time = time.time()
                                self._a_pack_forward_an_ubatch(vt, i, u,
                                        data_ubatches, target_ubatches, 
                                        requires_grad=False, 
                                        prefetch_model_handler=self.prefetch_model_handler,
                                        swapin_stashx_handler=self.swapin_stashx_handler,# æ–°å»ºä¸€ä¸ªswapin_streamï¼Œä¸“é—¨ç”¨æ¥ swap in stashX
                                        swapin_localx_handler=self.swapin_localx_handler,
                                        swapin_msgx_handler=self.swapin_msgx_handler,
                                        swapout_stashx_handler=self.swapout_stashx_handler,
                                        swapout_localx_handler=self.swapout_localx_handler,
                                        swapout_msgx_handler=self.swapout_msgx_handler,
                                        sucinfo=self.sucinfo)
                                end_time = time.time()
                                execution_time = end_time - start_time
                                print(f"rank{self.rank}, vt.idx:{vt.idx}, {vt.type}, microbatch{i}, å‰å‘æ‰§è¡Œäº†:{execution_time:.6f}ç§’")
                                compute_time.append(execution_time)
                                if self.verbose: print_gpu_mem(self.rank, vt, "End(#%d)" % i)
                                if self.nvprof: nvtx_range_pop() 
                                start_time = time.time()
                                gc.collect()
                                end_time = time.time()
                                execution_time = end_time - start_time
                                print(f"rank{self.rank}, vt.idx:{vt.idx}, {vt.type}, microbatch{i}, gc.collectæ‰§è¡Œäº†:{execution_time:.6f}ç§’")
                                gc_time.append(execution_time)
                            ### Prefetch point @ FWD Del
                            # 3.é˜»å¡ï¼Œç›´åˆ°è¯¥æµä¸­çš„ä»»åŠ¡å…¨éƒ¨å®Œæˆ
                            self.default_stream.synchronize() # CPU wait Compute
                            if self.nvprof: nvtx_range_push("task{}({}) PrefetchPt".format(vt.idx, vt.show_layers() )) 
                            # è¯¥å‚æ•°é»˜è®¤ä¸ºfalseï¼Œæ‰§è¡Œ
                            # 4.é¢„å–suc_vtçš„æ¨¡å‹ï¼Œå°†å…¶Wå’ŒBæ‹¿åˆ°GPUä¸Š
                            if not self.args.no_prefetch_model:
                                # inputï¼šå³æŠŠvtçš„æ‰€æœ‰layerçš„Wå’ŒB input åˆ°GPUä¸Š
                                # åˆ†æï¼šæ²¡æœ‰æŒ‡å®šæµï¼Œæ•´ä¸ªè¿‡ç¨‹åº”æ˜¯åœ¨é»˜è®¤æµä¸Šæ‰§è¡Œ
                                # 1.æ–­è¨€å½“å‰æ²¡æœ‰å…¶ä»–çš„ iput æ“ä½œæ­£åœ¨æ‰§è¡Œï¼Œç¡®ä¿åªæœ‰ä¸€ä¸ª iput æ“ä½œå¯ä»¥è¿›è¡Œ
                                # 2.åœ¨é»˜è®¤æµä¸Šè®°å½•ä¸€ä¸ªäº‹ä»¶ï¼ˆåˆ†é…ä¸€ä¸ªæ–°çš„eventï¼‰ï¼Œå³ev_computeï¼Œç”¨äºåç»­åœ¨ swapin æµä¸Šç­‰å¾…
                                # 3.è‹¥ç»™å®švtä¸Šçš„æ‰€æœ‰layerçš„Wå’ŒBçš„åª’ä»‹ä¸ºSHMï¼Œåˆ™æŒ‰ç…§cpuä¸Šå‚æ•°å’Œbufferçš„å¤§å°å’Œç±»å‹ï¼Œä¸ºgpuä¸Šçš„dataåˆ†é…ä¸€ä¸ªå¤§å°å’Œç±»å‹ç›¸åŒçš„ç©ºtensor
                                # 4.å°†(vt, ev_compute)æ·»åŠ åˆ° put_queue ä¸­ï¼ŒğŸ“Œè¿™ä¹Ÿæ„å‘³ç€è¯¥å‡½æ•°æ‰€åœ¨å®ä¾‹(PrefetchLocalModelGPU)çš„çº¿ç¨‹å°†å¼€å§‹æ‰§è¡Œswap in
                                self.prefetch_model_handler.iput(suc_vt)

                            # åœ¨P2Pæƒ…å†µä¸‹ï¼Œè¿™ä¸ªåº”è¯¥ä¸æ‰§è¡Œ
                            # ğŸ“Œ24/10/10ï¼šå®é™…ä¸Šå°±æ˜¯ç»™vPPå‡†å¤‡çš„ã€‚æœ€åä¸€ä¸ªFWDvtâ†’ç¬¬ä¸€ä¸ªBWDvtåœ¨å‰åå‘microbatchå¤§å°ä¸ä¸€è‡´æ—¶ï¼Œé€šä¿¡åª’ä»‹è¢«è‡ªåŠ¨è®¾ç½®ä¸ºMSG
                            #   æ­¤æ—¶è¿™é‡Œå°±ä¼šæ‰§è¡Œ
                            if self.swapin_msgx_handler is not None and not self.args.no_prefetch_msgx:
                                # self.sucinfo.msgx()ï¼š
                                # è‹¥å½“å‰vtå’Œåç»§vtçš„æƒ…å†µä¸ºï¼šFWD -> é¦–ä¸ªBWDï¼Œä¸”suc_vtçš„è¾“å…¥Xçš„åª’ä»‹ä¸ºMSGï¼Œè¿”å›suc_vté¦–å±‚çš„å±‚å·ã€è¾“å…¥Xçš„å…ƒæ•°æ®
                                #
                                # 
                                self.swapin_msgx_handler.prefetch_suc(self.sucinfo.msgx())
                            # if self.swapin_stashx_handler is not None and not self.args.no_prefetch_stashx:
                            #     self.swapin_stashx_handler.prefetch_suc(self.sucinfo.stashx())
                            if self.nvprof: nvtx_range_pop() 
                            ### Delete model {W,B}
                            if self.nvprof: nvtx_range_push("task{}({}) Del(W,B)".format(vt.idx, vt.show_layers())) 
                            start_time = time.time()
                            for l in vt.layers:
                                # è‹¥ä¸éœ€è¦è¾“å‡ºWå’ŒBï¼Œé€’å½’åœ°åˆ é™¤æ¨¡å—ï¼ˆåŒ…æ‹¬å­æ¨¡å—ï¼‰ä¸­çš„æ‰€æœ‰å‚æ•°ã€æ¢¯åº¦å’Œç¼“å†²åŒº
                                # å¤§éƒ¨åˆ†å‰å‘ä»»åŠ¡éƒ½ä¸éœ€è¦è¾“å‡ºWå’ŒB
                                if not (l in vt.Out['W']) and not (l in vt.Out['B']):
                                    self.local_model[l].del_param_grad_buf()
                                # è‹¥Wå’ŒBçš„è¾“å‡ºåª’ä»‹ä¸ºPINï¼Œå³BWDä»»åŠ¡ä¹Ÿåœ¨å½“å‰rankä¸Šï¼ŒWå’ŒBéœ€è¦ä¿å­˜åœ¨GPUä¸Šï¼Œé¿å…å†æ¬¡æ‹¿å–
                                elif vt.Out['W'][l].medium=='PIN' and vt.Out['B'][l].medium=='PIN':
                                    pass
                                else: # P2P
                                    raise NotImplementedError
                            end_time = time.time()
                            execution_time = end_time - start_time
                            delete_time.append(execution_time)
                            print(f"rank{self.rank}, vt.idx:{vt.idx}, {vt.type}, åˆ é™¤æ‰§è¡Œäº†:{execution_time:.6f}ç§’")
                            start_time = time.time()
                            gc.collect()
                            end_time = time.time()
                            execution_time = end_time - start_time
                            print(f"rank{self.rank}, vt.idx:{vt.idx}, {vt.type}, gc.collectæ‰§è¡Œäº†:{execution_time:.6f}ç§’")
                            gc_time.append(execution_time)
                            if self.verbose: print_gpu_mem(self.rank, vt, "Deleted(W,B)")
                            if self.nvprof: nvtx_range_pop() 
                        # -----------------------------------------------
                    elif vt.type == 'BWD' and vt.is_gpu:
                        # -----------------------------------------------
                        ### Swap-in model {W,B}
                        if self.nvprof: nvtx_range_push("task{}({}) SwapIn(W,B)".format(vt.idx, vt.show_layers())) 
                        if self.verbose: print_gpu_mem(self.rank, vt, "SwapIn(W,B) start")
                        # è¯¥å‚æ•°ä¸ºfalseï¼Œæ‰§è¡Œelse
                        # è¿”å›åç»­ä»»åŠ¡ï¼ˆFWDæˆ–BWDä»»åŠ¡ï¼‰ï¼Œå³å½“å‰rankä¸Šç¬¬j+1æˆ–j+2ä¸ªä»»åŠ¡
                        suc_vt = None if self.args.no_prefetch_model else self.sucinfo.model()

                        # 1.æ‹¿å–æ¨¡å‹Wå’ŒBè‡³GPU
                        # ç­‰å¾…å½“å‰vtçš„Wå’ŒBçš„é¢„å–äº‹ä»¶çš„å®Œæˆï¼ŒåŒæ—¶å¼€å§‹suc_vtçš„éƒ¨åˆ†ä»»åŠ¡ï¼Œå³å…±äº«å†…å­˜åˆ°å›ºå®šå†…å­˜çš„æ¨¡å‹å¤åˆ¶
                        # æ‹¿å–get_queueï¼ˆé€»è¾‘ä¸Šå®Œæˆé¢„å–çš„ä»»åŠ¡é˜Ÿåˆ—ï¼‰ä¸­çš„é¦–ä¸ªå…ƒç´ ï¼Œå³ç­‰å¾…ä¸€ä¸ªä¹‹å‰å°±è§¦å‘çš„é¢„å–æ¨¡å‹ï¼ˆswapinï¼‰äº‹ä»¶å®Œæˆã€‚
                        # æ‹¿å–åªä»£è¡¨é€»è¾‘ä¸Šæ‰§è¡Œå®Œï¼Œå®é™…ä¸Šå¯èƒ½æ²¡æ‰§è¡Œå®Œï¼Œå› æ­¤éœ€è¦ç­‰å¾…äº‹ä»¶çš„å®Œæˆã€‚æœ€åè¿”å›æ‹¿å–å®Œæˆçš„é¦–ä¸ªå…ƒç´ ä¸­çš„vt_idx 
                        start_time = time.time()
                        cur_vt_idx = self.prefetch_model_handler.get(vt, suc_vt)
                        end_time = time.time()
                        execution_time = end_time - start_time
                        print(f"rank{self.rank}, vt.idx:{vt.idx}, {vt.type}, å–æ¨¡å‹æ‰§è¡Œäº†:{execution_time:.6f}ç§’")
                        get_time.append(execution_time)
                        # ç¡®ä¿ä¹‹å‰é¢„å–æ¨¡å‹çš„vtå°±æ˜¯å½“å‰æ­£åœ¨æ‰§è¡Œçš„vt
                        assert cur_vt_idx == vt.idx
                        if self.verbose: print_gpu_mem(self.rank, vt, "SwapIn(W,B) end")
                        if self.nvprof: nvtx_range_pop() 

                        ### Run through each microbatch in a data batch. 
                        # 2.å¯¹æ¯ä¸ªmicrobatchæ‰§è¡Œä¸€æ¬¡å‰å‘å¾—åˆ°è¾“å‡ºç»“æœï¼Œå†å¯¹è¾“å‡ºç»“æœè¿›è¡Œåå‘ä¼ æ’­ã€‚è‹¥å½“å‰æ˜¯ç¬¬ä¸€ä¸ªBWDä»»åŠ¡è¿˜éœ€å°†losså­˜èµ·æ¥
                        #   ä»BWDå‡½æ•°çš„è¿è¡Œè§’åº¦æ¥è¯´, å°±æ˜¯ä¸æ–­åœ°(æ¯æ‰§è¡Œä¸€æ¬¡micorbatch)æ‰§è¡ŒBWDå¹¶å‘å‰ä¸€ä¸ªBWDä»»åŠ¡å‘é€dX
                        m_loss = 0. # loss averaged across examples in this minibatch
                        for i, u in enumerate(vt.ubatchszs):
                            ### Recompute to create pytorch graph
                            # é‡è®¡ç®—ï¼Œå³é‡æ–°æ‰§è¡Œå‰å‘è®¡ç®—ï¼Œå¾—åˆ°è¯¥vtçš„è¾“å…¥å’Œè¾“å‡º
                            start_time = time.time()
                            X_named_tensors, Y_named_tensors = \
                                self._a_pack_forward_an_ubatch(vt, i, u,
                                                            data_ubatches, target_ubatches, 
                                                            requires_grad=True,
                                                            swapin_stashx_handler=self.swapin_stashx_handler,
                                                            swapin_localx_handler=self.swapin_localx_handler,# vDPä¸“ç”¨ï¼ŒvPPä¸ºNone
                                                            swapin_msgx_handler=self.swapin_msgx_handler,
                                                            sucinfo=self.sucinfo)
                            if self.nvprof: nvtx_range_pop() 
                            # è‹¥å½“å‰vtæ˜¯ç¬¬ä¸€ä¸ªBWDä»»åŠ¡, åˆ™è¿”å›çš„Y_named_tensorsä¿å­˜çš„æ˜¯loss
                            # å°†è¿”å›çš„lossé™¤ä»¥microbatchçš„æ•°é‡å¾—åˆ°ä¸€ä¸ªå¹³å‡å€¼, å†å°†è¯¥å¹³å‡å€¼ç´¯åŠ åˆ°m_loss
                            if 'loss' in Y_named_tensors:
                                # æ¯ä¸ªmicorbatchè®¡ç®—å‡ºæ¥çš„losséƒ½è¦é™¤ä»¥microbatchçš„æ•°é‡
                                Y_named_tensors['loss'] /= len(vt.ubatchszs) # NOTE: ubatches need to be equal
                                m_loss += Y_named_tensors['loss'].item()
                            ### Backward pass on recomputed graph
                            self._a_pack_backward_an_ubatch(vt, i, u,
                                                        X_named_tensors, Y_named_tensors,
                                                        swapin_localx_handler=self.swapin_localx_handler,# vDPä¸“ç”¨ï¼ŒvPPä¸ºNone
                                                        swapout_localx_handler=self.swapout_localx_handler,# vDPä¸“ç”¨ï¼ŒvPPä¸ºNone
                                                        sucinfo=self.sucinfo,
                                                        iteration_num=it)
                            end_time = time.time()
                            execution_time = end_time - start_time
                            print(f"rank{self.rank}, vt.idx:{vt.idx}, {vt.type}, microbatch{i}, åå‘æ‰§è¡Œäº†:{execution_time:.6f}ç§’")
                            compute_time.append(execution_time)
                            if self.verbose: print_gpu_mem(self.rank, vt, "End(#%d)" % i)
                            if self.nvprof: nvtx_range_pop()
                            ### Clean up
                            # æ¯ä¸ªmicrobatchç»“æŸåï¼Œåˆ é™¤æ‰ä¿å­˜çš„æ•´ä¸ªvtçš„è¾“å…¥è¾“å‡º
                            del X_named_tensors; del Y_named_tensors # very important!
                            start_time = time.time()
                            gc.collect()
                            end_time = time.time()
                            execution_time = end_time - start_time
                            print(f"rank{self.rank}, vt.idx:{vt.idx}, {vt.type}, microbatch{i}, gc.collectæ‰§è¡Œäº†:{execution_time:.6f}ç§’")
                            gc_time.append(execution_time)

                        ### Prefetch point @ AllReduce
                        # 3.é¢„å–suc_vtçš„æ¨¡å‹ï¼Œå°†å…¶Wå’ŒBæ‹¿åˆ°GPUä¸Š
                        if not self.args.no_prefetch_model:
                            if self.nvprof: nvtx_range_push("task{}({}) PrefetchPt".format(vt.idx, vt.show_layers() )) 
                            # inputï¼šå³æŠŠvtçš„æ‰€æœ‰layerçš„Wå’ŒB input åˆ°GPUä¸Š
                            # åˆ†æï¼šæ²¡æœ‰æŒ‡å®šæµï¼Œæ•´ä¸ªè¿‡ç¨‹åº”æ˜¯åœ¨é»˜è®¤æµä¸Šæ‰§è¡Œ
                            # 1.æ–­è¨€å½“å‰æ²¡æœ‰å…¶ä»–çš„ iput æ“ä½œæ­£åœ¨æ‰§è¡Œï¼Œç¡®ä¿åªæœ‰ä¸€ä¸ª iput æ“ä½œå¯ä»¥è¿›è¡Œ
                            # 2.åœ¨é»˜è®¤æµä¸Šè®°å½•ä¸€ä¸ªäº‹ä»¶ï¼ˆåˆ†é…ä¸€ä¸ªæ–°çš„eventï¼‰ï¼Œå³ev_computeï¼Œç”¨äºåç»­åœ¨ swapin æµä¸Šç­‰å¾…
                            # 3.è‹¥ç»™å®švtä¸Šçš„æ‰€æœ‰layerçš„Wå’ŒBçš„åª’ä»‹ä¸ºSHMï¼Œåˆ™æŒ‰ç…§cpuä¸Šå‚æ•°å’Œbufferçš„å¤§å°å’Œç±»å‹ï¼Œä¸ºgpuä¸Šçš„dataåˆ†é…ä¸€ä¸ªå¤§å°å’Œç±»å‹ç›¸åŒçš„ç©ºtensor
                            # 4.å°†(vt, ev_compute)æ·»åŠ åˆ° put_queue ä¸­ï¼ŒğŸ“Œè¿™ä¹Ÿæ„å‘³ç€è¯¥å‡½æ•°æ‰€åœ¨å®ä¾‹(PrefetchLocalModelGPU)çš„çº¿ç¨‹å°†å¼€å§‹æ‰§è¡Œswap in
                            self.prefetch_model_handler.iput(suc_vt) 
                            if self.nvprof: nvtx_range_pop() 
                        ### Optional dW aggregation (and B sync)
                        if self.CONFIGS["mode"] == 'vDP' and self.CONFIGS['N'] > 1:
                            self.default_stream.synchronize() # TODO: wait Compute by cuda event 
                            if self.nvprof: nvtx_range_push("task{}({}) AllReduce(dW,B)".format(vt.idx, vt.show_layers())) 
                            for l in vt.layers:
                                self.local_model[l].average_grad(self.p2pm_handler)
                                if self.args.average_buffer:
                                    self.local_model[l].average_buf(self.p2pm_handler) # optional: all rank average buffers (can comment out to only use rank0's buf)
                            # TODO: wait AllReduce finish by cuda event
                            if self.nvprof: nvtx_range_pop() 
                        # ä¿å­˜è®¡ç®—å‡ºæ¥çš„loss
                        if m_loss != 0.:
                            local_losses.append(m_loss)
                            global_losses.append(m_loss)

                        ### Swap-out model {W,dW,B}
                        # 4.ç›´æ¥åˆ é™¤Wï¼Œå¸è½½dWã€Bè‡³cpuçš„shared_memoryç‰ˆæœ¬æ¨¡å‹ï¼ˆæ¯å±‚è‡ªå·±å°±æ˜¯ä¸€ä¸ªæ¨¡å‹ï¼‰ä¸Šï¼ˆå®é™…å­˜å‚¨äºpinned memoryï¼‰
                        # è¯¥ä»£ç æ²¡å®ç°ä¸offloadçš„ä»£ç ï¼Œå¿…é¡»æ‰§è¡Œ
                        if self.CONFIGS["opt_offld"]:                   
                            # ### Clip dW for "gpt2_huggingface"
                            #     self.default_stream.synchronize()
                            #     for l in vt.layers:
                            #         torch.nn.utils.clip_grad_norm_(self.local_model[l].model.parameters(), self.args.max_grad_norm) 
                            ### Out {W,dW,B}
                            # é˜»å¡ï¼Œç›´åˆ°è¯¥æµä¸­çš„ä»»åŠ¡å…¨éƒ¨å®Œæˆ
                            self.default_stream.synchronize() # CPU wait
                            if self.nvprof: nvtx_range_push("task{}({}) SwapOut(dW,B)".format(vt.idx, vt.show_layers())) 
                            # å¯¹vtä¸­çš„æ‰€æœ‰layerï¼Œè‹¥dWçš„è¾“å‡ºåª’ä»‹ä¸ºLOCï¼ŒBçš„è¾“å‡ºåª’ä»‹ä¸ºSHMï¼Œå°†gpuæ¨¡å‹çš„gradå’Œbufferå¸è½½åˆ°cpuçš„shared_modelä¸Š
                            # ğŸ“Œè¿™ä¿©ä¸œè¥¿å®é™…ä¸Šå­˜å‚¨åœ¨pinned memoryä¸Šï¼Œè™½ç„¶æŒ‚åœ¨shared_modelä¸Šï¼ˆbufferä»¥pinned_bufæˆå‘˜å˜é‡æŒ‚åœ¨shared_modelä¸Šï¼‰
                            start_time = time.time()
                            for l in vt.layers:
                                if vt.Out['dW'][l].medium == "LOC" and vt.Out['B'][l].medium == "SHM":
                                    if self.CONFIGS["mode"]=='vPP' or (self.CONFIGS["mode"]=='vDP' and self.rank==0):
                                        # 1.åœ¨cpuä¸ŠæŒ‰ç…§paramçš„shapeå’Œç±»å‹åˆ†é…ä¸€ä¸ªé›¶å€¼tensor
                                        # 2.å°†åˆšåˆ†é…çš„tensoræ‹·è´åˆ°pinned memoryä¸­
                                        # 3.å°†åˆšåˆšåˆ†é…çš„tensorèµ‹ç»™ shared memory ç‰ˆæœ¬æ¨¡å‹ï¼ˆä¸€å±‚å°±æ˜¯ä¸€ä¸ªæ¨¡å‹ï¼‰çš„gradå±æ€§
                                        # 4.ğŸ“Œä»¥éé˜»å¡çš„æ–¹å¼å°†gpuå‚æ•°çš„ grad.data æ‹·è´åˆ°åˆšåˆšåˆ†é…çš„tensorä¸Šï¼Œå³æ‹·è´åˆ°shared_modelä¸Š
                                        #   shared_modelçš„param.gradå®é™…ä¸Šåœ¨pinned memoryä¸Š
                                        self.local_model[l].swapout_grad() # Swap-out dW (accumulated)
                                        # 1.è‹¥æ¨¡å‹å­˜åœ¨bufferï¼Œåœ¨cpuä¸Šçš„å›ºå®šå†…å­˜æŒ‰ç…§bufferçš„shapeå’Œç±»å‹åˆ†é…ä¸€ä¸ªé›¶å€¼tensor
                                        # 2.å°†gpuä¸Šçš„buffer tensorğŸ“Œä»¥éé˜»å¡çš„æ–¹å¼æ‹·è´åˆ°cpuå›ºå®šå†…å­˜ä¸Šåˆšåˆšåˆ†é…çš„é›¶å€¼tensor
                                        # æœ€ç»ˆè¿™ä¸ªpinned_bufä¼šä»¥æˆå‘˜å˜é‡ï¼ˆpinned_bufï¼‰çš„å½¢å¼æŒ‚åœ¨shared_modelä¸Š
                                        self.local_model[l].swapout_buf() # Swap-out B (updated)
                                else:
                                    raise NotImplementedError
                            end_time = time.time()
                            execution_time = end_time - start_time
                            swapout_time.append(execution_time)
                            print(f"rank{self.rank}, vt.idx:{vt.idx}, {vt.type}, microbatch{i}, å¸è½½æ‰§è¡Œäº†:{execution_time:.6f}ç§’")
                            if self.verbose: print_gpu_mem(self.rank, vt, "SwapOut'ed(dW,B)")    
                            if self.nvprof: nvtx_range_pop() 
                            ### Delete model {W,dW,B} 
                            # åœ¨é»˜è®¤æµä¸Šé˜»å¡ï¼Œç­‰å¾…swapoutå®Œæˆ
                            self.default_stream.synchronize() # CPU wait for SwapOut
                            if self.nvprof: nvtx_range_push("task{}({}) Del(W,dW,B)".format(vt.idx, vt.show_layers())) 
                            # é€’å½’åœ°åˆ é™¤æ¯ä¸€å±‚ï¼ˆåŒ…æ‹¬å­æ¨¡å—ï¼‰ä¸­çš„æ‰€æœ‰å‚æ•°ã€æ¢¯åº¦å’Œç¼“å†²åŒº
                            start_time = time.time()
                            for l in vt.layers:
                                if vt.Out['dW'][l].medium == "LOC" and vt.Out['B'][l].medium == "SHM":
                                    self.local_model[l].del_param_grad_buf() # also del gradient
                                else: # 'B' == PIN
                                    raise NotImplementedError
                            end_time = time.time()
                            execution_time = end_time - start_time
                            delete_time.append(execution_time)
                            print(f"rank{self.rank}, vt.idx:{vt.idx}, {vt.type}, åˆ é™¤æ‰§è¡Œäº†:{execution_time:.6f}ç§’")
                            start_time = time.time()
                            gc.collect()
                            end_time = time.time()
                            execution_time = end_time - start_time
                            print(f"rank{self.rank}, vt.idx:{vt.idx}, {vt.type}, gc.collectæ‰§è¡Œäº†:{execution_time:.6f}ç§’")
                            gc_time.append(execution_time)

                            if self.verbose: print_gpu_mem(self.rank, vt, "Deleted(W,B)")
                            if self.nvprof: nvtx_range_pop() 
                        else:
                            raise ValueError("GPU Optimizer Underdevelopment.")
                        # -----------------------------------------------
                    elif vt.type == 'UPD' and not vt.is_gpu:
                        # -----------------------------------------------
                        ### In {dW,W,K} Out {W,K}
                        # UpdateInBkgdå®ä¾‹çš„çº¿ç¨‹åœ¨åå°è¿›è¡Œvtä¸Šçš„layerçš„bufferä»å›ºå®šå†…å­˜åˆ°å…±äº«å†…å­˜çš„å¤åˆ¶ï¼Œä»¥åŠåœ¨shared_memoryä¸Šè¿›è¡Œå‚æ•°çš„æ›´æ–°
                        if self.nvprof: nvtx_range_push("task{}({}) UPD(W)".format(vt.idx, vt.show_layers())) 
                        if self.CONFIGS["mode"]=='vPP' or (self.CONFIGS["mode"]=='vDP' and self.rank==0):
                            if not self.args.no_update:
                                # å°†ç»™å®šçš„vtæ”¾å…¥åˆ°put_queueé˜Ÿåˆ—ä¸­ï¼ŒåŒæ—¶å°†self.the_last_put è®¾ç½®ä¸º vt.idxã€‚ğŸ“Œè¿™æ„å‘³ç€UpdateInBkgdå®ä¾‹çš„çº¿ç¨‹ä¼šå¼€å§‹æ‰§è¡Œ
                                # vtä¸Šçš„layerçš„bufferä»å›ºå®šå†…å­˜åˆ°å…±äº«å†…å­˜çš„å¤åˆ¶ï¼Œä»¥åŠåœ¨shared_memoryä¸Šè¿›è¡Œå‚æ•°çš„æ›´æ–°
                                self.update_handler.iput(vt)
                        if self.nvprof: nvtx_range_pop() 
                        # -----------------------------------------------
                    else:
                        raise ValueError("Unknown vTask.type {} with .device {} !".format(vt.type,vt.device))
                    if self.nvprof: nvtx_range_pop() 
                if self.nvprof: nvtx_range_pop() 
                ### tasks iteration ends
                # ç­‰å¾…æœ€åä¸€ä¸ªæ”¾è¿›put_queueä¸­çš„ä»»åŠ¡ä»get_queueä¸­æ‹¿å‡ºæ¥ï¼Œå³ç­‰å¾…updateæ‰§è¡Œå®Œæˆ
                if not self.args.no_update:
                    self.update_handler.synchronize()
                    # æ‰§è¡Œå®Œçš„minibatchæ•°é‡
                    self.update_cnt += 1
                # torch.cuda.synchronize(self.rank)ï¼šç­‰å¾…å½“å‰GPUä¸Šæ‰€æœ‰çš„æ ¸å‡½æ•°æ‰§è¡Œå®Œæ¯•
                torch.cuda.synchronize(self.rank)
                dist.barrier()
                ### statistics
                # å°†åœ¨å½“å‰ä¸€ä¸ªminibatchä¸Šæ‰§è¡Œå®Œå½“å‰rankä¸Šæ‰€æœ‰ä»»åŠ¡èŠ±è´¹çš„æ—¶é—´å­˜èµ·æ¥
                self.time_iters.append(pc()-time_start) 
                if self.nvprof and it == self.args.nvprof_iter["end"]:
                    nvtx_mark("cudaProfilerStop") 
                    cuda_profiler.stop()
                    probe_cuda_mem.stop()
                    print("rank%d: cuda profiler stops"%self.rank)
                ## if it % self.args.display_period == 0:
                ps = "rank%d: Epoch%d/%d Iter%d/%d %.3f sec, %.3f/%.3f GB" % ( 
                    self.rank, epoch, self.args.num_epochs, it, self.args.num_iters, 
                    self.time_iters[-1],
                    float(torch.cuda.memory_allocated()) / 1024**3,# æŸ¥çœ‹å½“å‰GPUçš„å†…å­˜å ç”¨
                    float(torch.cuda.memory_reserved()) / 1024**3)# æŸ¥çœ‹å‘CUDAç”³è¯·çš„å†…å­˜å ç”¨
                # 
                if local_losses != []:
                    np.save(os.path.join(self.args.output_dir, "local_losses_rank%d.npy"%self.rank), local_losses)
                # vDPï¼Œç•¥
                if self.CONFIGS["mode"] == 'vDP' and self.CONFIGS['N'] > 1:
                    global_losses[-1] = allreduce_cpu_loss(global_losses[-1], averaging=True)
                # è‹¥å½“å‰rankæ˜¯æ‰§è¡Œç¬¬ä¸€ä¸ªBWDä»»åŠ¡ï¼Œå³åŒ…å«è®¡ç®—å±‚çš„BWDä»»åŠ¡ï¼Œä¸ºå­—ç¬¦ä¸²psæ·»åŠ lossä¿¡æ¯
                if self.rank == self.CONFIGS['loss_rank']:
                    ps += ", Loss %.3f"% global_losses[-1]
                    np.save(os.path.join(self.args.output_dir, "train_losses.npy"), global_losses)
                print(ps)

                self.delete_time.append(sum(delete_time))
                self.get_time.append(sum(get_time))
                self.swapout_time.append(sum(swapout_time))
                self.gc_time.append(sum(gc_time))
                self.compute_time.append(sum(compute_time))

                print(f"rank{self.rank}, å–æ¨¡å‹å…±èŠ±è´¹:{self.get_time[-1]}'s, è®¡ç®—å…±èŠ±è´¹:{self.compute_time[-1]}'s, åˆ é™¤æ¨¡å‹å…±èŠ±è´¹:{self.delete_time[-1]}'s, å¸è½½æ¢¯åº¦bufferå…±èŠ±è´¹:{self.swapout_time[-1]}'s, gc.collectå…±èŠ±è´¹:{self.gc_time[-1]}'s")
                if self.args.no_update:
                    assert self.CONFIGS["mode"] !='vPP'
                    gs = checker.check_grad_sum_harmony(self.shared_model)
                    grad_sums.append(gs)
                    np.save(os.path.join(self.args.output_dir, "grad_sums_rank%d.npy"%self.rank), grad_sums)
                # check GPU OoM & cudaFree & cudaMalloc
                self.cgm.check(it, is_check_malloc=not self.args.empty_cache and len(self.time_iters)-1 >= self.avg_it)
        ### end training
        torch.cuda.synchronize(self.rank)
        dist.barrier()
        print("rank%d: --- done ---" % self.rank)

    # 
    def finish(self): 
        ### statistics
        if self.verbose:
            # vPP p2pm_handler ä¸ºNone
            print_p2p_bytes(self.rank, self.p2px_handler, self.p2pm_handler, self.update_cnt)

        # self.avg_itï¼šå³æ•´ä¸ªè¿­ä»£æ¬¡æ•°çš„ä¸€åŠ
        # å–åä¸€åŠæ‰€æœ‰iterationï¼ˆè·‘ä¸€ä¸ªminibatchï¼‰æ‰€éœ€çš„æ—¶é—´ï¼Œå–å¹³å‡å€¼ï¼Œå¾—åˆ°å¹³å‡çš„ä¸€æ¬¡è¿­ä»£æ—¶é—´
        avg_iter_time = np.mean(self.time_iters[self.avg_it:]) # sec
        avg_compute_time = np.mean(self.compute_time[self.avg_it:])
        avg_delete_time = np.mean(self.delete_time[self.avg_it:])
        avg_collect_time = np.mean(self.gc_time[self.avg_it:])
        avg_get_time = np.mean(self.get_time[self.avg_it:])
        avg_swapout_time = np.mean(self.swapout_time[self.avg_it:])

        
        # CONFIGS["D"]ï¼šminibatchsize
        # ä¸€ä¸ªminibatch sampleçš„æ•°é‡/ä¸€æ¬¡è¿­ä»£çš„å¹³å‡æ—¶é—´ = ååé‡
        avg_throughput = self.CONFIGS['D'] / avg_iter_time # samples/sec
        # ä»ä¸åŒè¿›ç¨‹ä¸­æ”¶é›† å„ä¸ªrankå‘CUDAç”³è¯·çš„å†…å­˜å ç”¨ï¼Œç›®æ ‡è¿›ç¨‹ï¼ˆrank0ï¼‰ä¼šæ”¶é›†æ‰€æœ‰è¿›ç¨‹å‘é€çš„æ•´æ•°ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ•´æ•°åˆ—è¡¨
        gpu_reserved = gather_integer(torch.cuda.memory_reserved(), self.rank) # bytes
        if self.rank == 0:
            gpu_reserved = " ".join("%.1f"%(float(byte)/1024**3) for byte in gpu_reserved) # GB
            # è¿”å› ["occupied"ï¼šå·²ä½¿ç”¨çš„ç‰©ç†å†…å­˜é‡]
            cpu_occupied = self.pcm.system_cpu_memory(["occupied"])
            # self.avg_itï¼šæ‰€æœ‰è¿­ä»£ä¸­é—´çš„é‚£ä¸€æ¬¡
            # len(self.time_iters)ï¼šè¿­ä»£æ¬¡æ•°
            # 
            print("[Global] Iter[%d,%d) Avg Iter Time: %.3f sec, Avg Throughput: %.3f sample/s, GPU: (%s) GB, CPU: %s, Num Updates: %d\n" % (self.avg_it, len(self.time_iters), avg_iter_time, avg_throughput, gpu_reserved, cpu_occupied, self.update_cnt))
            print(f"[Global] å¹³å‡è®¡ç®—æ—¶é—´:{avg_compute_time}, å¹³å‡åˆ é™¤æ—¶é—´:{avg_delete_time}, å¹³å‡åƒåœ¾å›æ”¶æ—¶é—´:{avg_collect_time}, å¹³å‡æ‹¿å–æ—¶é—´:{avg_get_time}, å¹³å‡å¸è½½æ¢¯åº¦bufferæ—¶é—´:{avg_swapout_time}")
            print(f"[Global] æ‹¿å–æ—¶é—´å æ€»ä½“æ—¶é—´çš„æ¯”ä¾‹:{avg_get_time / avg_iter_time}")
            self.pcm.print("rank%d: eventually" % self.rank)
        ### save model
        # æš‚ç•¥ï¼Œé»˜è®¤ä¸ä¿å­˜æ¨¡å‹
        # self.args.save_final_modelï¼šé»˜è®¤ä¸ºfalse
        if self.args.save_final_model and self.rank == 0 and self.save_model is not None:
            self.save_model(self.args, self.shared_model, self.update_cnt)
