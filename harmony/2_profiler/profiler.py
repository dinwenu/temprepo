# Copyright (c) Microsoft Corporation.
# Licensed under the MIT license.

from __future__ import division, print_function
import os
import sys
import argparse
import json
import numpy as np
import gc
from copy import deepcopy
from collections import OrderedDict as ODict

import torch
from torch.autograd import Variable

from time import perf_counter as pc

from prof_data_struct import *

# æ ¹æ®metaç”Ÿæˆtensor
# æ ¹æ®è¾“å…¥çš„ metaï¼Œåˆ›å»ºä¸€ä¸ªå…·æœ‰æŒ‡å®šå½¢çŠ¶ã€æ•°æ®ç±»å‹å’Œè®¾å¤‡çš„å¼ é‡ï¼Œå¹¶æ ¹æ® requires_grad å‚æ•°è®¾ç½®ç”Ÿæˆçš„tesnoræ˜¯å¦éœ€è¦æ¢¯åº¦
# æ³¨æ„ï¼Œå³ä½¿ubatchsizeçš„å¤§å°ä¸º1ï¼Œä¹Ÿä¼šä¿®æ”¹metaä¸­ä¿å­˜çš„ shape æˆå‘˜å˜é‡ï¼Œå³[1024]->[ubatchsize, 1024]
def realize_TensorMeta(meta, ubatchsize=-1, requires_grad=False, force_dtype=None, device="cuda:0", use_rand=True):
    assert type(meta) is TensorMeta
    # è‹¥metaå½“å‰è®°å½•çš„è¾“å…¥åªæ˜¯ä¸€ä¸ªå•ä¸ªçš„sampleï¼Œå¹¶éä¸€ä¸ªbatchï¼Œå°†metaä¸­ä¿å­˜çš„è¾“å…¥çš„shapeå˜ä¸ºubatchsizeçš„å¤§å°ï¼Œå³
    # [1024]->[ubatchsize, 1024]ã€‚åŒæ—¶å°†is_ubatchè¿™ä¸ªæˆå‘˜å˜é‡ç½®ä¸ºtrueï¼Œå³è¾“å…¥æ˜¯ä¸€ä¸ªbatch
    meta.add_ubatch(ubatchsize) # in-place add ubatchsize to shape if not there
    # è‹¥æ²¡è®¾ç½® force_dtype è¿™ä¸ªå‚æ•°ï¼Œå–å…ƒæ•°æ®ä¿å­˜çš„è¾“å…¥çš„ dtype
    dtype = force_dtype if force_dtype is not None else meta.dtype
    # æ ¹æ® meta (å…ƒæ•°æ®)ï¼Œåˆ›å»ºä¸€ä¸ªå…·æœ‰æŒ‡å®šå½¢çŠ¶ã€æ•°æ®ç±»å‹å’Œè®¾å¤‡çš„å¼ é‡
    if dtype == torch.float32:
        tensor = Variable(torch.rand(meta.shape, dtype=torch.float32, device=device)) if use_rand else Variable(torch.ones(meta.shape, dtype=torch.float32, device=device))
    elif dtype == torch.int64:
        tensor = Variable(torch.randint(low=0,high=2,size=meta.shape,dtype=torch.int64, device=device)) if use_rand else Variable(torch.ones(meta.shape,dtype=torch.int64, device=device))
    else:
        raise ValueError("unknown X.dtype={}".format(meta.dtype))
    # æ ¹æ® requires_grad å‚æ•°è®¾ç½®å¼ é‡æ˜¯å¦éœ€è¦æ¢¯åº¦
    tensor.requires_grad_(requires_grad)
    # å¦‚æœéœ€è¦æ¢¯åº¦ï¼Œä¿ç•™å¼ é‡çš„æ¢¯åº¦ï¼Œä»¥ä¾¿åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ä½¿ç”¨
    if requires_grad:
        tensor.retain_grad()
    return tensor

# æ ¹æ®ubatchsize, vlayer_id, X_namesä»XMETAä¸­æŠŠå…ƒæ•°æ®æ‹¿å‡ºæ¥ï¼Œæ ¹æ®å…ƒæ•°æ®ç”Ÿæˆä¸€ä¸ªéšæœºçš„tensorï¼Œ
# è¿”å›ä¸€ä¸ªæœ‰åºå­—å…¸ï¼š{name: ç”Ÿæˆçš„tensor}ï¼Œé¡ºåºå³å‚æ•°namesä¸­nameçš„é¡ºåº
# 1.è¿”å›self.stats[ubatchsize][vlayer_id][name]ï¼Œnameå°±æ˜¯è¯¥å±‚çš„è¾“å…¥åï¼Œè¿™ä¸ªè¿”å›çš„ä¸œè¥¿æ˜¯ä¸€ä¸ª TensorMetaï¼Œå³tensorçš„å…ƒæ•°æ®
# 2.æ ¹æ®metaï¼ˆå…ƒæ•°æ®ï¼ŒTensorMetaï¼‰ç”ŸæˆçœŸå®çš„tensor
def realize_X(XMETA, ubatchsize, vlayer_id, names, requires_grad=False, device="cuda:0", use_rand=True):
    named_tensors = ODict() # { name : tensor or const or [tensor,tensor] }
    for name in names: # [XMETA.get(ubatchsize, vlayer_id)[name] for name in X_names]
        # è¿”å›self.stats[ubatchsize][vlayer_id][name]ï¼Œnameå°±æ˜¯è¯¥å±‚çš„è¾“å…¥å
        # è¿™ä¸ªè¿”å›çš„ä¸œè¥¿æ˜¯ä¸€ä¸ª TensorMetaï¼Œå³tensorçš„å…ƒæ•°æ®
        meta = XMETA.get(ubatchsize, vlayer_id)[name]
        # è‹¥è¾“å…¥çš„åç§°ä»¥ input ä¸ºå¼€å¤´ï¼Œrequires_gradå‚æ•°ç½®ä¸ºfalse
        if name.startswith("input"): # in ["input0","input1","input2","input_ids"]: # TODO: add identity chain to input
            requires_grad = False
        if type(meta) is TensorMeta:
            # æ ¹æ®metaç”ŸæˆçœŸå®çš„tensor
            # æ ¹æ®è¾“å…¥çš„ metaï¼Œåˆ›å»ºä¸€ä¸ªå…·æœ‰æŒ‡å®šå½¢çŠ¶ã€æ•°æ®ç±»å‹å’Œè®¾å¤‡çš„å¼ é‡ï¼Œå¹¶æ ¹æ® requires_grad å‚æ•°è®¾ç½®ç”Ÿæˆçš„tesnoræ˜¯å¦éœ€è¦
            # æ¢¯åº¦ã€‚ğŸ“Œæ³¨æ„ï¼Œå³ä½¿ubatchsizeçš„å¤§å°ä¸º1ï¼Œä¹Ÿä¼šä¿®æ”¹metaä¸­ä¿å­˜çš„ shape æˆå‘˜å˜é‡ï¼Œå³[1024]->[ubatchsize, 1024]
            # æœ€åè¿”å›ç”Ÿæˆçš„tensor
            named_tensors[name] = realize_TensorMeta(meta, ubatchsize, requires_grad, device=device, use_rand=use_rand)
        elif type(meta) is ConstMeta: # output of size(int)
            named_tensors[name] = meta.const
        elif type(meta) is list: # output tuple of bert pretrainhead 
            named_tensors[name] = [realize_TensorMeta(m, ubatchsize, requires_grad, device=device, use_rand=use_rand) for m in meta]
        else:
            raise ValueError("unknown meta={}".format(meta))
    return named_tensors

def realize_D(TMETA, ubatchsize, device="cuda:0", use_rand=True): 
    return realize_X(TMETA, ubatchsize, 0, TMETA.get_names(ubatchsize, vlayer_id=0), requires_grad=False, device=device, use_rand=use_rand)

# æ ¹æ®TMETAä¸­ä¿å­˜çš„target tesnorçš„å…ƒæ•°æ®éšæœºç”Ÿæˆä¸€ä¸ªtensorï¼Œæ”¾åœ¨å­—å…¸é‡Œè¿”å›ã€‚{"label": ç”Ÿæˆçš„tensor}
def realize_T(TMETA, ubatchsize, device="cuda:0", use_rand=True):
    return realize_X(TMETA, ubatchsize, TMETA.last_vlayer_id, TMETA.target_names, requires_grad=False, device=device, use_rand=use_rand)
    

def realize_dX(XMETA, ubatchsize, vlayer_id, names, device="cuda:0", use_rand=True): # excluding T
    named_gradients = ODict() # { name : tensor or None or [tensor,tensor] }
    for name in names: # [XMETA.get(ubatchsize, vlayer_id)[name] for name in X_names]
        meta = XMETA.get(ubatchsize, vlayer_id)[name]
        # if name in ["input0","input1","input2"]: # TODO: add identity chain to input
        #     requires_grad = False
        if type(meta) is TensorMeta:
            assert meta.is_ubatch
            named_gradients[name] = realize_TensorMeta(meta, requires_grad=False, force_dtype=torch.float32, device=device, use_rand=use_rand)
        elif type(meta) is ConstMeta: # output of size(int)
            named_gradients[name] = None
        elif type(meta) is list: # output tuple of bert pretrainhead 
            named_gradients[name] = [realize_TensorMeta(m, requires_grad=False, force_dtype=torch.float32, device=device, use_rand=use_rand) for m in meta]
        else:
            raise ValueError("unknown meta={}".format(meta))
    return named_gradients


class Profiler(object):
    def __init__(self, model, optimizer=None, compute_loss=None, offload_optim=True, device='cuda:0', verbose=False):
        self.model = model
        self.optimizer = optimizer
        # NOTE: safe to self.model and self.optimizer? 
        #       - yes for profile_forward and profile_backward (stateless)
        #       - no for profile_update (modified model and optimizer state) (so leave update to last phase)
        self.compute_loss = compute_loss
        self.offload_optim = offload_optim
        self.device = device
        self.verbose = verbose
        
        # clean up model grad and graph
        # æ¸…ç©ºæ¨¡å‹æ¯ä¸ªvlayerçš„æ¢¯åº¦ï¼Œå¹¶å°†å‚æ•°ä»è®¡ç®—é€”ä¸­åˆ†ç¦»ï¼Œå¹¶æ‰§è¡Œåƒåœ¾å›æ”¶å’Œæ¸…ç©ºcudaç¼“å­˜
        self.del_model_grad()

    # å°†å±‚è¾“å‡ºçš„nameå’ŒtensoråŠ å…¥åˆ°æœ‰åºå­—å…¸ named_tensors ä¸­
    def _save_Y_tensors_to_named(self, Y_names, Y_tensors, named_tensors):
        assert type(Y_tensors) is list
        if len(Y_names) == 1 and len(Y_tensors) > 1:
            named_tensors[Y_names[0]] = Y_tensors
        else:
            for name, tensor in zip(Y_names, Y_tensors):
                named_tensors[name] = tensor

    # ç”¨äºå°†æ¨¡å‹å±‚çš„å‚æ•°ç¼“å†²åŒºåŠ è½½åˆ° CUDA è®¾å¤‡ä¸Šï¼Œå¹¶æ ¹æ®å‡½æ•°çš„ç¬¬äºŒä¸ªå‚æ•° è®¾ç½®å‚æ•°æ˜¯å¦éœ€è¦æ¢¯åº¦
    @torch.no_grad()
    def _swapin_param_buf(self, vlayer, requires_grad=False): 
        # å°†æ¨¡å‹å±‚ vlayer çš„å‚æ•°åŠ è½½åˆ° CUDA è®¾å¤‡ä¸Š
        vlayer.cuda()
        if len(list(vlayer.parameters())) != 0:
            for param in vlayer.parameters():
                if param is not None:
                    # æ–­è¨€å‚æ•°çš„æ¢¯åº¦ä¸º Noneï¼Œå¹¶ä¸”ä¸éœ€è¦æ¢¯åº¦
                    assert param.grad is None and (not param.requires_grad), \
                    "swapin requires no grad for both FWD and BWD (param={}, param.grad={}, param.requires_grad={})".format(param, param.grad, param.requires_grad) 
                    # è®¾ç½®å‚æ•°æ˜¯å¦éœ€è¦æ¢¯åº¦
                    param.requires_grad_(requires_grad)

    # 1.è‹¥vlayerçš„æ¢¯åº¦ä¸ä¸ºç©ºï¼Œå°†å…¶æ¢¯åº¦ç½®ä¸ºNone
    # 2.å°†å‚æ•°ä»è®¡ç®—å›¾ä¸­åˆ†ç¦»ï¼ˆdetachï¼‰ï¼Œä½¿å…¶æˆä¸ºå¶å­èŠ‚ç‚¹ï¼Œå¹¶ä¸”ä¸å†ä¿ç•™æ¢¯åº¦ä¿¡æ¯ã€‚è¿™æ ·åšå¯ä»¥é¿å…æ¢¯åº¦çš„ä¼ æ’­
    # 3.æ‰§è¡Œåƒåœ¾å›æ”¶å¹¶æ¸…ç©ºcudaç¼“å­˜
    @torch.no_grad()
    def _del_grad(self, vlayer, manual_gc=False):
        if len(list(vlayer.parameters())) != 0:
            for param in vlayer.parameters(): 
                if param is not None:
                    if param.grad is not None:
                        param.grad = None
                    # å°†å‚æ•°ä»è®¡ç®—å›¾ä¸­åˆ†ç¦»ï¼ˆdetachï¼‰ï¼Œä½¿å…¶æˆä¸ºå¶å­èŠ‚ç‚¹ï¼Œå¹¶ä¸”ä¸å†ä¿ç•™æ¢¯åº¦ä¿¡æ¯ã€‚è¿™æ ·åšå¯ä»¥é¿å…æ¢¯åº¦çš„ä¼ æ’­
                    param.detach_() # in-place detaches self Tensor from the graph that created it, making it a leaf.
                    assert not param.requires_grad
        if manual_gc:
            # gc.collect()ç”¨äºæ‰§è¡ŒPythonçš„åƒåœ¾å›æ”¶
            # torch.cuda.empty_cache()ç”¨äºæ¸…ç©ºCUDAç¼“å­˜ï¼Œé‡Šæ”¾GPUä¸Šçš„å†…å­˜
            gc.collect(); torch.cuda.empty_cache()

    # æ¸…ç©ºæ¨¡å‹æ¯ä¸ªvlayerçš„æ¢¯åº¦ï¼Œå¹¶å°†å‚æ•°ä»è®¡ç®—é€”ä¸­åˆ†ç¦»ï¼Œå¹¶æ‰§è¡Œåƒåœ¾å›æ”¶å’Œæ¸…ç©ºcudaç¼“å­˜
    def del_model_grad(self):
        # ä¸‰ä¸ªå‚æ•°åˆ†åˆ«å¯¹åº”ï¼švlayerç±»ã€è¾“å…¥åç§°åˆ—è¡¨ã€è¾“å‡ºåç§°åˆ—è¡¨
        for vlayer, _, _ in self.model:
            # 1.è‹¥vlayerçš„æ¢¯åº¦ä¸ä¸ºç©ºï¼Œå°†å…¶æ¢¯åº¦ç½®ä¸ºNone
            # 2.å°†å‚æ•°ä»è®¡ç®—å›¾ä¸­åˆ†ç¦»ï¼ˆdetachï¼‰ï¼Œä½¿å…¶æˆä¸ºå¶å­èŠ‚ç‚¹ï¼Œå¹¶ä¸”ä¸å†ä¿ç•™æ¢¯åº¦ä¿¡æ¯ã€‚è¿™æ ·åšå¯ä»¥é¿å…æ¢¯åº¦çš„ä¼ æ’­
            # 3.æ‰§è¡Œåƒåœ¾å›æ”¶å¹¶æ¸…ç©ºcudaç¼“å­˜
            self._del_grad(vlayer, manual_gc=True)

    # åˆ†ä¸¤ç§æƒ…å†µï¼Œæ‰€æœ‰å±‚çš„å‰å‘/åå‘è®¡ç®— å’Œ æŸå¤±å‡½æ•°çš„è®¡ç®—
    # 1.æ ¹æ®å…ƒæ•°æ®åœ¨GPUä¸Šéšæœºç”Ÿæˆä¸€ä¸ªtensorä½œä¸ºå±‚çš„è¾“å…¥ï¼Œè‹¥æ˜¯æœ€åè®¡ç®—æŸå¤±çš„å±‚ï¼Œè¿˜è¦å®ä¾‹åŒ–ä¸€ä¸ªtarget tensorï¼Œå³æ ‡ç­¾tensor
    #   ğŸ“Œæ³¨æ„ï¼Œæ— è®ºubatchsizeæ˜¯å¤šå¤§ï¼Œä¸€å¼€å§‹metaçš„shapeéƒ½åªæ˜¯1ç»´çš„ï¼Œè¯¥å‡½æ•°å†…éƒ¨ä¼šæŠŠç¬¬ä¸€ä¸ªç»´åº¦å˜ä¸ºubatchsizeçš„å¤§å°
    # 2.è®¡ç®—å±‚çš„æ‰§è¡Œæ—¶é—´
    # 3.å°†è¾“å‡ºä¿å­˜èµ·æ¥ï¼Œå› ä¸ºè‹¥å‡½æ•°æœ€åä¸€ä¸ªå‚æ•°ç½®ä¸ºtrue(å³è¿›è¡Œçš„æ˜¯åå‘è®¡ç®—)ï¼Œè¿™ä¸ªè¾“å‡ºéœ€è¦è¿”å›
    # 4.è‹¥å½“å‰å±‚ä¸æ˜¯è®¡ç®—æŸå¤±çš„é‚£ä¸€å±‚ï¼Œåˆ™æ ¹æ®è¾“å‡ºå®ä¾‹åŒ–ä¸€ä¸ªå…ƒæ•°æ®ï¼Œå› ä¸ºè¯¥å±‚çš„è¾“å‡ºå°±æ˜¯ä¸‹ä¸€å±‚çš„è¾“å…¥ï¼Œä¸‹ä¸€å±‚æ‰§è¡Œè¯¥å‡½æ•°æ—¶
    #   éœ€è¦æ ¹æ®è¿™ä¸ªå…ƒæ•°æ®éšæœºåˆ›é€ ä¸€ä¸ªè¾“å…¥tensor
    # ğŸ“Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œrequires_gradä¸ºTrueï¼Œä»£è¡¨è¯¥å‡½æ•°æ˜¯åœ¨æ£€æµ‹BWDçš„è¿‡ç¨‹ä¸­è¢«è°ƒç”¨çš„ï¼Œæ­¤æ—¶FWDè®¡ç®—çš„æ—¶é—´è¦åŠ å…¥åˆ°BWDä¸­ï¼Œ
    #   å³æœ€ç»ˆçš„BWDæ‰§è¡Œæ—¶é—´åŒ…å«äº†é‡è®¡ç®—å½“å‰å±‚çš„æ—¶é—´
    def _vlayer_forward_an_ubatch(self, ubatchsize, vlayer_id, vlayer, X_names, Y_names, tid, TIME, XMETA, TMETA, requires_grad=False):
        if vlayer_id != len(self.model)-1: # not criterion yet
            # In {X}ï¼Œåœ¨GPUä¸Šæ ¹æ®å…ƒæ•°æ®ç”Ÿæˆä¸€ä¸ªtensor
            # æ ¹æ®ubatchsize, vlayer_id, X_namesä»XMETAä¸­æŠŠå…ƒæ•°æ®æ‹¿å‡ºæ¥ï¼Œæ ¹æ®å…ƒæ•°æ®ç”Ÿæˆä¸€ä¸ªéšæœºçš„tensorç”¨äºå½“å‰å±‚çš„å‰å‘è®¡ç®—
            # è¿”å›ä¸€ä¸ªæœ‰åºå­—å…¸ï¼š{name: ç”Ÿæˆçš„tensor}ï¼Œé¡ºåºå³å‚æ•°namesä¸­nameçš„é¡ºåº
            # ğŸ“Œæ³¨æ„ï¼Œæ— è®ºubatchsizeæ˜¯å¤šå¤§ï¼Œä¸€å¼€å§‹metaçš„shapeéƒ½åªæ˜¯1ç»´çš„ï¼Œè¯¥å‡½æ•°å†…éƒ¨ä¼šæŠŠç¬¬ä¸€ä¸ªç»´åº¦å˜ä¸ºubatchsizeçš„å¤§å°
            # 1.1.è¿”å›self.stats[ubatchsize][vlayer_id][name]ï¼Œnameå°±æ˜¯è¯¥å±‚çš„è¾“å…¥åï¼Œè¿™ä¸ªè¿”å›çš„ä¸œè¥¿æ˜¯ä¸€ä¸ª TensorMetaï¼Œå³tensorçš„å…ƒæ•°æ®
            # 1.2.æ ¹æ®metaï¼ˆå…ƒæ•°æ®ï¼ŒTensorMetaï¼‰ç”ŸæˆçœŸå®çš„tensor
            named_tensors = realize_X(XMETA, ubatchsize, vlayer_id, X_names, requires_grad, self.device)
            # Forward on GPU
            # print(f"ç”Ÿæˆè¾“å…¥Xåï¼Œtorch.cuda.memory_allocated():{torch.cuda.memory_allocated()/1024/1024} ,torch.cuda.memory_reserved():{torch.cuda.memory_reserved()/1024/1024}")
            torch.cuda.synchronize(self.device)
            t_start = pc() 
            # 2.æ‰§è¡Œå½“å‰å±‚ï¼šå–å‡ºåˆšåˆšç”Ÿæˆçš„è¾“å…¥tensorï¼Œä½œä¸ºå±‚çš„è¾“å…¥
            Y_tensors = vlayer(*[named_tensors[name] for name in X_names])
            torch.cuda.synchronize(self.device)
            t_end = pc() 
            # print(f"ç”Ÿæˆè¾“å‡ºYåï¼Œtorch.cuda.memory_allocated():{torch.cuda.memory_allocated()/1024/1024} ,torch.cuda.memory_reserved():{torch.cuda.memory_reserved()/1024/1024}")
            # Result
            # 3.è®°å½•è¿è¡Œæ—¶é—´:
            # self.stats[FWD/BWD][ubatchsize][vlayer_id][device] += time
            TIME.add('FWD' if not requires_grad else 'BWD', ubatchsize, vlayer_id, 'GPU', t_end-t_start) 
            # print("\t\t\tforward'ed trial:{}".format(tid))
            if not isinstance(Y_tensors, tuple):
                Y_tensors = (Y_tensors,)
            Y_tensors = list(Y_tensors)
            # Save {Y}
            # 4.å°†å±‚è¾“å‡ºçš„nameå’ŒtensoråŠ å…¥åˆ°æœ‰åºå­—å…¸ named_tensors ä¸­
            self._save_Y_tensors_to_named(Y_names, Y_tensors, named_tensors)
            # Out {Y} && {stashX}
            # 5.å½“å‰çš„è¾“å‡ºå³ä¸‹ä¸€å±‚çš„è¾“å…¥ï¼Œä¸ºä¸‹ä¸€å±‚çš„è¾“å…¥ç”Ÿæˆå…ƒæ•°æ®å¹¶ä¿å­˜åˆ°XMETAä¸­ï¼ŒğŸ“Œä¸‹ä¸€å±‚å‰å‘è®¡ç®—çš„æ—¶å€™å°±ç”¨è¿™ä¸ªå…ƒæ•°æ®ç”Ÿæˆtensor
            # self.stats[ubatchsize][vlayer_id][names[0]] = TensorMeta (æ ¹æ®ä¼ å…¥çš„Y_tensorså®ä¾‹åŒ–çš„å…ƒæ•°æ®)
            XMETA.set(ubatchsize, vlayer_id+1, Y_names, Y_tensors)

        # è‹¥åˆ°äº†æœ€åä¸€å±‚
        else: # criterion
            assert Y_names == ["loss"]
            print("åˆ°æœ€åä¸€å±‚äº†ï¼Œvlayerä¸ºï¼š", vlayer) # CrossEntropyLoss()
            print("X_namesä¸º: ", X_names) # ['out26']
            # In {X}
            # 1.å¯¹æ¯ä¸€ä¸ªè¾“å…¥tensorçš„nameç”ŸæˆçœŸå®çš„tensorï¼Œè¿”å›ä¸€ä¸ªæœ‰åºå­—å…¸ï¼š{name: ç”Ÿæˆçš„tensor}ï¼Œé¡ºåºå³å‚æ•°namesä¸­nameçš„é¡ºåº
            named_tensors = realize_X(XMETA, ubatchsize, vlayer_id, X_names, requires_grad, self.device)
            print("named_tensorsçš„å½¢çŠ¶ä¸º:", named_tensors[X_names[0]].shape)
            print(named_tensors[X_names[0]])
            # In {T}
            # 2.æ ¹æ®TMETAä¸­ä¿å­˜çš„ç›®æ ‡å€¼tensorçš„å…ƒæ•°æ®éšæœºç”Ÿæˆä¸€ä¸ªç›®æ ‡å€¼tensorï¼Œæ”¾åœ¨å­—å…¸é‡Œè¿”å›ã€‚{"label": ç”Ÿæˆçš„tensor}
            named_targets = realize_T(TMETA, ubatchsize, self.device)
            print("named_targetsçš„å½¢çŠ¶ä¸º:", named_targets[TMETA.target_names[0]].shape)
            # Forward on GPU
            torch.cuda.synchronize(self.device)
            t_start = pc()
            # 3.è®¡ç®—äº¤å‰ç†µæŸå¤±
            if self.compute_loss is not None:
                # named_tensorsï¼šæ¨¡å‹æœ€åä¸€å±‚çš„è¾“å‡º
                # named_targetsï¼šç›®æ ‡å€¼
                Y_tensors = self.compute_loss(vlayer, named_tensors, X_names, named_targets)
            else:
                Y_tensors = [vlayer(named_tensors[name],named_targets["target"]) for name in X_names]
                Y_tensors = [sum(Y_tensors)]
            torch.cuda.synchronize(self.device)
            t_end = pc() 
            # Result
            # 4.è®°å½•è®¡ç®—æŸå¤±çš„æ—¶é—´:
            TIME.add('FWD' if not requires_grad else 'BWD', ubatchsize, vlayer_id, 'GPU', t_end-t_start) 
            # print("\t\t\tforward'ed trial:{} loss = {}".format(tid, Y_tensors))
            # Save {Y}
            # 5.å°†å±‚è¾“å‡ºçš„nameï¼ˆ["loss"]ï¼‰å’ŒtensoråŠ å…¥åˆ°æœ‰åºå­—å…¸ named_tensors ä¸­
            self._save_Y_tensors_to_named(Y_names, Y_tensors, named_tensors)
            del named_targets
        # Clean up
        del Y_tensors
        # return for backward pass
        # è‹¥è¯¥é¡¹ä¸ºtrueï¼Œè¯´æ˜æ‰§è¡Œçš„æ˜¯åå‘ä¼ æ’­ï¼Œå°†è¯¥å±‚çš„è¾“å…¥å’Œè¾“å‡ºï¼ˆä¸€ä¸ªæœ‰åºå­—å…¸ï¼‰ä¼ å›æ¥
        if requires_grad:
            return named_tensors
        else:
            del named_tensors

    # 1.å‡†å¤‡backwardå‡½æ•°çš„ç¬¬äºŒä¸ªå‚æ•°
    # 2.å¯¹è¯¥å±‚çš„è¾“å‡ºtensorè¿›è¡Œåå‘è®¡ç®—
    # 3.è®°å½•è¯¥å±‚åå‘ä¼ æ’­çš„æ—¶é—´
    def _vlayer_backward_an_ubatch(self, ubatchsize, vlayer_id, vlayer, X_names, Y_names, tid, TIME, XMETA, TMETA, named_tensors):
        # 1.å‡†å¤‡backwardå‡½æ•°çš„ç¬¬äºŒä¸ªå‚æ•°
        # In {dY}
        # è‹¥ç°åœ¨æ˜¯è®¡ç®—æŸå¤±çš„é‚£ä¸€å±‚ï¼Œé‚£ä¹ˆè¾“å‡ºçš„lossæ˜¯ä¸€ä¸ªæ ‡é‡ï¼Œbackwardå‡½æ•°ä¸éœ€è¦ç¬¬äºŒä¸ªå‚æ•°ï¼Œå› æ­¤è¿™é‡Œç›´æ¥ç»™äº†ä¸€ä¸ªNone
        if vlayer_id == len(self.model)-1: # criterion
            print("æœ€åä¸€å±‚è¾“å‡ºçš„lossé•¿ä»€ä¹ˆæ ·ï¼š", named_tensors['loss']) # æœ€åä¸€å±‚è¾“å‡ºçš„lossé•¿ä»€ä¹ˆæ ·ï¼š tensor(10.8588, device='cuda:0', grad_fn=<NllLossBackward0>)
            #                              æ£€æŸ¥ named_tensors['loss'] æ˜¯å¦ä¸º torch.Tensor æˆ– Variable ç±»å‹
            assert Y_names == ['loss'] and isinstance(named_tensors['loss'], (torch.Tensor,Variable))
            named_gradients = ODict({ 'loss': None })
            assert named_tensors['loss'].requires_grad
        else:
            # ä½¿ç”¨åé¢é‚£ä¸€å±‚çš„è¾“å…¥çš„å…ƒæ•°æ®ç”Ÿæˆtensorï¼Œå³æ¢¯åº¦çš„å¤§å°å’Œå½“å‰å±‚çš„è¾“å‡ºä¸€æ ·å¤§
            # â“ä¸ºä»€ä¹ˆæ¢¯åº¦çš„å¤§å°å’Œå½“å‰å±‚çš„è¾“å‡ºä¸€æ ·å¤§ï¼Ÿ
            # ç­”ï¼šè¿™ä¸æ˜¯æ¢¯åº¦ï¼Œè€Œæ˜¯ä½œä¸ºbackward()å‡½æ•°çš„ç¬¬äºŒä¸ªå‚æ•°ï¼Œç”¨äºæ‰§è¡Œé›…å¯æ¯”å‘é‡ç§¯çš„ï¼Œå¯ä»¥ç†è§£ä¸ºè®¾ç½®äº†ä¸€ä¸ªæƒé‡ï¼Œ
            # ç”¨æ¥è°ƒæ•´å„ä¸ªå› å˜é‡yå¯¹æœ€ç»ˆé‚£ä¸ªâ€œæ ‡é‡æ¢¯åº¦â€çš„å½±å“å¤§å°
            # ç­”ï¼šäº‹å®ä¸Šä½¿ç”¨å½“å‰å±‚çš„è¾“å‡ºä¹Ÿæ˜¯ä¸€æ ·çš„ï¼švlayer_id, self.model[vlayer_id][2]
            named_gradients = realize_dX(XMETA, ubatchsize, vlayer_id+1, self.model[vlayer_id+1][1], self.device)
        # Backward on GPU
        Y_tensors = [] # è¯¥å±‚çš„è¾“å‡ºtensor
        Y_gradients = [] 
        for name in Y_names: # only tensor & required_grad can run autograd
            # æ‹¿åˆ°è¯¥å±‚çš„è¾“å‡ºtensor
            Y = named_tensors[name]
            if (type(Y) in [torch.Tensor, Variable]) and (Y.requires_grad):
                Y_tensors.append(Y)
                Y_gradients.append(named_gradients[name])
            elif type(Y) is list: # output tuple of bert pretrainheader
                for i, y in enumerate(Y):
                    if (type(y) in [torch.Tensor, Variable]) and (y.requires_grad):
                        Y_tensors.append(y)
                        Y_gradients.append(named_gradients[name][i])
        torch.cuda.synchronize(self.device)
        # print("è¯¥å±‚è¾“å…¥è®¡ç®—æ¢¯åº¦å‰çš„æ¢¯åº¦ä¸ºï¼š", named_tensors[X_names[0]].grad) # None
        t_start = pc() 
        # 2.å¯¹è¯¥å±‚çš„è¾“å‡ºtensorè¿›è¡Œæ¢¯åº¦è®¡ç®—
        torch.autograd.backward(tuple(Y_tensors), grad_tensors=tuple(Y_gradients))
        torch.cuda.synchronize(self.device)
        t_end = pc() 
        # print("è¯¥å±‚è¾“å…¥è®¡ç®—æ¢¯åº¦åçš„æ¢¯åº¦ä¸ºï¼š", named_tensors[X_names[0]].grad)
        # Result
        # 3.è®°å½•è¯¥å±‚åå‘ä¼ æ’­çš„æ—¶é—´
        TIME.add('BWD', ubatchsize, vlayer_id, 'GPU', t_end-t_start) 
        # print("\t\t\tbackward'ed trial:{}".format(tid))
        # Clean up {X,Y,dX,dY}
        del named_tensors; del named_gradients; del Y_tensors; del Y_gradients

    # å¯¹æ¯ä¸€ä¸ªubatchsizeæ‰§è¡Œ
    # profileæ¯ä¸€å±‚çš„æ‰§è¡Œæ—¶é—´å’Œç©ºé—´å ç”¨
    def profile_forward(self, ubatchsize_range, num_trials, TIME, MEMORY, XMETA, TMETA):
        # NOTE: no OoM allowed in this function
        if self.verbose: print("forward ...")
        for ubatchsize in range(*ubatchsize_range):
            print("\tubatchsize {} ...".format(ubatchsize))
            for vlayer_id, (vlayer, X_names, Y_names) in enumerate(self.model):
                if self.verbose: print("\t\tvlayer_id {}".format(vlayer_id))
                # Clean start
                gc.collect(); torch.cuda.empty_cache()
                # ç­‰å¾…è®¾å¤‡ä¸Šçš„æ‰€æœ‰æµæ“ä½œå®Œæˆ
                torch.cuda.synchronize(self.device)
                # memory_reservedï¼šå‘CUDAç”³è¯·çš„å†…å­˜å ç”¨
                assert torch.cuda.memory_reserved()==0, "vlayer begin w/ alloc = {} B, resrv = {} B".format(torch.cuda.memory_allocated(), torch.cuda.memory_reserved())
                # å°†å†…å­˜ä½¿ç”¨çš„å³°å€¼é‡ç½®ä¸ºå½“å‰å€¼ï¼Œè¿™æ ·åœ¨åç»­çš„ä»£ç æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œå¯ä»¥å‡†ç¡®åœ°è¿½è¸ªå†…å­˜çš„æœ€é«˜ä½¿ç”¨é‡
                torch.cuda.reset_peak_memory_stats() 
                # Swap-in model {W,B}
                # ç”¨äºå°†æ¨¡å‹å±‚çš„å‚æ•°ç¼“å†²åŒºåŠ è½½åˆ° CUDA è®¾å¤‡ä¸Šï¼Œå¹¶æ ¹æ®å‡½æ•°çš„ç¬¬äºŒä¸ªå‚æ•°requires_grad è®¾ç½®å‚æ•°æ˜¯å¦éœ€è¦æ¢¯åº¦
                self._swapin_param_buf(vlayer, requires_grad=False)
                
                # total_params = 0
                # total_memory_bytes = 0
                # for param in vlayer.parameters():
                #     if param is not None:
                #         num_params = param.numel()
                #         dtype = param.dtype
                #         memory_bytes = num_params * param.element_size()
                        
                #         total_params += num_params
                #         total_memory_bytes += memory_bytes
                        
                #         # print(f"å‚æ•°åç§°: {name}, å‚æ•°é‡: {num_params}, æ•°æ®ç±»å‹: {dtype}, ç©ºé—´å ç”¨: {memory_bytes / (1024 ** 2):.6f} MB")
                # print(f"layer{vlayer_id}, æ€»å‚æ•°é‡: {total_params}, æ€»ç©ºé—´å ç”¨: {total_memory_bytes / (1024 ** 2):.6f} MB\n")

                # print("==========================")
                # print(f"åŠ è½½è¯¥å±‚æ¨¡å‹åï¼Œtorch.cuda.memory_allocated():{torch.cuda.memory_allocated()/1024/1024} ,torch.cuda.memory_reserved():{torch.cuda.memory_reserved()/1024/1024}")
                # First iteration for MEMORY
                # è¿™ä¸€æ¬¡å‰å‘åªè®°å½•å†…å­˜å ç”¨ï¼Œå°½ç®¡æ—¶é—´ä¹Ÿè®°å½•äº†ï¼Œä½†ä¼šè¢«æ¸…ç©º
                with torch.no_grad():
                    # åˆ†ä¸¤ç§æƒ…å†µï¼Œæ‰€æœ‰å±‚çš„å‰å‘/åå‘è®¡ç®— å’Œ æŸå¤±å‡½æ•°çš„è®¡ç®—
                    # 1.æ ¹æ®å…ƒæ•°æ®éšæœºç”Ÿæˆä¸€ä¸ªtensorä½œä¸ºå±‚çš„è¾“å…¥ï¼Œè‹¥æ˜¯æœ€åè®¡ç®—æŸå¤±çš„å±‚ï¼Œè¿˜è¦å®ä¾‹åŒ–ä¸€ä¸ªtarget tensorï¼Œå³æ ‡ç­¾tensor
                    #   ğŸ“Œæ³¨æ„ï¼Œæ— è®ºubatchsizeæ˜¯å¤šå¤§ï¼Œä¸€å¼€å§‹metaçš„shapeéƒ½åªæ˜¯1ç»´çš„ï¼Œè¯¥å‡½æ•°å†…éƒ¨ä¼šæŠŠç¬¬ä¸€ä¸ªç»´åº¦å˜ä¸ºubatchsizeçš„å¤§å°
                    # 2.è®¡ç®—å±‚çš„æ‰§è¡Œæ—¶é—´
                    # 3.å°†è¾“å‡ºä¿å­˜èµ·æ¥ï¼Œå› ä¸ºè‹¥å‡½æ•°æœ€åä¸€ä¸ªå‚æ•°ç½®ä¸ºtrue(å³è¿›è¡Œçš„æ˜¯åå‘è®¡ç®—çš„é‡è®¡ç®—)ï¼Œè¿™ä¸ªè¾“å‡ºéœ€è¦è¿”å›
                    # 4.è‹¥å½“å‰å±‚ä¸æ˜¯è®¡ç®—æŸå¤±çš„é‚£ä¸€å±‚ï¼Œåˆ™æ ¹æ®è¾“å‡ºå®ä¾‹åŒ–ä¸€ä¸ªå…ƒæ•°æ®ï¼Œå› ä¸ºè¯¥å±‚çš„è¾“å‡ºå°±æ˜¯ä¸‹ä¸€å±‚çš„è¾“å…¥ï¼Œä¸‹ä¸€å±‚æ‰§è¡Œè¯¥å‡½æ•°æ—¶
                    #   éœ€è¦æ ¹æ®è¿™ä¸ªå…ƒæ•°æ®éšæœºåˆ›é€ ä¸€ä¸ªè¾“å…¥tensor
                    # ğŸ“Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œrequires_gradä¸ºTrueï¼Œä»£è¡¨è¯¥å‡½æ•°æ˜¯åœ¨æ£€æµ‹BWDçš„è¿‡ç¨‹ä¸­è¢«è°ƒç”¨çš„ï¼Œæ­¤æ—¶FWDè®¡ç®—çš„æ—¶é—´è¦åŠ å…¥åˆ°BWDä¸­ï¼Œ
                    #   å³æœ€ç»ˆçš„BWDæ‰§è¡Œæ—¶é—´åŒ…å«äº†é‡è®¡ç®—å½“å‰å±‚çš„æ—¶é—´
                    self._vlayer_forward_an_ubatch(ubatchsize, vlayer_id, vlayer, X_names, Y_names, 0, TIME, XMETA, TMETA, requires_grad=False)
                    gc.collect()
                # torch.cuda.max_memory_allocated()ï¼šè·å–å½“å‰è¿›ç¨‹ä¸­å¼ é‡åˆ†é…çš„æœ€å¤§å†…å­˜é‡
                # å°†å½“å‰ubatchsize, vlayer_idå¯¹åº”çš„æœ€å¤§å†…å­˜ä½¿ç”¨é‡å­˜å…¥MEMORYä¸­
                # ğŸ“Œåˆ†æï¼šæ­¤å†…å­˜å ç”¨åŒ…å«è¾“å…¥ã€æ¨¡å‹ã€è¾“å‡ºçš„å ç”¨ï¼Œå³å…¨éƒ¨åŠ è½½ä¸€èµ·çš„å€¼
                MEMORY.set('FWD', ubatchsize, vlayer_id, torch.cuda.max_memory_allocated())
                # print(f"è¯¥å±‚æœ€ç»ˆçš„å³°å€¼å†…å­˜å ç”¨ä¸ºï¼š{torch.cuda.max_memory_allocated()/1024/1024}")
                # print("==========================")
                # print("vlayer_id: ", vlayer_id," ,torch.cuda.max_memory_allocated():", torch.cuda.max_memory_allocated())
                # Then iterations for TIME
                # self.stats['FWD'][ubatchsize][vlayer_id][device] = 0.0
                TIME.reset('FWD', ubatchsize, vlayer_id, 'GPU')
                # è¿™æ¬¡å‰å‘ä¼šè®°å½•å±‚çš„æ‰§è¡Œæ—¶é—´
                for tid in range(0, num_trials): # each trial is one microbatch 
                    with torch.no_grad():
                        self._vlayer_forward_an_ubatch(ubatchsize, vlayer_id, vlayer, X_names, Y_names, tid, TIME, XMETA, TMETA, requires_grad=False)
                        gc.collect()
                # Swap-out {W,B}
                # å°†å±‚æ”¾å›åˆ°cpuä¸Š
                vlayer.cpu()            

    # å¯¹æ¯ä¸€ä¸ªubatchsizeæ‰§è¡Œï¼š
    # å¯¹æ¯ä¸€å±‚ï¼Œå…ˆæ‰§è¡Œä¸€æ¬¡å‰å‘è®¡ç®—ï¼Œæ‹¿åˆ°è¯¥å±‚çš„è¾“å…¥è¾“å‡ºtensorï¼Œå› ä¸ºåå‘è®¡ç®—å°±æ˜¯å¯¹è¯¥å±‚çš„è¾“å‡ºtensorè®¡ç®—æ¢¯åº¦ã€‚
    # è€Œåæ‰§è¡Œè¯¥å±‚çš„åå‘è®¡ç®—ï¼Œè®°å½•è¯¥å±‚gpuå†…å­˜çš„å ç”¨å’Œåå‘ä¼ æ’­çš„æ—¶é—´
    def profile_backward(self, ubatchsize_range, num_trials, TIME, MEMORY, XMETA, TMETA):
        # NOTE: no OoM allowed in this function
        if self.verbose: print("backward (with recompute) ...")
        for ubatchsize in range(*ubatchsize_range):
            print("\tubatchsize {} ...".format(ubatchsize))
            # åæ–¹å‘æ‰§è¡Œæ‰€æœ‰layer
            for vlayer_id, (vlayer, X_names, Y_names) in reversed(list(enumerate(self.model))): # reverse all vlayer (layer)
                if self.verbose: print("\t\tvlayer_id {}".format(vlayer_id))
                # Clean start
                gc.collect(); torch.cuda.empty_cache()
                torch.cuda.synchronize(self.device)
                # memory_reservedï¼šå½“å‰å·²ç»åœ¨ CUDA è®¾å¤‡ä¸Šåˆ†é…ä½†å°šæœªä½¿ç”¨çš„å†…å­˜é‡
                assert torch.cuda.memory_reserved()==0, "vlayer begin w/ alloc = {} B, resrv = {} B".format(torch.cuda.memory_allocated(), torch.cuda.memory_reserved())
                torch.cuda.reset_peak_memory_stats() 
                # Swap-in model {W,B}
                # ç”¨äºå°†æ¨¡å‹å±‚çš„å‚æ•°ç¼“å†²åŒºåŠ è½½åˆ° CUDA è®¾å¤‡ä¸Šï¼Œå¹¶æ ¹æ®å‡½æ•°çš„ç¬¬äºŒä¸ªå‚æ•°requires_grad è®¾ç½®å‚æ•°æ˜¯å¦éœ€è¦æ¢¯åº¦
                self._swapin_param_buf(vlayer, requires_grad=True)
                print(f"åŠ è½½è¯¥å±‚æ¨¡å‹åï¼Œtorch.cuda.memory_allocated():{torch.cuda.memory_allocated() / 1024 / 1024} MB ,torch.cuda.memory_reserved():{torch.cuda.memory_reserved() / 1024 / 1024} MB")
                # First iteration for MEMORY
                # è¿™æ¬¡æ‰§è¡Œåªè®°å½•gpuå†…å­˜å ç”¨ä¿¡æ¯
                # å…ˆæ‰§è¡Œä¸€éè¯¥å±‚çš„å‰å‘è®¡ç®—ä»¥æ‹¿åˆ°è¯¥å±‚çš„è¾“å…¥ã€è¾“å‡ºtensorï¼ŒğŸ“Œå› ä¸ºè¦å¯¹è¯¥å±‚çš„è¾“å‡ºè¿›è¡Œåå‘è®¡ç®—
                named_tensors = self._vlayer_forward_an_ubatch(ubatchsize, vlayer_id, vlayer, X_names, Y_names, 0, TIME, XMETA, TMETA, requires_grad=True) # X/Y { name : tensor or const or [tensor,tensor] }
                size_bytes = named_tensors[Y_names[0]].element_size() * named_tensors[Y_names[0]].nelement()  # æ€»å­—èŠ‚æ•°
                size_mb = size_bytes / 1024 / 1024  # è½¬æ¢ä¸ºMB
                print(f"è¾“å‡ºæ¿€æ´»çš„æ˜¾å­˜å ç”¨: {size_mb:.2f} MB")
                
                print(f"å‰å‘è®¡ç®—åï¼Œtorch.cuda.memory_allocated():{torch.cuda.memory_allocated() / 1024 / 1024} MB ,torch.cuda.memory_reserved():{torch.cuda.memory_reserved() / 1024 / 1024} MB")
                # 1.å‡†å¤‡backwardå‡½æ•°çš„ç¬¬äºŒä¸ªå‚æ•°
                # 2.å¯¹è¯¥å±‚çš„è¾“å‡ºtensorè¿›è¡Œåå‘è®¡ç®—
                # 3.è®°å½•è¯¥å±‚åå‘ä¼ æ’­çš„æ—¶é—´
                self._vlayer_backward_an_ubatch(ubatchsize, vlayer_id, vlayer, X_names, Y_names, 0, TIME, XMETA, TMETA, named_tensors)
                print(f"åå‘è®¡ç®—åï¼Œtorch.cuda.memory_allocated():{torch.cuda.memory_allocated() / 1024 / 1024} MB ,torch.cuda.memory_reserved():{torch.cuda.memory_reserved() / 1024 / 1024} MB")
                del named_tensors # very important!
                gc.collect()
                # è®°å½•gpuå†…å­˜ä½¿ç”¨é‡ï¼šå°†å½“å‰ubatchsize, vlayer_idå¯¹åº”çš„æœ€å¤§å†…å­˜ä½¿ç”¨é‡å­˜å…¥MEMORYä¸­
                MEMORY.set('BWD', ubatchsize, vlayer_id, torch.cuda.max_memory_allocated())
                # print("vlayer_id: ", vlayer_id," ,torch.cuda.max_memory_allocated():", torch.cuda.max_memory_allocated())
                # Then iterations for TIME
                TIME.reset('BWD', ubatchsize, vlayer_id, 'GPU')
                # è®°å½•è¯¥å±‚åå‘ä¼ æ’­æ‰§è¡Œçš„æ—¶é—´
                for tid in range(0, num_trials): # each trial is one microbatch 
                    named_tensors = self._vlayer_forward_an_ubatch(ubatchsize, vlayer_id, vlayer, X_names, Y_names, tid, TIME, XMETA, TMETA, requires_grad=True) # X/Y { name : tensor or const or [tensor,tensor] }
                    self._vlayer_backward_an_ubatch(ubatchsize, vlayer_id, vlayer, X_names, Y_names, tid, TIME, XMETA, TMETA, named_tensors)
                    del named_tensors # very important!
                    gc.collect()
                # Swap-out model {dW,W,B}
                self._del_grad(vlayer)
                vlayer.cpu()

    # åœ¨cpuä¸Šä¸ºæ¯ä¸€å±‚éƒ½æ‰§è¡Œ num_trials æ¬¡å‚æ•°çš„æ›´æ–°ï¼Œå¹¶è®°å½•å‚æ•°æ›´æ–°çš„æ—¶é—´
    @torch.no_grad()
    def profile_update(self, num_trials, TIME):
        if self.offload_optim:
            for vlayer_id, ((vlayer, _, _), optim) in enumerate(zip(self.model, self.optimizer)):
                if optim is not None:
                    if self.verbose: print("\tvlayer_id {}".format(vlayer_id))
                    # Traverse all trials; each trial is one vlayer update
                    for tid in range(0, num_trials):
                        # å°†å±‚æ‰€æœ‰å‚æ•°çš„æ¢¯åº¦éšæœºåˆå§‹åŒ–ï¼Œç±»å‹ä¸ºfp32ï¼Œä½äºcpuä¸Š
                        for param in vlayer.parameters():
                            param.requires_grad_(True)
                            param.grad = torch.rand(param.data.shape, dtype=torch.float32, device="cpu")
                        # compute updated weight
                        # æ‰§è¡Œå‚æ•°æ›´æ–°
                        t_start = pc() 
                        optim.step()
                        optim.zero_grad()
                        t_end = pc() 
                        TIME.add('UPD', None, vlayer_id, 'CPU', t_end-t_start) 
                        # print("\t\tupdated on trial:{}".format(tid))
        else:
            raise NotImplementedError("update on GPU")
        # print("update done")

    # ä½¿ç”¨æœ€å¤§çš„micro batch sizeè·‘ä¸€ä¸‹å®Œæ•´çš„å‰åå‘
    # data_names: ["Input0"]
    # data_tensorsï¼š[tensor([1,1,1, ...,1,1,1])]ï¼Œtensoré•¿åº¦1024
    # target_names: ["labels"]
    # target_tensors: [tensor([1,1,1, ...,1,1,1])]ï¼Œtensoré•¿åº¦1024
    def initial_iteration(self, umax, data_names, data_tensors, target_names, target_tensors):
        ubatchsize_range = [umax, umax + 1, 1]
        TIME = Time(ubatchsize_range, ubatchsize_range, len(self.model))
        MEMORY = Memory(ubatchsize_range, ubatchsize_range, len(self.model))
        XMETA = XMeta(ubatchsize_range, len(self.model))
        TMETA = TMeta(ubatchsize_range, len(self.model))
        XMETA.init_data_meta_on_vlayer0(data_names, data_tensors)
        TMETA.init_target_meta_on_last_vlayer(target_names, target_tensors)
        self.profile_forward(ubatchsize_range, -1, TIME, MEMORY, XMETA, TMETA)
        self.profile_backward(ubatchsize_range, -1, TIME, MEMORY, XMETA, TMETA)
        print("initial iteration finished at batchsize {}".format(umax))

    # é€šè¿‡å€å¢æ³•æ¢æµ‹æœ€å¤§microbatchçš„å¤§å°
    # args.probe_whatï¼šFWD
    # data_names: ["Input0"]
    # data_tensorsï¼š[tensor([1,1,1, ...,1,1,1])]ï¼Œtensoré•¿åº¦1024
    # target_names: ["labels"]
    # target_tensors: [tensor([1,1,1, ...,1,1,1])]ï¼Œtensoré•¿åº¦1024
    def probe_max_ubatchsize(self, type, data_names, data_tensors, target_names, target_tensors):
        """ 
        Probe max microbatch size by multiplicative-increase
        
        NOTE: additive-increase/decrease is not used in practice, as it causes repeated program rerun 
        (esp., model's initialization overhead). This is due to the limitation of PyTorch: 
        Each OoM causes memory leak (https://github.com/pytorch/pytorch/issues/27600), and 
        rerun is the only way to recover full GPU memory after OoM.
        
        NOTE: Forward probing, backward probing, normal profiling need three seperate runs of 
        the entire python program, due to the above limitation. 
        """
        assert type in ('FWD', 'BWD')
        
        print("\n----- probing {}'s max microbatch size -----".format(type))
        
        ubatchsize, umax = 1, -1
        while True:
            print("{}: try ubatchsize {} ...".format(type, ubatchsize))
            try:
                # è¿™é‡Œæ„Ÿè§‰åªæ˜¯ä¸ºäº†ä»¥åå¥½æ‰©å±•ä»£ç ï¼Œå®é™…è¿™é‡Œåªä¼šæ‰§è¡Œubatchsize
                ubatchsize_range = [ubatchsize, ubatchsize + 1, 1]
                print(f"ubatchsize_range:{ubatchsize_range}")
                # åˆå§‹åŒ–æ—¶é—´çš„ç»Ÿè®¡ä¿¡æ¯ï¼š{ 'FWD'/'BWD' : { ubatchsize: { vlayer_id: { 'device': 0.xxx sec } } } }
                TIME = Time(ubatchsize_range, ubatchsize_range, len(self.model))
                # åˆå§‹åŒ–å†…å­˜å ç”¨çš„ç»Ÿè®¡ä¿¡æ¯ï¼š{ 'FWD'/'BWD' : { ubatchsize: { vlayer_id: xxx bytes } } }
                MEMORY = Memory(ubatchsize_range, ubatchsize_range, len(self.model))
                # ubatchsize_rangeæ˜¯ä¸€ä¸ªæœ‰ä¸‰ä¸ªå€¼çš„åˆ—è¡¨ï¼Œä»£è¡¨ first, last, step, ä¼šè¢«è§£åŒ…ä¼ ç»™range
                # ä¸ºæ¯ä¸€ä¸ªubatchsizeè®¾ç½®ä¸€ä¸ªæœ‰åºå­—å…¸ODictï¼Œè¯¥å­—å…¸ä¸­çš„keyä¸ºvlayer_idï¼ˆä»0å¼€å§‹ï¼‰ï¼Œéå†æ¯ä¸€ä¸ªidï¼Œå°†å€¼åˆå§‹åŒ–ä¸ºNone
                XMETA = XMeta(ubatchsize_range, len(self.model))
                # 1.åŒä¸Šï¼Œåˆå§‹åŒ–ä¸€ä¸ªXMetaï¼Œå› ä¸ºXMetaæ˜¯TMetaçš„çˆ¶ç±»
                # 2.éå†æ¯ä¸€ä¸ª{ubatchsizeï¼šODict}çš„é”®å€¼å¯¹ï¼Œåˆ é™¤ODictä¸­é™¤æœ€åä¸€å±‚å¤–çš„æ¯ä¸ªvlayer_idçš„å€¼
                # TMetaç”¨æ¥å­˜æœ€åä¸€å±‚ï¼ˆè®¡ç®—æŸå¤±å±‚ï¼‰çš„target tensor
                TMETA = TMeta(ubatchsize_range, len(self.model))
                # ç»™ XMETA ä¸­æˆå‘˜å˜é‡æœ‰åºå­—å…¸statsä¸­çš„æ¯ä¸€ä¸ªubatchsizeçš„ç¬¬0å±‚ï¼ˆvlayer_id=0ï¼‰èµ‹å€¼ï¼Œå³ä¸ºç¬¬0å±‚ç”Ÿæˆä¸€ä¸ªæœ‰åºå­—å…¸ï¼Œ
                # å­—å…¸çš„nameä¸ºè¾“å…¥åç§°ï¼Œå€¼ä¸ºæ ¹æ®ç¬¬äºŒä¸ªå‚æ•° data_tensors ç”Ÿæˆçš„å…ƒæ•°æ®ï¼Œåé¢ä¼šæ ¹æ®å…ƒæ•°æ®ç”Ÿæˆç›¸åŒå½¢çŠ¶å’Œç±»å‹çš„éšæœºtensor
                XMETA.init_data_meta_on_vlayer0(data_names, data_tensors)
                # ä¸ºstatsä¸­çš„æ¯ä¸€ä¸ªubatchsizeçš„æœ€åä¸€å±‚ï¼ˆvlayer_id=len(self.model)-1ï¼‰èµ‹å€¼
                # ä¸ºæœ€åä¸€å±‚èµ‹å€¼ï¼Œåœ¨statsä¸­ï¼Œæ¯ä¸ªvlayer_idè¿˜æ˜¯ä¸€ä¸ªODictï¼Œkeyä¸ºnameï¼Œå³è¾“å…¥çš„åå­—ï¼Œvalueä¸ºTensorMetaï¼Œå³tensorçš„å…ƒä¿¡æ¯
                TMETA.init_target_meta_on_last_vlayer(target_names, target_tensors)
                if type == 'FWD':
                    # å¯¹æ¯ä¸€ä¸ªubatchsizeæ‰§è¡Œ
                    # profileæ¯ä¸€å±‚çš„æ‰§è¡Œæ—¶é—´å’Œç©ºé—´å ç”¨
                    self.profile_forward(ubatchsize_range, 1, TIME, MEMORY, XMETA, TMETA)
                    print("....................FWD MEMORY..............................")
                    print(MEMORY)
                elif type == 'BWD':
                    # â“ä¸ºå•¥è¿˜è¦æ‰§è¡Œä¸€æ¬¡æ­£å‘
                    # ç­”ï¼šæš‚æ—¶çš„ç†è§£ï¼šå‰å‘è‹¥æ˜¯OOMäº†ä¹Ÿä¸ç”¨ç®—åå‘äº†ï¼Œç›´æ¥ç»ˆæ­¢äº†
                    self.profile_forward(ubatchsize_range, 1, TIME, MEMORY, XMETA, TMETA)
                    # åå‘æ£€æµ‹çš„æ—¶é—´
                    # å¯¹æ¯ä¸€ä¸ªubatchsizeæ‰§è¡Œï¼š
                    # å¯¹æ¯ä¸€å±‚ï¼Œå…ˆæ‰§è¡Œä¸€æ¬¡å‰å‘è®¡ç®—ï¼Œæ‹¿åˆ°è¯¥å±‚çš„è¾“å…¥è¾“å‡ºtensorï¼Œå› ä¸ºåå‘è®¡ç®—å°±æ˜¯å¯¹è¯¥å±‚çš„è¾“å‡ºtensorè®¡ç®—æ¢¯åº¦ã€‚
                    # è€Œåæ‰§è¡Œè¯¥å±‚çš„åå‘è®¡ç®—ï¼Œè®°å½•è¯¥å±‚gpuå†…å­˜çš„å ç”¨å’Œåå‘ä¼ æ’­çš„æ—¶é—´
                    self.profile_backward(ubatchsize_range, 1, TIME, MEMORY, XMETA, TMETA)
                    print("....................BWD MEMORY..............................")
                    print(MEMORY)
                umax = ubatchsize
            except Exception as e: 
                if 'CUDA out of memory' in str(e):
                    del e
                    break
                elif 'an illegal memory access' in str(e):
                    print(e)
                    del e
                    break
                else:
                    raise e
            ubatchsize *= 2
        
        print("--- {}'s max microbatch size = {} ---\n".format(type, umax))
        return umax

# åœ¨cuda:0ä¸Šè¿›è¡Œprofileï¼Œå°†æ”¶é›†çš„ä¿¡æ¯ä¿å­˜åˆ°.pickleæ–‡ä»¶ä¸­
# 1.modelã€è¾“å…¥æ•°æ®ã€labelæ•°æ®ã€Profilerç±»çš„åˆå§‹åŒ–
# 2.é€šè¿‡å€å¢æ³•æ¢æµ‹æœ€å¤§ microbatch çš„å¤§å°ï¼ˆ1ï¼Œ2ï¼Œ4ï¼Œ8ï¼‰
# 3.ä½¿ç”¨åˆšåˆšå¾—åˆ°çš„æœ€å¤§micro batchæ‰§è¡Œæ¢æµ‹ï¼š
#   3.1.FWDBWDï¼šæ”¶é›†æ¯ä¸€å±‚çš„å‰åå‘(çš„å¹³å‡)æ‰§è¡Œæ—¶é—´ã€å†…å­˜å ç”¨(æœ€å¤§å†…å­˜ä½¿ç”¨é‡)ã€è¾“å…¥è¯¥å±‚çš„æ•°æ®çš„å…ƒæ•°æ®ã€label tensorçš„å…ƒæ•°æ®
#   3.2.UDPï¼šæ”¶é›†æ¯ä¸€å±‚åœ¨cpuä¸Šçš„(å¹³å‡)å‚æ•°æ›´æ–°æ—¶é—´ã€å‚æ•°ç›¸å…³çš„å…ƒæ•°æ®ã€bufferç›¸å…³å…ƒæ•°æ®ã€ä¼˜åŒ–å™¨çŠ¶æ€ç›¸å…³å…ƒæ•°æ®
def run(args, synthetic_data, create_model, create_optimizer, compute_loss=None):
    
    assert torch.cuda.is_available()
    print(f"CUDA_VISIBLE_DEVICESç¯å¢ƒå˜é‡: {os.environ.get('CUDA_VISIBLE_DEVICES', 'æœªè®¾ç½®')}")
    torch.cuda.set_device(0) # control by CUDA_VISIBLE_DEVICES
    device = "cuda:0"
    print("device: ", device)

    """ Initialize model. """
    # 1.ä½¿ç”¨Importliobæ¨¡å—ï¼ŒæŠŠç¬¬1æ­¥æ‹†åˆ†å±‚çš„ä»£ç å¯¼å…¥è¿›æ¥ï¼Œèµ‹å€¼ç»™module
    # 2.ä»å‚æ•° args ä¸­æŒ‡å®šçš„é…ç½®æ–‡ä»¶ä¸­åŠ è½½ GPT-2 æ¨¡å‹çš„é…ç½®ä¿¡æ¯ï¼Œåˆ›å»ºä¸€ä¸ª GPT2Config å¯¹è±¡å¹¶èµ‹å€¼ç»™ config
    # 3.åˆ›å»ºäº†ä¸€ä¸ªäº¤å‰ç†µæŸå¤±å‡½æ•° CrossEntropyLoss çš„å®ä¾‹
    # 4.å®ä¾‹åŒ–å·²è¢«æ‹†åˆ†çš„model
    # 5.ä¸ºargsæ·»åŠ æ–°çš„å€¼ï¼Œå³æ¨¡å‹çš„configå®ä¾‹
    # è¿”å›model
    model = create_model(args)
    print("model created")

    """ Initialize data. """
    # åˆå§‹åŒ–æ•°æ®
    # æ ¹æ®inputå’Œlabelçš„å½¢çŠ¶ä¸ç±»å‹ï¼Œåˆ†åˆ«ä¸ºè¿™ä¿©åˆ›å»ºä¸€ä¸ªå€¼å…¨ä¸º 1 çš„å¼ é‡ã€‚è¿”å›è¿™ä¿©tensorçš„åå­—å’Œåˆ›å»ºçš„å¼ é‡
    # ğŸ“Œè¿™ä¸ªæ•°æ®ä¸æ˜¯æ‹¿æ¥ç”¨çš„ï¼Œè€Œæ˜¯æ ¹æ®å…¶ç”Ÿæˆå…ƒæ•°æ®ï¼Œç”¨çš„æ—¶å€™æ ¹æ®å…ƒæ•°æ®ï¼ˆshapeï¼Œç±»å‹ï¼‰éšæœºç”Ÿæˆä¸€ä¸ªtensor
    data_names, data_tensors, target_names, target_tensors = synthetic_data(args)
    # print("data_tensorsçš„å½¢çŠ¶:", data_tensors[0].shape)
    # print(data_tensors)
    # exit(0)
    
    """ Initialize Harmony. """
    # åˆå§‹åŒ–Profilerç±»ï¼Œå¹¶æ¸…ç©ºæ¨¡å‹æ¯ä¸ªvlayerçš„æ¢¯åº¦ï¼Œå¹¶å°†å‚æ•°ä»è®¡ç®—å›¾ä¸­åˆ†ç¦»ï¼Œå¹¶æ‰§è¡Œåƒåœ¾å›æ”¶å’Œæ¸…ç©ºcudaç¼“å­˜
    # no_offload_optim é»˜è®¤ä¸ºfalseï¼Œnotåç½®ä¸ºtrueï¼Œå³å¸è½½ä¼˜åŒ–å™¨
    p = Profiler(model, compute_loss=compute_loss, offload_optim=not args.no_offload_optim, device=device, verbose=args.verbose)

    """ Modes to profile. """ 
    # é€šè¿‡å€å¢æ³•æ¢æµ‹æœ€å¤§ microbatch çš„å¤§å°ï¼ˆ1ï¼Œ2ï¼Œ4ï¼Œ8ï¼‰,åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼ŒåŒæ ·æ”¶é›†äº†æ—¶é—´ã€å†…å­˜ç­‰ä¿¡æ¯ï¼ŒğŸ“Œä½†æ˜¯å¹¶ä¸ä¿å­˜è¿™äº›ä¿¡æ¯
    if args.mode == "probe":
        # é€šè¿‡å€å¢æ³•æ¢æµ‹æœ€å¤§ microbatch çš„å¤§å°ï¼ˆ1ï¼Œ2ï¼Œ4ï¼Œ8ï¼‰
        # args.probe_whatï¼šFWD/BWD
        # data_names: ["Input0"]
        # data_tensorsï¼š[tensor([1,1,1, ...,1,1,1])]ï¼Œtensoré•¿åº¦1024
        # target_names: ["labels"]
        # target_tensors: [tensor([1,1,1, ...,1,1,1])]ï¼Œtensoré•¿åº¦1024
        umax = p.probe_max_ubatchsize(args.probe_what, data_names, data_tensors, target_names, target_tensors)
        assert umax > 0, "[Error] Invalid {}'s max microbatch size = {}. Likely that even microabatch size = 1 explodes the GPU memory.".format(args.probe_what, umax)
        # å°†æ¢æµ‹åˆ°äº†æœ€å¤§micro-batchçš„å¤§å°å†™å…¥jsonæ–‡ä»¶ã€‚ï¼ˆè¿™é‡Œumaxæ˜¯ä¸€ä¸ªæ•´æ•°ï¼Œç›´æ¥å°†å…¶å†™å…¥.jsonæ–‡ä»¶ä¸­ï¼‰
        save_prof_data_struct(umax, args.output_dir, 'probe_{}_umax{}'.format(args.probe_what, args.outname_suffix))
    
    # ä½¿ç”¨åˆšåˆšå¾—åˆ°çš„æœ€å¤§micro batchæ‰§è¡Œæ¢æµ‹ï¼š
    # 1.FWDBWDï¼šæ”¶é›†æ¯ä¸€å±‚çš„å‰åå‘(çš„å¹³å‡)æ‰§è¡Œæ—¶é—´ã€å†…å­˜å ç”¨(æœ€å¤§å†…å­˜ä½¿ç”¨é‡)ã€è¾“å…¥è¯¥å±‚çš„æ•°æ®çš„å…ƒæ•°æ®ã€label tensorçš„å…ƒæ•°æ®
    # 2.UDPï¼šæ”¶é›†æ¯ä¸€å±‚åœ¨cpuä¸Šçš„(å¹³å‡)å‚æ•°æ›´æ–°æ—¶é—´ã€å‚æ•°ç›¸å…³çš„å…ƒæ•°æ®ã€bufferç›¸å…³å…ƒæ•°æ®ã€ä¼˜åŒ–å™¨çŠ¶æ€ç›¸å…³å…ƒæ•°æ®
    # ğŸ“Œè¿™å—æ‰çœŸæ­£ä¿å­˜è¿™äº›ä¿¡æ¯ï¼Œä¸”æ¯ä¸ªmicrobatchsizeéƒ½ä¿å­˜äº† 1,2,3,4...ï¼Œé»˜è®¤æƒ…å†µä¸‹å¹¶æ²¡æœ‰microbatchsizeçš„è·³è·ƒ
    elif args.mode == "normal":
        
        # whaté‡Œé»˜è®¤æœ‰è¿™ä¸ªï¼Œæ‰§è¡Œ
        if 'FWDBWD' in args.what:
            
            # get probed ubatchsize
            # 1.ä»æ–‡ä»¶ä¸­æ‹¿å‡ºåˆšåˆšæµ‹å¾—çš„å‰å‘æœ€å¤§çš„micro batchå’Œåå‘æœ€å¤§çš„micro batch
            fwd_umax = load_prof_data_struct(args.output_dir, 'probe_{}_umax{}'.format('FWD', args.outname_suffix), base_dir="my_prof") if args.fwd_umax == -1 else args.fwd_umax
            bwd_umax = load_prof_data_struct(args.output_dir, 'probe_{}_umax{}'.format('BWD', args.outname_suffix), base_dir="my_prof") if args.bwd_umax == -1 else args.bwd_umax
            print(f"fwd_umax:{fwd_umax}")
            print(f"bwd_umax:{bwd_umax}")
            # åå‘çš„å ç”¨æ›´å¤§ï¼Œè¿™ä¹Ÿç¬¦åˆè®ºæ–‡ä¸­è¯´çš„
            assert fwd_umax >= bwd_umax, "fwd_umax:{} v.s. bwd_umax:{}".format(fwd_umax, bwd_umax)
            
            # run initial iteration for starting cuda context
            # ä½¿ç”¨æœ€å¤§çš„micro batch sizeè·‘ä¸€ä¸‹å®Œæ•´çš„å‰åå‘
            p.initial_iteration(bwd_umax, data_names, data_tensors, target_names, target_tensors)
            
            # set ubatchsize_range for FWD and BWD 
            if args.ubatchsize_step >= 1.0:
                ubatchsize_step = int(args.ubatchsize_step)
            else:
                ubatchsize_step = max(int(float(args.ubatchsize_step) * min(fwd_umax, bwd_umax)), 1)
            fwd_ubatchsize_range = [1, fwd_umax + 1, ubatchsize_step]
            bwd_ubatchsize_range = [1, bwd_umax + 1, ubatchsize_step]
            print("\n----- normal profiling -----")
            print("forward microbatch sizes: [{}, {}) with a step size {}".format(fwd_ubatchsize_range[0], fwd_ubatchsize_range[1], fwd_ubatchsize_range[2]))
            print("backward microbatch sizes: [{}, {}) with a step size {}".format(bwd_ubatchsize_range[0], bwd_ubatchsize_range[1], bwd_ubatchsize_range[2]))
            print("-------------------------------\n")

            # profile FWD and BWD
            TIME = Time(fwd_ubatchsize_range, bwd_ubatchsize_range, len(p.model))
            MEMORY = Memory(fwd_ubatchsize_range, bwd_ubatchsize_range, len(p.model))
            XMETA = XMeta(fwd_ubatchsize_range, len(p.model))
            TMETA = TMeta(fwd_ubatchsize_range, len(p.model))
            XMETA.init_data_meta_on_vlayer0(data_names, data_tensors)
            TMETA.init_target_meta_on_last_vlayer(target_names, target_tensors)
            
            # args.num_trialsæ˜¯è·‘çš„iterationçš„æ¬¡æ•°ï¼Œè¿™æ ·çš„è¯TIMEé‡Œè®°å½•çš„æ—¶é—´æ˜¯4æ¬¡æ‰§è¡Œæ—¶é—´çš„å’Œ
            print("\n----- profiling forward -----")
            # ğŸ“Œæ³¨æ„ï¼Œfwd_ubatchsize_rangeä¸­çš„æ¯ä¸ªmicrobatchsizeéƒ½è¢«æµ‹äº†
            p.profile_forward(fwd_ubatchsize_range, args.num_trials, TIME, MEMORY, XMETA, TMETA)
            print("\n----- profiling backward -----")
            p.profile_backward(bwd_ubatchsize_range, args.num_trials, TIME, MEMORY, XMETA, TMETA)
            
            # save results
            # å°†FWD/BWDæ¯ä¸ªubatchsizeæ¯å±‚è®°å½•çš„æ€»çš„æ—¶é—´é™¤ä¸Šargs.num_trialsï¼Œå³å°†æ€»çš„æ—¶é—´æ›¿æ¢ä¸ºå¹³å‡æ—¶é—´
            TIME.avg_trials(args.num_trials)
            
            if args.verbose:
                print(TIME)
                print(MEMORY)
                print(XMETA)
                print(TMETA)
            
            # å°†å‡ ä¸ªå­˜ç€é‡‡é›†ä¿¡æ¯çš„ç»“æ„å­˜åˆ° .pickle æ–‡ä»¶ä¸­
            print()
            save_prof_data_struct(TIME, args.output_dir, "prof_TIME_FWDBWD{}".format(args.outname_suffix))
            save_prof_data_struct(MEMORY, args.output_dir, "prof_MEMORY_FWDBWD{}".format(args.outname_suffix))
            save_prof_data_struct(XMETA, args.output_dir, "prof_XMETA{}".format(args.outname_suffix)) # NOTE: data shape is ubatched
            save_prof_data_struct(TMETA, args.output_dir, "prof_TMETA{}".format(args.outname_suffix)) # NOTE: target shape is ubatched
            print()

        # whaté‡Œé»˜è®¤æœ‰è¿™ä¸ªï¼Œæ‰§è¡Œ
        # ğŸ“Œå°½ç®¡åªæµ‹äº†ä¸€æ¬¡UDPï¼Œä½†UPDçš„æ—¶é—´ä¸ubatchçš„å¤§å°æ— å…³ï¼Œå› ä¸ºå‚æ•°é‡æ°¸è¿œä¸å˜ï¼Œå› æ­¤åªåœ¨è¿™æµ‹ä¸€æ¬¡å°±å¤Ÿäº†
        if 'UPD' in args.what:
            if not args.no_offload_optim:

                """ Initialize optimizer. """
                # åˆå§‹åŒ–ä¼˜åŒ–å™¨ï¼šä¸ºmodelçš„æ¯ä¸€å±‚åˆ›å»ºä¸€ä¸ªAdamWä¼˜åŒ–å™¨ï¼Œè¿”å›ä¸€ä¸ªä¼˜åŒ–å™¨åˆ—è¡¨
                p.optimizer = create_optimizer(p.model)
                print("optimizer created on CPU")

                # profile UPD
                TIME = Time(None, None, len(p.model))
                # å‚æ•°ç›¸å…³çš„å…ƒæ•°æ®
                # ä¸ºmodelçš„æ¯ä¸€å±‚å»ºç«‹ä¸€ä¸ªå­—å…¸ {å‚æ•°çš„åå­—ï¼šTensorMeta(å‚æ•°çš„å…ƒæ•°æ®)}
                # ä¸ºmodelçš„æ¯ä¸€å±‚å»ºç«‹ä¸€ä¸ªå­—å…¸ {vlayer_id: å‚æ•°çš„å¤§å°(bytes)}
                WMETA = WMeta(p.model)
                # bufferç›¸å…³çš„å…ƒæ•°æ®
                BMETA = BMeta(p.model)
                # ä¼˜åŒ–å™¨çŠ¶æ€ç›¸å…³çš„å…ƒæ•°æ®
                KMETA = KMeta(p.model, p.optimizer)
                
                print("\n----- profiling update -----")
                # åœ¨cpuä¸Šä¸ºæ¯ä¸€å±‚éƒ½æ‰§è¡Œ num_trials æ¬¡å‚æ•°çš„æ›´æ–°ï¼Œå¹¶è®°å½•å‚æ•°æ›´æ–°çš„æ—¶é—´
                p.profile_update(args.num_trials, TIME)

                # save results
                # å¹³å‡å‚æ•°æ›´æ–°çš„æ—¶é—´
                TIME.avg_trials(args.num_trials)

                if args.verbose:
                    print(TIME)
                    print(WMETA)
                    print(BMETA)
                    print(KMETA)

                # å°†å‡ ä¸ªå­˜ç€é‡‡é›†ä¿¡æ¯çš„ç»“æ„å­˜åˆ° .pickle æ–‡ä»¶ä¸­
                print()
                save_prof_data_struct(TIME, args.output_dir, "prof_TIME_UPD{}".format(args.outname_suffix))
                save_prof_data_struct(WMETA, args.output_dir, "prof_WMETA{}".format(args.outname_suffix))
                save_prof_data_struct(BMETA, args.output_dir, "prof_BMETA{}".format(args.outname_suffix))
                save_prof_data_struct(KMETA, args.output_dir, "prof_KMETA{}".format(args.outname_suffix))
                print()

            else:
                raise NotImplementedError("Update on GPU")
    else:
        raise ValueError
